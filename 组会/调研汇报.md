
回过头思考一些之前的问题，很多地方之前都是理所当然的，现在会对这种设计产生疑问。比如频率编码这里，不管是 ANN2SNN，还是直接训练 SNN，目前看来，SNN与ANN的差异就是激活层换了 SNN的 LIF 神经元，并引入时间维度，从训练角度上来看，时间维度引入了一个循环，要从时间上遍历，就这个差异为什么导致 darwin3 硬件上设计相对传统 GPU 设计会有这么缺陷（时间步错乱、同步问题等）

引入时间维度自然不可避免的导致模型推理延迟很大（因为要走一个循环），不能说是为了符合生物合理性就去引入这个时间步问题，为什么要引入时间步这个问题

时间步的引入，同样导致了基于时间的频率编码显得有很多不合理性，为什么要将数据复制 t 份，这 t 份从信息熵角度来看，显得很冗余，你给模型喂了 t 份大致一样的数据，倒不如直接喂一份，这还导致显著增加模型训练时候显存的开销。

Darwin3 硬件性能很差，采用串行加法器，推理速度很慢，通信是串行的。而且只能针对线性层进行部署。

针对推理的加速

TUTEL: ADAPTIVE MIXTURE-OF-EXPERTS AT SCALE
针对 MOE 的分布式训练方法，提出了训练时候并行策略切换的方法，SNN MOE 架构，能否部署？


Mapping Very Large Scale Spiking Neuron Network to Neuromorphic Hardware
1) 软件模拟器的实现，是否有针对性的在 Darwin3 硬件上试过，效果真的有这么好吗？23 ASPLOS ，应该有试过，但效果不太好，但软件模拟器上效果很好，那么这里面造成的差异在哪里，这里面或许能发现当前 Darwin3 的瓶颈所在。如果部署在硬件上，也没有考虑中继问题，而且这个方案
2) 实验是模拟在单卡上，那么多卡 mapping 是否是可以继续深入研究下去，比如模型太大，需要多种 Darwin3 卡进行映射，这里就进入分布式领域，可以继续做下去。

传统 GPU 上有多卡训练推理加速，比如 TP，DP，PP，这里针对多卡类脑芯片，是否也能效仿，但做训练加速前，模型肯定要牵扯到多卡 mapping 操作，这里又绕回到前面这个问题上，可见多卡如何进行SNN 应用的mapping 至关重要。

The Forward-Forward Algorithm: Some Preliminary Investigations
无需全局反向传播，对每一层实现局部反向传播，相当于每一层训练简单的二分类器，思考这个能否作用在SNN硬件上，完成SNN硬件上的训练过程。


Fast-SNN: Fast Spiking Neural Network by Converting Quantized ANN
这里面有具体讲述 ANN2SNN 的数学上的严格证明，为什么这是一个数学上严格等价的过程