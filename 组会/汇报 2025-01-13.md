# To do
- [ ] mirco-service 的config.json 设计
- [ ] 传统做法
- [x] docker 调度：p36
- [x] 三个地方可放的优缺点，darwin，FPGA，上位机
- [ ] 限制：
	- [x] 存储和计算：传统做法是存储的位置要尽可能靠近计算单元，减少数据的搬运
	- [x] 通信：zeroMQ 和 JSON 编码协议
	- [x] 组合：怎么交互，单个任务的算子依赖是确定的，这里可以采用流水线并行化的方法，不同任务这就是 Darwin 的对用户任务调度的策略，


拆分算子，部署算子，不就是应该这么做吗

config.json 这个文件的配置，所属任务的ID号，任务ID的第几个算子，该算子是哪个用户的，

![[Pasted image 20250118103115.png]]

原本 Darwin 的设计是把整个类脑硬件语言描述模型简单拆分，然后把子模型整个映射到真实硬件吗？
映射的粒度是什么，是子模型吗，那么是否模型的拆分就没有一个固定的标准，所有引入 POG，将模型的拆分引入一个标准，映射的粒度就是单个算子，
![[Pasted image 20250118103630.png]]

软件设计说明书 p36

用户的任务被调度，然后到执行过程时进行算子拆分，流水线并行调度，在流水线中，算子之间的数据依赖关系决定了任务的执行顺序。数据从一个阶段流向下一个阶段，并且每个阶段的处理可以并行化。任务在程序编译时就已经确定了算子如何分配到流水线不同的阶段，用户算子的依赖是确定的。

用户提交的 SNN 任务，不管形式怎么样，用哪个框架写的，最后算子语义都是确定的，即用了那些层，层的参数，SNN 算子的规定，这是要统一标准的，起码在 Darwin 上是要统一的。

用户任务转换成计算图，然后对计算图拆分成一系列的算子定义，这个过程就是 POG 过程。然后具体的算子转化成具体的ISA描述，这个过程就是 EPG 的过程，然后就是将 EPG 过程化的算子部署到具体异构的真实硬件，这里要涉及驱动，也就是 EPG 化的算子 mapping 到 Hardware 上。

这个流程难道不就是应该这么做吗，如果不是，那要怎么做
![[Pasted image 20250119113821.png]]
这里子任务是什么，细粒度是什么，