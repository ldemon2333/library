# EC-SNN 方案
EC-SNN 代码阅读，看懂拆分思路和子模型保存位置。

![[Pasted image 20250702170844.png]]


# 类脑分布式推理异构框架
1. 通过 EC-SNN 得到拆分后的子模型 CSNN-1，CSNN-2，...，CSNN-C
2. 对子模型进行打包镜像，主备形式进行部署
3. 每个子模型得到输入input，利用自身下面的 Darwin 硬件进行局部自身推理，并把最终结果发给 Fusion MLP，这里通信协议上也要有标识信息来自哪个子模型
4. 当 Fusion MLP 得到所有子模型的推理结果后，进行 Concat 后，利用 GPU 硬件资源进行最终的推理计算，得到最终分类结果，以某种形式返回给用户。



![[SL.drawio (2).png]]

以脑启云项目为基础，一个 node 管理两个 darwin 设备，在 node 上部署拆分剪枝后的子模型CSNN，CSNN 做推理使用类脑硬件资源，这里输入input 可能复制好几份，每份都传入到一个子模型中，后续可能应该在前面做一个统一的代理入口。子模型推理完对应的类别，

这里每个子模型都是以 deployment 的多实例主备部署，同时部署多个 Pod，但每次只有一个 Pod 对外提供服务，其余处于“就绪但不接收流量”的状态。

CSNN 子模型可以使用 Darwin 硬件资源，Fusion MLP，使用 GPU 硬件资源

[[pod主备部署方案实现]]

[[pod 之间通信使用 clusterIp 服务类型]]

[[input 前端统一代理入口方案]]

脑启云项目将类脑硬件资源接入 k8s 方案


通信优化，适应 SNN 特性，讲故事， SNN 拆分上的细节，introduction（拆分之后怎么和硬件适配，相关指标，中文）

存储方面