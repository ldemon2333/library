# Done
- runc 源码分析，debug 了整个代码逻辑，分析父子进程如何通信，构造出一个容器，容器生命周期的切换源码实现
- 容器底层 Linux 技术研究：namespaces，cgroups，capabilities/seccomp
	- 7 个 namespace 具体是什么，含义是什么，作用是什么。
	- cgroups 的简单实现机制（文件系统的方式实现）。

- 了解容器技术的生态和 docker 架构，k8s 的架构
- 实现了一个手搓低阶完整版容器(namespaces + cgroups+capabilities/seccomp)（c 实现）

![[Pasted image 20250221183030.png]]
# Namespaces
如何实现容器，进程隔离技术，每个进程有自己的系统资源视图。

## 容器技术所用到的 7 种 namespaces
- **PID namespace**: isolation of the system process tree;
- **NET namespace**: isolation of the host network stack;
- **MNT namespace**: isolation of host filesystem mount points;
- **UTS namespace**: isolation of hostname;
- **IPC namespace**: isolation for interprocess communication utilities (shared segments, semaphores);
- **USER namespace**: isolation of system users IDs;
- **CGROUP namespace**: isolation of the virtual cgroup filesystem of the host.

通过对进程的命名空间的隔离设置，实现进程组独立的系统视图。

# Cgroups
用于对进程组进行 **资源隔离、限制与监控**。其发展历程与核心目标如下：
- v1 版本：
	- **多层级结构**：每个资源控制器（CPU、内存等）独立挂载，导致配置复杂。
    - **功能碎片化**：不同控制器间缺乏统一优先级和协调机制。
    - **安全问题**：权限模型松散，存在资源逃逸风险。
- v2 版本（2016年合并入内核）：
    - **统一层级设计**：所有控制器集中管理，形成单一资源树结构。
    - **精细化资源模型**：支持权重（如 `cpu.weight` ）与绝对限制（如 `memory.max` ）结合。
    - **安全增强**：默认启用「无侵入式委托」，防止子 cgroup 越权操作父组资源。

目前使用的是 cgroupv2 版本，完成容器内进程组的资源限制。如何设置，类似文件系统的写入操作，直接在 /sys/fs/cgroup/中进行修改相应的配置文件即可，目前可设置的资源限制
![[Pasted image 20250222135152.png]]


# Capabilities 与 Seccomp
Linux 两大核心的安全机制，它们通过 **“最小化权限”** 原则，防止程序滥用权限或被攻击者利用。

## Capabilities：拆分“超级权限”的钥匙
传统 Linux 的权限模型：**要么是普通用户，要么是 root（全权限）**，缺乏细粒度控制。

Capabilities 将 root 的万能钥匙拆分成 **30+ 种独立的小钥匙**，每把钥匙对应一种特定权限。例如：
- **CAP_NET_BIND_SERVICE**：允许绑定到 1024 以下的端口（如 Web 服务的 80 端口）。
- **CAP_DAC_OVERRIDE**：绕过文件权限检查（谨慎使用！）。
- **CAP_KILL**：允许终止任意进程。

构建容器时，主动设置容器的细粒度权限，通过"最小化权限“原则，只有运行容器里相应进程的相应权限。

## Seccomp：限制程序的“行动范围”
### **1. 系统调用的风险**
Linux 程序通过 **系统调用（syscall）** 与内核交互（如读写文件、创建进程）。  
攻击者常利用漏洞触发非常规系统调用（如 `execve` 执行恶意程序）。  
**问题**：普通程序可能用到几十个系统调用，但实际只需其中几个。

### **2. Seccomp 的核心原理**
Seccomp 像一道 **“系统调用防火墙”**，仅允许程序使用明确许可的调用，其他一律拦截。
- **严格模式（strict）**：只允许 `read`, `write`, `exit`, `sigreturn` 四个调用（极少使用）。
- **过滤模式（filter）**：通过 BPF 规则自定义允许的调用列表（主流方案）。



# 其他底层技术 
Union File System：通过分层叠加实现高效镜像存储。
网络虚拟化：虚拟网络接口和路由规则，实现容器间通信。
CRIU（Checkpoint/Restore）:实现容器热迁移，保留运行状态（常用于高可用场景）。


# Docker 架构
![Layered Docker architecture: docker (cli) -> dockerd -> containerd -> containerd-shim -> runc](https://iximiuz.com/implementing-container-runtime-shim/docker-containerd-runc-2000-opt.png)

![[Pasted image 20250210211716.png]]

从下往上，分为：
- container: 由 （Capabilities/sccomp）实现了容器，本质是“受限的进程”。
- runc：low-level，根据 OCI runtime 规范实现的一个命令行工具，能够管理创建容器的生命周期。真正启动容器是通过 coLinux 底层技术隔离（namespaces）、资源控制（cgroups）、文件系统（UnionFS）、安全ntainerd-shim 去调用 runc 来启动容器的，runc 启动完容器后本身会直接退出，containerd-shim 则会成为容器进程的父进程，负责收集容器进程的状态，上报给 containerd，并在容器中 pid 为 1 的进程退出后接管容器中的子进程进行清理，确保不会出现僵尸进程。runc创建的容器无网络配置，需要通过 containered 配置。
- containered-shim：容器的父进程。当我们要创建一个容器的时候，现在 Docker Daemon 并不能直接帮我们创建了，而是请求 containerd 来创建一个容器，containerd 收到请求后，也并不会直接去操作容器，而是创建一个叫做 containerd-shim 的进程，让这个进程去操作容器，我们指定容器进程是需要一个父进程来做状态收集、维持 stdin 等 fd 打开等工作的，假如这个父进程就是 containerd，那如果 containerd 挂掉的话，整个宿主机上所有的容器都得退出了，而引入 containerd-shim 这个垫片就可以来规避这个问题了。
- containered：high-level，容器的管理者，高阶容器运行时，能管理网络，能制作容器镜像。
- dockerd：docker 后端守护进程，复制监听来自客户端的请求。

## 容器启动流程
![](https://pub-e579a40e156a4a5a996f89c77c847416.r2.dev/2024/08/c3e2711aba1feff07f0374a4709c94d4.png)
1. containerd拉取&确认镜像就绪
2. containerd先创建容器对应的shim（垫片）进程
3. containerd通过rpc调用shim进程接口开始创建容器的实际过程（创建参数信息会一并传入）
4. shim程序准备容器rootfs（容器的宿主文件系统），挂载需要的volume（存储卷）
5. shim程序通过调用运行runc命令行程序（runc create独立进程，此时同样会传递创建参数信息）创建容器
6. runc create进程再次创建新进程执行runc init
    1. 此时容器创建参数（namespace、特权设置等）会以bootstrapData的形式通过runc create和runc init的pipe传递给runc init进程
    2. 同时在这里会预先给runc init进程设置好Cgroup，后面的容器进程就会继承这个Cgroup属性
7. runc init进程逐步转化为容器主进程（我们真正要运行的程序）
    1. runc init进程会先执行一个C程序，调用 nsexec，通过创建三代父子关系进程实现渐进式的进程namespace切换，之所以要这样是因为依靠单个进程无法实现自举切换，必须由前面一个高权限的创建出后面一个低权限的，逐步收缩下一代进程所占据的空间
    2. runc init进程执行完C程序后，继续执行Go代码，做一些网络、路由、selinux、rootfs（mount namespace内）、sysctl、readonly、capabilities等容器对应属性方面的设置工作，最终执行exec系统调用，正式转变为容器主进程
8. runc create接收到runc init的成功事件，设置rlimits（init进程权限不足）等其他需要高权限才能进行的配置
9. runc create调用成功，返回容器主进程的pid、socket文件等，runc进程退出，shim进程接管容器主进程，成为其父进程，可以进行后续对其的管理（更新、删除、exec等）


# k8s 的架构
![[Pasted image 20250227191341.png]]

还在跟进了解，containerd 只是 pod 里很小一部分，k8s 主要面向微服务，提高自动部署（调度），扩展，滚动更新，容灾。

Q: k8s 用在 AI 领域做训练的实例有点少，向前传递也要走容器之间，反向传播容器之间通信的开销感觉会很大，在仔细找找。如果做推理的话，只要走一遍前向，可能能作为服务节点。
An Automatic Artificial Intelligence Training Platform Based on Kubernetes [2020年]


# 达尔文容器虚拟化技术路线
- Darwin OS 上三大底层容器化技术的实现：
	- 七个类型的 namespace （资源隔离）
	- cgroups （资源限制）
	- capabilities 与 seccomp （安全机制）
- 实现类似于 runc 的 low-level 操作容器运行时工具，功能包括容器生命周期的控制，容器内进程快照，checkpoint-restore 等，这里涉及到 runc 的 config.json 配置文件，里面是关于底层 namespace，cgroups，seccomp/capabilities 的配置，定义这个容器的属性。
- 实现 high-level 的容器运行时，功能增加保存镜像，高效镜像存储搭建功能，到这里完成单机容器化，用户可以在自己单个容器内里自由开发 SNN 相关任务而不受影响。

进阶：SNN 任务多机容器化，将用户的 SNN 按照算子拆分，每个算子部署到一个容器内，这里会涉及到 SNN 网络的 config.json 配置文件，里面具体指示算子的具体部署，实现容器编排，容器之间数据如何传输，使得用户 SNN 任务可以快速高效的训练 

训练以微服务多容器来进行，是否有这个必要？可能引入更多的麻烦和缺陷，有待商榷，做到每个用户一个容器来执行自己的任务是否就已经足够了。

或者可以 k8s 这种架构可以作为 Darwin OS 上的一个管理用户容器的一种架构，作为一个 server 端，去管理用户的容器，是让 OS 管理员来操控，而不是让用户来操控。


















