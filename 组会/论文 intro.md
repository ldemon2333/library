### **论文引言 (Introduction)**

#### **1. 背景：脉冲神经网络与云原生计算的交汇**

随着人工智能（AI）的飞速发展，对计算效率和模型能效的要求日益严苛。传统的深度神经网络（ANNs）虽在诸多领域取得巨大成功，但其基于密集浮点运算的计算范式导致了高昂的能耗，限制了其在资源受限的边缘设备和大规模持续服务中的应用。在此背景下，作为第三代神经网络模型的脉冲神经网络（Spiking Neural Networks, SNNs）受到了学术界和工业界的广泛关注。SNNs 以其事件驱动（Event-Driven）、稀疏计算（Sparsity）和低功耗的特性，以及与生物神经系统的高度相似性，被认为是构建下一代高效能 AI 的关键技术，尤其在处理时序数据、边缘智能和未来神经形态芯片（Neuromorphic Computing）领域展现出巨大潜力。

与此同时，云原生（Cloud-Native）技术，特别是以 Kubernetes 为代表的容器编排系统，已成为部署、管理和扩展大规模应用的事实标准。Kubernetes 提供了强大的资源管理、自动化运维和弹性伸缩能力，为现代软件架构奠定了基石。为了让人工智能技术普惠化，将 SNN 这一新兴的计算范式与成熟的 Kubernetes 生态系统相结合，是实现其大规模部署和高效运维的必由之路。然而，这两种技术的融合并非一蹴而就。

#### **2. 问题陈述：SNN 与 Kubernetes 的根本性“阻抗失配”**

将新型硬件加速器集成到 Kubernetes 的标准途径是设备插件（Device Plugin）框架。然而，该框架在设计之初主要面向 GPU 等传统加速器，其资源模型与 SNN 硬件独特的计算架构之间存在着根本性的“阻抗失配”（Impedance Mismatch）。直接将 SNN 加速器套用现有框架，会引发一系列制约其性能和效率的关键问题：

- 资源模型的错配：从“黑盒”抽象到微观架构的失真。
    
    标准的设备插件将硬件视为一个单一、不可分割的“黑盒”资源（如 nvidia.com/gpu: 1）。若将此模式应用于 SNN 加速器，则完全忽视了其内部高度异构的微观架构——由大量可独立工作的神经元核心（Neuron Cores）、专用的脉冲路由网络（Spike Routing Networks）和事件处理队列（Event Queues）等组成。这种粗粒度的抽象导致 Kubernetes 调度器对硬件的能力“语义性失明”，无法进行精细化匹配。例如，一个脉冲交互频繁但所需神经元数量较少的任务，可能会被错误地调度到路由能力弱但核心数量多的硬件上，造成严重的资源错配和性能瓶颈，使得 SNN 最核心的稀疏计算优势在调度层面被完全扼杀。
    
- 调度指标的缺失：无法量化 SNN 的真实工作负载。
    
    Kubernetes 的调度决策依赖于对 CPU、内存等资源的量化请求。SNN 的性能与负载并非由浮点运算能力（FLOPs）定义，而是由其核心的事件处理能力，如脉冲处理速率（Spike Processing Rate, KSPS/MSPS）或事件吞吐量（Event Throughput, KEPS/MEPS）来衡量。现有框架缺乏对这些 SNN 原生指标的定义和度量能力，导致开发者无法准确声明其应用需求，调度器也无法进行负载感知（Workload-Aware）的智能决策，最终造成“随机”的次优调度和集群整体资源利用率的低下。
    
- 分布式潜力的束缚：从单体式推理到范式演进的障碍。
    
    单体式 SNN 推理受限于单芯片的物理资源，难以支撑“脑规模”的复杂模型，并面临着高延迟和低鲁棒性的挑战。SNN 的异步并行特性使其成为模型切分（Model Splitting）和分布式学习（如 Split Learning）的天然载体，这不仅是扩展模型规模、降低延迟、提升系统鲁棒性的有效途径，更能在边缘计算场景下利用脉冲通信的稀疏性保护用户隐私。然而，由于上述资源模型和调度指标的缺失，Kubernetes 无法识别和管理 SNN 硬件内部可独立调度的异步处理单元，也无法优化分布式场景下各模块间的脉冲通信。这极大地限制了 SNN 在分布式场景下发挥其核心优势。
    

#### **3. 我们的贡献：SNN Device Plugin**

为了弥合 SNN 与云原生生态之间的鸿沟，本文设计并实现了一个创新的 **SNN Device Plugin for Kubernetes**。该插件旨在从根本上解决上述“阻抗失配”问题，其核心目标是构建一个能够深度理解并赋能 SNN 计算范式的原生云解决方案。我们不再将 SNN 硬件视为被动、单一的资源，而是通过一个智能的、感知其架构的接口，将其独特的计算能力无缝集成到 Kubernetes 的调度与管理流程中。

本文的主要贡献如下：

1. **提出并实现了一种面向 SNN 的分层式资源模型。** 我们的插件能够智能感知并向 Kubernetes 汇报 SNN 加速器内部的微观结构，如可用的神经元核心集群、脉冲路由单元等，将“黑盒”资源转化为可供精细化调度的“白盒”资源。
    
2. **定义并集成了一套 SNN 原生的调度指标。** 通过将事件吞吐量（KEPS/MEPS）等指标暴露给 Kubernetes，我们使调度器能够首次基于 SNN 的真实负载进行决策，从而实现工作负载与硬件能力的最优匹配。
    
3. **为 SNN 的分布式部署提供了原生支持。** 通过识别和暴露硬件内部的异步处理单元，我们的插件能够协同 Kubernetes 自定义调度器，为 Split Learning 等分布式应用提供优化的部署方案，最大化 SNN 异步计算的优势。
    

通过深入结合 SNN 硬件的稀疏性、事件驱动和异步计算特性，我们设计的设备插件为在 Kubernetes 上构建、部署和扩展高性能、低功耗的 SNN 应用奠定了坚实的基础，特别是在分布式推理场景中，为未来 AI 发展开辟了新的可能性。