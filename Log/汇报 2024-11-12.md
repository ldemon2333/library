# Done
| Course | Content | Time |
| ------ | ------- | ---- |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |

# Question:
- [x] 非冯诺伊曼架构还是不能理解，每个核还是有自己的内存，但没有所有核的共享内存，也就没有总线概念，然后就是异步事件驱动，与使用时钟在每个周期获取指令的传统处理器不同，Darwin3 的神经元核心由脉冲事件驱动。到底什么算是冯诺依曼架构，什么是非冯诺伊曼架构，冯诺依曼架构的瓶颈是什么，

冯·诺依曼架构的瓶颈主要是“冯·诺依曼瓶颈”（von Neumann bottleneck），它指的是系统内 CPU 与内存之间的数据传输速率远低于 CPU 的处理速度。该架构中，数据和指令都存储在内存中，并通过总线（bus）传输到 CPU。由于 CPU 需要频繁地从内存读取指令和数据，有限的总线带宽限制了数据传输速度，导致 CPU 等待时间增加，处理效率降低。这种瓶颈的具体表现和原因包括以下几方面：

1. **数据带宽限制**：CPU 和内存之间的数据传输速率无法满足 CPU 的高速处理需求。随着 CPU 处理速度的提升，内存带宽成为瓶颈。

2. **存储和处理分离**：冯·诺依曼架构中，数据和指令存储在统一的存储器中，并通过相同的通道传输给 CPU。这种设计虽然简化了硬件结构，但使得 CPU 在访问数据和指令时必须交替进行，从而进一步限制了系统性能。

3. **缓存未必有效**：现代计算机虽然通过多级缓存减少 CPU 直接访问内存的频率，但在一些高频内存访问的场景中，缓存未必能显著提升性能，导致瓶颈仍然存在。

冯·诺依曼瓶颈在大数据处理、高速计算、深度学习等应用中尤为突出，因此一些新的架构设计（如哈佛架构、神经形态计算、内存计算等）尝试通过分离存储和计算、增加并行性等方式来减轻这一瓶颈。


- [x] 神经芯片硬件单个Darwin3所能继续做的优化是什么？Linked 表如何更进一步的压缩，fan-in与fan-out的设计，内存压缩机制的设计
- [x] 物源那个网站似乎还没做完，很多超链接打不开？注册账号都不行
- [x] 想自己走一遍这个SNN部署到这个硬件芯片的全过程，能不能直接连接芯片，进行开发，想玩一下这个OS，实践一下。
![[Pasted image 20241112103411.png]]
- [x] 整个开发顺序，首先是利用SPAIC框架，完成模型的设计，前向传播图搭建，然后利用达尔文编译将模型变为达尔文MDL中间语言，类似于一种模型结构的描述规则，然后交给OS，os自动解析整个数据，将这个模型部署到Darwin芯片上。训练方式有三种
- 训练ANN，ANN转化到SNN，然后部署到芯片
- 利用框架，snnTorch，SPAIC，spike，直接完成SNN的训练，直接部署到芯片上
- 先不训练，部署到芯片上，在芯片上训练。

![[Pasted image 20241029112958.png]]


三条路线：
- 针对硬件进行神经元优化，优化硬件结构，模型表示，探索更高效的数据表征方式
- ResNet 直接部署到芯片上
- OS 源代码研究，分布式OS，通信方面研究

做一个真正类脑OS









