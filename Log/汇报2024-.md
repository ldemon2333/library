# Done
| Course | Content | Time |
| ------ | ------- | ---- |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |
|        |         |      |

# Question:
- [ ]  达尔文芯片是near-memory-computing，小规模，这个芯片指令集是自己定制语言Darwin-MDL，有无技术文档？
- [ ] 上层编译器做的怎么样？
- [ ] 芯片技术文档有无？
- [ ] BIC 芯片与深度学习芯片（GPU）这个区别是什么？
- [ ] 芯片是分散式多核架构，无片外内存，内存放入核中，这个核与GPU的tensor core有啥区别，每个PE核都在核心中采用独立但紧密的内存和计算，我的理解就是把一种比DRAM更快的内存放进处理核中，感觉就是数据获取更快，但本质上还是一种计算和存储分离架构，感觉还是一种冯诺依曼式架构，为什么称之为非冯诺依曼架构？
- [ ] 这个芯片现在做的怎么样了？
- [ ] 后面实验的硬件平台这个环境要怎么搭建，是有实现虚拟环境吗，还是直接在芯片上做实验？
- [ ] 其他团队也有在做软件工具链，那么我们自己的软件工具链Darwin的Darwin-S做的怎么样了？技术文档有无？
- [ ] 这个OS有做出来吗？
- [ ] 后续这个研究方向具体是什么，比如做进程调度算法的研究吗？或者OS系统调用实现？
- [ ] 是否要去了解上层那些神经元模型，学习法则突触可塑性规则（STDP）这种？
- [ ] 达尔文芯片是小规模的，意味我们的OS是否也是小型的一个OS？
- [ ] 清华的天机芯片是做混合模型的架构，是走混合BIC 路线的，而我们的这个Darwin 是完全走BIC 路线的，完全仿大脑SNN来做的是吧？
- [ ] 大多数 BIC 芯片仅支持神经网络的推理阶段，而学习阶段必须提前在GPU 上完成。那么我们这个Darwin 芯片可以支持训练吗，还是只能做推理？
- [ ] 这个脑网络模拟器可以验证硬件性能，我们自己研发的脑网络模拟器现在做的怎么样了？
- [ ] Darwin项目最终目标是什么，是要做一个神经芯片通用计算平台，还是一个专门不通用的平台？
- [ ] 这么多开发工具链，我应该先学那个工具？