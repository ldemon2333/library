https://www.zhihu.com/question/33576416/answer/1243835966?utm_campaign=shareopn&utm_medium=social&utm_psn=1857221371815403520&utm_source=wechat_session

并行计算的核心目标是对一个问题进行拆解。拆解成若干独立的部分，然后对这些独立的部分同时进行计算，以提高整体的计算效率。但是由于硬件并行的范式多种多样，譬如有CPU多核并行，有SIMD并行，也有多台机器分布式内存的并行，因为这些并行的范式不一样，导致我们进行并行算法设计的时候也会有所不同，譬如不同的并行范式通信方式就不一样，而且对于这些并行范式进行编程的方式也不一样，譬如CPU多核并行可以使用pthread或者openMP，对于分布式内存进行编程，因为没有共享内存，所以需要显式进行通信，例如使用mpi，而对于SIMD的情况，在GPU上则需要以SIMT的思维编程。

虽然并行的范式各种各样，导致其算法设计，编程都有所区别，但是大致都可以分为三个层次
- 计算机体系结构：计算机都有哪些形式的并行？
- 并行编程：如何对于并行计算机进行编程？
- 并行算法：如何将一个问题拆解成可独立计算的子问题，如何减小通信？

# 并行计算机体系结构
体系结构非常粗略地可以分为计算与存储两块，一个重要的认知是，性能的瓶颈往往都是在数据移动，而非计算上。体系结构层面的并行主要分为这么几种：
- 多核CPU并行，可使用Pthread或openmp编程
- 每个CPU内部的SIMD（向量化）指令，一般由编译器自动向量化，也可以手动进行编程
- GPU的SIMT并行，SIMT在硬件层面依然是SIMD，但是在软件层面则比SIMD更加灵活
- 多台独立的计算机构成一个集群，可使用MPI进行通信和编程

# 并行编程
并行编程的目的就是针对某一种特定的并行硬件，我们如何将我们设计好的算法用程序编写出来。譬如CPU多核并行可以使用pthread或者openMP，对于分布式内存进行编程使用mpi进行通信，而在GPU上则需要以SIMT的思维编程。而并行编程的过程中，也会涉及到一些串行编程中不会出现的问题，譬如data race和死锁等等，我们的程序如何避免这些问题？

一些基础问题：
- 并行和并发的区别是什么？
- 进程和线程的区别是什么？原理是什么？是如何调度的？
- 单线程程序如何提高性能（各种编译优化）？
	- 提高局部性
	- 去冗余
- 如何平衡局部性和并行性？
- 如何做性能分析？都有啥工具？
	- 如何用各种 hardware performance counter?
- pthread 怎么用？它是怎么实现的？
- OpenMP 怎么用？它是怎么实现的？和 pthread 的区别与联系？
	- OpenMP里面的各种细节，譬如如何同步、如何共享数据等
- MPI怎么用？它是怎么实现的？和OpenMP分别代表了什么模型？
	- MPI里的各种通信模式，各种collect，如何同步之类的
	- MPI为什么快？跟Apache Spark之类的什么关系？
- 并行的任务应该如何调度？Scheduling算法都有哪些？
- SIMD、SPMD、SIMT之间的区别是什么？
- 数据竞争是什么？critical section是如何实现的？
- 线程之间同步的原理？
- 并行编程都有哪些模型？
- GPU怎么编程（cuda程序怎么写）？跟CPU SIMD啥区别？
- 如何把一个算法在GPU上高性能地实现？

# 并行算法分析与设计
