与非 edge 端的devices 相比，部署在 edge 端的硬件设备通常有以下几个限制条件：
- 硬件设备需要低功耗，
- 有限的硬件资源，包括相对少的内存，I/O存储
- 要求具有快速实时的响应，对信息的低延迟。

类脑硬件从电路设计方式可以被分为三类，模拟设计、数字设计和混合设计。模拟设计的脉冲神经形态硬件[1, 2, 3]往往比数字设计更贴近生物神经网络的工作原理。模拟相对于数字电路有以下优点：
- 模拟电路能够更高效地模拟神经元的连续变化，具有较低的能耗。
- 模拟电路能够更自然地模拟生物神经元的特性，ke。在某些应用场景中，模拟电路可以实现极高的处理速度。
- 模拟电路通常具有较低的处理延迟，因为它们不需要像数字电路那样进行大量的时序同步。神经元的激发可以直接与输入信号的变化关联，减少了延迟。
当然模拟电路相对于数字电路也具有以下缺点：
- 模拟电路设计需要精确控制电压、时间常数和电流等参数，以模拟神经元的动态特性。由于模拟电路通常更加复杂，设计和验证的难度较高，并且更容易受到温度、电压波动等因素的影响。
- 尽管模拟电路可以实现并行计算，但在大规模集成时，模拟设计面临的挑战比数字设计更大。模拟电路的组件（如放大器、传感器、忆阻器等）[1, 2, 3]需要精确匹配和调试，这使得在更大规模的硬件中集成时可能会遇到不稳定性和误差的问题。
- 模拟电路通常对外部噪声和电源波动非常敏感。微小的变化可能导致系统的非线性行为或者性能下降，因此需要高精度的设计和严格的电源管理。
- 与数字电路相比，模拟电路的调试和优化更加复杂。在模拟电路中，信号是连续的，难以通过传统的数字信号分析方法直接分析和调试。

因为以上缺点难以解决，edge端模拟硬件设计往往较少。现在研究主要是面向数字电路edge端硬件设计。

数字电路设计[4, 5, 6, 7, 8, 9, 10, 11, 12, 13]相较于模拟设计有以下几个优点：
- 数字电路通过二进制表示信息（"0" 和 "1"），可以精确控制计算过程中的每个步骤。由于信号是离散的，数字电路的输出通常是高度可重复的，不受温度、电压波动和元件老化等因素的影响。因此，数字设计具有更高的精度和可重现性，这对于在不同环境条件下运行的嵌入式系统尤为重要。
- 数字电路的设计通常比模拟电路简单，因为设计工具（如HDL和仿真软件）可以帮助自动化许多设计过程。数字电路的行为可以通过逻辑仿真[4]进行验证，调试工具也能够有效地识别设计中的问题。
- 数字电路易于进行规模扩展，对于嵌入式系统来说，数字设计能够在资源有限的情况下轻松实现大规模的神经网络，并支持并行计算。
- 数字电路主要采用事件驱动[5, 9]的方式，利用 SNN 中脉冲的时间稀疏性进行计算，并且不需要每时每刻都进行计算时降低功耗[10]，这对嵌入式 SNN 系统尤为重要。
- 数字设计通常能够很好地与其他现代数字技术兼容。例如，数字设计能够与 **FPGA**、**ASIC**、**微处理器** 等现代硬件平台无缝结合，支持嵌入式系统的灵活开发与部署。使得研究可以针对如何在FPGA上部署SNN开展[13]。
同时，SNN的数字电路edge端设计通常也与非冯诺依曼架构结合，根据内存存储单元与计算单元相近的远近分为两类，一类是 near-memory 计算架构，一类是 in-memory架构。

当然也有数字/模拟混合设计[14]，综合考虑两种设计的优缺点，取长补短。

1. [Novel designs of spiking neuron circuit and STDP learning circuit based on memristor]
2. [M. Hu, Y. Chen, J. J. Yang, Y. Wang and H. H. Li, "A Compact Memristor-Based Dynamic Synapse for Spiking Neural Networks," in IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, vol. 36, no. 8, pp. 1353-1366, Aug. 2017, doi: 10.1109/TCAD.2016.2618866.]
3. [Neuromorphic Spiking Neural Networks and Their Memristor-CMOS Hardware Implementations]
4. [A 640M pixel/s 3.65mW sparse event-driven neuromorphic object recognition processor with on-chip learning] 
5. [A Programmable Event-driven Architecture for Evaluating Spiking Neural Networks]
6. [A Low-Power Hardware Architecture for On-Line Supervised Learning in Multi-Layer Spiking Neural Networks]
7. [A 0.086-mm2 12.7-pJ/SOP 64k-Synapse 256-Neuron Online-Learning Digital Spiking Neuromorphic Processor in 28-nm CMOS] 
8. [A 65-nm Neuromorphic Image Classification Processor With Energy-Efficient Training Through Direct Spike-Only Feedback]
9. [Always-On, Sub-300-nW, Event-Driven Spiking Neural Network based on Spike-Driven Clock-Generation and Clock- and Power-Gating for an Ultra-Low-Power Intelligent Device] 
10. [μBrain: An Event-Driven and Fully Synthesizable Architecture for Spiking Neural Networks]
11. [Human activity recognition: suitability of a neuromorphic approach for on-edge AIoT applications]
12. [Power-efficient gesture sensing for edge devices: mimicking fourier transforms with spiking neural networks]
13. [Exploiting FPGAs and Spiking Neural Networks at the Micro-Edge: The EdgeAI Approach]
14. [A 3.43TOPS/W 48.9pJ/pixel 50.1nJ/classification 512 analog neuron sparse coding neural network with on-chip learning and classification in 40nm CMOS]


SNN具有低功耗执行优点，为了缩小SNN和神经形态硬件之间的差距，已经提出了各种映射方案，我们通常称之为映射工具链，所谓映射工具链，就是一种将SNN 映射到神经形态硬件的方法，其目标通常是尽可能地减少脉冲延迟和能耗，并且对性能的影响要尽可能的少。现有设计方案通常包括两个阶段：分区和映射。分区通常是设计某种分区算法将 SNN 图划分为小的神经元簇，然后神经元簇作为后续映射的单位放置到具体硬件上的物理神经元核心执行运算。

虽然这些工具链可以很方便的将大型SNN部署到神经形态硬件上，但它们目前主要关注部署在服务器端的神经形态硬件，并不是面向边缘端。

面向边缘计算的场景，不同于服务器端的类脑硬件，实现 SNN 映射面临独特挑战：主要是能源限制、实时处理和有限的计算资源。

目前的SNN 映射方案通常分位三类：专用硬件映射、基于交叉开关的硬件通用映射和其他灵活的映射方案。

>	第一类涉及专门为专门的 SNN 解决方案量身定制的专用硬件设计方案。此类映射方案的示例包括用于 µBrain [16] 的 SentryOS [15]、用于 TrueNorth [7] 的 Corelet 工具链 [17] 和用于 Loihi [8] 的 LCompiler [18]。这些完整的工具链旨在最大限度地优化核心利用率。SentryOS 工具链包含一个 SentryC 编译器，它将 SNN 网络结构划分为多个子网络，以及一个 SentryRT 实时管理器，负责实时对不同的子网络进行排序和计算。Corelet 是 TrueNorth 的专用可编程工具链，它封装了生物细节和神经元复杂性，然后提出了一种面向对象的 Corelet 语言来编写和执行 SNN。 LCompiler 框架通过呈现一个数据流图将 SNN 映射到 Loihi 神经形态硬件上，该数据流图具有描述 SNN 实例的逻辑实体，例如隔间、突触、输入映射、输出轴突和突触轨迹。该框架首先将 SNN 转换为微代码，并将 SNN 拓扑转换为连接矩阵。接下来，它采用贪婪算法将逻辑实体映射到硬件，然后再生成 Loihi 核心的比特流。在 Wang 等人的研究中。[19]，他们提出了一种针对 Tianjic 神经形态芯片 [20] 的创新映射方法。该方法包括两个阶段：逻辑映射和物理映射。在逻辑映射阶段，作者引入了一种采用异步 4D 模型分区的闭环映射策略。对于物理映射阶段，应用了汉密尔顿循环算法。该方法的优点是能够实现较高的资源利用率和处理效率，为在神经形态硬件上高效部署神经网络提供了一个有趣的视角。所有这些映射工具链都是针对特定目标而设计的，限制了它们的通用应用。这限制了它们在更通用用途上的适应性。

>第二类侧重于基于交叉开关的 SNN 拓扑方案，这是更通用的映射技术。这些方案包括最先进的映射技术，例如 NEUTRAMS [21]、SpiNeMap [13]、SNEAP [22] 和 DFSynthesizer [23]。
NEUTRAMS 是一个协同设计工具链，它可以对 SNN 进行分区以满足硬件约束，并优化它们在神经形态硬件上的映射。SpiNeMap 采用贪婪方法，大致基于 Kernighan-Lin 图分区算法 [24]，以最小化集群间尖峰通信，并利用 PSO 算法 [25] 将每个集群放置在物理核心上。SNEAP [22] 使用 METIS 图分区算法对 SNN 计算图进行分区，目标是通信成本，然后使用贪婪算法得到最终的映射结果。 DFSynthesizer [21] 是一个用于映射机器学习算法的端到端框架。它将 SNN 分解并划分为集群，然后利用同步数据流图的丰富语义来探索影响映射性能的不同硬件约束。这些现有的工具链主要针对云服务器设计，没有考虑边缘计算等复杂计算环境的限制。这可能会限制它们在资源受限的边缘场景中的适用性，因为环境因素会发挥作用。

针对边缘计算的工具链：
Xue 等人[1] 提出 edgemap 工具链，该工具链基于流的方法[2]启发，提出一种新型的分区方法，在随后的映射阶段，提出了一种多目标优化方法，专门用于降低能源成本和通信成本，以实现高效部署。

Xiao 等人[3] 提出 NeuMap 工具链，该工具链专注于具有前馈拓扑的基于 SNN 的应用程序。NeuMap 首先通过计算而不是模拟来获得 SNN 的通信模式。基于计算出的脉冲发放率，NeuMap 然后使用贪婪算法将 SNN 划分为多个集群，从而最小化集群之间的通信流量。最后，NeuMap 缩小了搜索空间并采用元启发式算法来寻求最佳的集群到核心方案。

除了映射工具链的支持，在资源受限的边缘环境中部署高效的 SNN 通常也需要硬件加速器来加速推理。[4] 提出了 Spiker+ 框架，可提供一个可配置的多层硬件 SNN、一个高效神经元架构库和一个设计框架，仅用几行 Python 代码即可开发复杂的神经网络加速器，用于在 FPGA 上生成高效、低功耗、小面积的定制 SNN 加速器，用于边缘推理。

Caspian 是一个神经形态开发平台，由一个低功耗神经形态处理器和高级 API 组成，可用于为边缘物联网应用模拟小规模 SNN[5]。此外，神经形态计算框架 TeNNLab[6] 与 Caspian 集成，以弥合软件应用程序与边缘设备上的底层硬件实现之间的差距。

其他使用SNN的物联网开发框架例如 NA-Designer[7]

其他一些 SNN simulator ，像NEST[8]，可以作为边缘设备上的SNN部署平台，可以为边缘计算进行优化。Nengo 框架[9]提出了一个 Loihi 模拟器，可以实现轻量级 SNN 模型。[10] 提出了一个优化的 FPGA 后端，将包装在 PYNQ API 中的 HLS 生成的硬件与 Nengo 神经网络开发框架集成在一起。

[11] 提出了一种高效的 SNN 模型生成方法，可以满足 FPGA 设备中的用户要求（例如准确性、执行时间）。所提出的方法使物联网开发人员能够生成高效的 SNN 模型，而无需详细了解神经形态硬件的内部工作原理。

[12] 提出一个名为 EC-SNN 的深度 SNN 拆分框架，用于在边缘设备上运行大型 SNN 模型。EC-SNN 框架提出一种通道修剪方法来减小每个子模型的大小，降低每个部署设备的整体能耗的同时显著减少边缘设备上的推理执行延迟。


1. [EdgeMap: An Optimized Mapping Toolchain for Spiking Neural Network in Edge Computing]
2. [Tsourakakis, C.E.; Gkantsidis, C.; Radunovic, B.; Vojnovic, M. FENNEL: Streaming graph partitioning for massive scale graphs. In Proceedings of the Seventh ACM International Conference on Web Search and Data Mining, WSDM 2014, New York, NY, USA,24–28 February 2014; pp. 333–342.]
3. [Optimal Mapping of Spiking Neural Network to Neuromorphic Hardware for Edge-AI]
4. [Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge]
5. [Caspian: A Neuromorphic Development Platform]
6. [Plank JS, Schuman CD, Bruer G, Dean ME, Rose GS (2018) The TENNLab exploratory neuromorphic computing framework. IEEE Lett Comput Soc 1(2):17–20. https://doi.org/10.1109/LOCS.2018.2885976]
7. [Developing IoT Applications Using Spiking Neural Networks Framework]
8. [NEST: An Environment for Neural Systems Simulations]
9. [Bekolay, T., et al. (2014). Nengo: A Python Tool for Building Large-Scale Functional Brain Models. Frontiers in Neuroinformatics, 7.]
10. [Implementing NEF Neural Networks on Embedded FPGAs]
11. [An Efficient SNN Model Generation Method for IoT Edge Computing]
12. [EC-SNN: Splitting Deep Spiking Neural Networks for Edge Devices]

工具链的做法，分区+映射，
- 分区：减小簇之间的通信流量，
- 映射：启发算法，如何更快映射，缩小搜索空间，根据优化目标进行相应的映射

EC-SNN做法，模型剪枝，模型角度出发，而且最后推理是在服务器上推理，edge端只是对数据初步训练。


