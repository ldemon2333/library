# Abstract
当前的神经形态系统通常难以使​​用且部署成本高昂。因此，需要一个简单而灵活的神经形态开发平台，让研究人员能够快速构建想法和应用的原型。==Caspian 提供高级 API 和快速脉冲模拟器，以便快速开发神经形态解决方案。它还提供了一种 FPGA 架构，可以简化部署 - 特别是在 SWaP（尺寸、重量和功率）受限的环境中。==Caspian 利用软件和硬件，旨在加速开发和部署，同时让新研究人员能够快速利用脉冲神经网络系统提高工作效率。

# 1. 介绍
近年来，神经形态计算研究显著增加 [21]。神经形态研究工作的多样性导致了不同的硬件实现、不同的软件框架和各种算法。尽管已经有一些努力将这些不同的努力统一在一个单一的保护伞下（例如，应用脑研究的 Nengo [3]），但对于那些刚接触神经形态计算的人来说，要想快速尝试神经形态计算框架并将其应用于自己的应用程序，仍然存在很大的进入门槛。考虑到这一点，我们提出了 Caspian，这是一个具有软件和硬件组件的神经形态开发平台，专门针对新用户，帮助他们快速开始使用神经形态计算系统。

我们的重点是开发一个针对非神经科学用户的平台。也就是说，我们假设有兴趣了解和使用神经形态系统的用户对运行生物学上准确的模拟不感兴趣，而只是对了解神经形态平台对他们的应用有何用处感兴趣。我们之所以提供这种区别，是因为这些用户可能会被其他软件包很好地服务，例如 Brian [11]、NEST [10] 等。然而，对于非神经科学家来说，这些软件包可能很难用来简单地开始研究脉冲神经网络的功能。

我们设想，非神经科学用户将希望通过两种方式与神经形态系统交互：使用现有的训练方法训练脉冲神经网络并部署它们，或者手动操作脉冲神经网络以研究如何将它们用于非机器学习任务，例如 [1] 中描述的任务。对于第一组，我们专注于支持 Caspian 框架内的几种现有算法和软件包，包括 SLAYER [23]、EONS [20] 和液态机。对于第二组用例，==我们专注于提供易于使用的网络表示和高度优化的硬件精确软件模拟器，以实现快速的 SNN 模拟和原型设计。==

在第 2 节中，我们讨论了神经形态计算中的其他软件和硬件工作，特别关注它们如何以及为何难以使用，特别是对于神经形态计算的新手来说，这激发了对 Caspian 等神经形态开发平台的需求。在第 3 节中，我们讨论了 Caspian 实现的 SNN 模型以及选择该模型的原因。第 4 节和第 5 节分别讨论了 Caspian 软件和硬件，详细介绍了系统的当前状态以及未来开发计划。在第 6 节中，我们展示了 Caspian 模拟器的性能，以及使用 Caspian 和 SLAYER 和 EONS 等训练方法的结果。

# 2. Background And Related work
对于具有计算机科学背景的神经形态学新手来说，前景似乎令人生畏。有许多不同的软件包和硬件实现，每个都有自己的术语和 API。有一些努力有助于将多个模拟器和硬件架构统一到一个通用 API 下。其中一项努力就是 ==PyNN。PyNN 是一个 Python API，用于设计独立于所用模拟器或硬件的神经网络 [6]。==它目前支持 NEURON、NEST 和 Brian 作为模拟引擎，并且可以使用 SpiNNaker 和 BrainScaleS 硬件。PyNN 及其相关模拟器深受神经科学的影响 [10, 11]。为了使用 PyNN，用户必须已经具备大量有关脉冲神经网络的知识，并且用户需要明确构建其网络的结构。PyNN 并非设计为面向计算的框架，因此，它不提供高级机器学习算法。

另一个著名的神经形态开发框架是 Nengo。Nengo 由应用脑研究 (ABR) 开发，是一个基于神经工程框架 (NEF) 原理构建的包罗万象的 Python 库。它提供多种模拟引擎，包括原生 Python 实现和 OpenCL 加速实现。Nengo 支持不同的学习算法以及与 Tensorflow 的深度学习集成。虽然 Nengo 比 PyNN 更注重计算，但它与 NEF 紧密相关，当 NEF 不是所需的方法时，它可能不切实际或无法使用。

除了软件框架之外，还有许多不同的神经形态硬件平台，包括基于 FPGA 的设计、数字 VLSI 设计和混合信号设计。一方面，SpiNNaker 是一种基于 ARM 的多核数字设计，具有定制网络，旨在实现高度可扩展的脉冲模拟。通过使用 ARM 内核 [9]，SpiNNaker 可以执行各种神经元和突触模型。其他数字设计，如 IBM TrueNorth [2] 和 Intel Loihi [5]，则倾向于神经突触内核方法，其中计算元素是为神经形态定制的。然而，模拟和混合信号硬件也是神经形态计算的一种有前途的方法。例如，BrainScaleS 使用晶圆级模拟神经元和突触集成来执行大型脉冲神经网络模拟，速度比实时速度更快 [14]。不幸的是，这些专门的集成电路设计价格昂贵，需要制造和分发定制硬件，因此一种替代方案是针对 FPGA 平台。有几个 FPGA 目标设计的例子，包括 DANNA [7]、DANNA2 [15]、NeuroFlow [4] 和
NengoFPGA [16]。如果需求发生变化，这些设计可以随着时间的推移而升级，也可以使用商品硬件进行部署。

# 3. CASPIAN
Caspian 的主要目标是不仅提供易于使用的软件和硬件，而且还提供足够简单的模型，以便新用户理解，同时允许足够的复杂性以执行 SNN 计算。特别是，我们希望用户能够轻松概念化他们的参数设置将对神经元或突触产生什么影响，而无需具备神经科学背景。

在确定适合 Caspian 的神经元模型时，至关重要的是，该模型既要足够简单易懂，又要计算速度快，便于评估。根据这一标准，我们选择了泄漏积分和触发 (LIF) 神经元模型。由于我们的目标只集中在使用 SNN 进行计算，我们将神经元和突触参数表示为无单位整数。表 1 给出了 Caspian 的默认神经元参数范围。Caspian LIF 神经元中有三个参数：阈值、轴突延迟和泄漏时间常数。阈值表示神经元触发所需的电荷量，是一个非负整数值。轴突延迟参数允许用户指定神经元的输出影响神经元传出突触的时间延迟。泄漏时间常数控制电荷随时间衰减的速率。 Caspian 使用 2−𝑡/𝜏 动态而不是 𝑒−𝑡/𝜏 来评估电荷泄漏，并且 𝜏 的值被限制为 2 的幂。这种设计选择允许在使用基于事件的评估时进行有用的硬件优化

默认的 Caspian 突触参数范围如表 2 所示。Caspian 突触有两个参数：权重和突触延迟。突触权重以有符号整数形式给出。突触权重直接添加到神经元的电荷值中，然后将其与神经元的阈值进行比较。例如，如果突触的权重值为 10，突触的突触后神经元的电荷值为 0，阈值为 5，那么当突触后神经元接收到事件时，神经元的电荷值将增加到 10（大于阈值）并导致该神经元激发。为了灵活地实施算法，我们还包括突触延迟，以便用户可以选择使用突触延迟和/或轴突延迟来延迟通过 SNN 的神经元激发。

我们选择了 Caspian 神经元和突触中阈值、电荷和权重的无单位表示，以抽象出这些动态如何在生物启发式模拟中被捕获的底层细节（其中神经元的阈值可以用电压表示，突触的权重可以用电流表示）。具体来说，我们抽象出这些细节是因为 Caspian 并不是用来模拟生物现实神经元和突触的工具。相反，我们希望让那些不熟悉大脑中神经元和突触运作细节的人能够使用 Caspian 模型。虽然动态被简化了，但它们仍然足够复杂，可以捕捉实现需要类似 LIF 行为的神经形态算法所必需的行为。

# 4. 软件
## 4.1 Network Representation
Caspian 网络表示为有向图，其中节点代表神经元，边代表突触连接。虽然每个神经元都分配有一个唯一的整数标识符，但标识符不需要是连续的序列。为了实现这种灵活性，神经元存储在以其唯一 ID 为键的哈希表数据结构中。然后，每个神经元都有其传入和传出突触连接的邻接列表。目前，每个神经元和每个突触都包含其唯一的参数，但 Caspian 的未来迭代可能会受益于添加参数共享机制，例如对卷积滤波器的显式支持。

Caspian 网络可以序列化为简单的 JSON 文件格式。此格式在开发过程中提供了极大的灵活性和互操作性。只需使用 JSON 库读取或写入网络文件，即可轻松创建外部工具。通过使用 JSON，如果网络较小，文件还可以实现一定程度的可读性。除了 JSON 序列化之外，Caspian 还可以轻松与 Python 中的 networkx 包集成。这在操作 Caspian 网络时提供了广泛的图形相关功能。

## 4.2 Simulation
模拟是 Caspian 平台的重要组成部分，可以实现脉冲神经网络的快速开发和原型设计。==目前，Caspian 提供单线程离散事件模拟，通过硬件实现提供精确的周期精度。==该模拟引擎基于高性能 DANNA2 模拟器 [15] 的原理构建。

模拟的工作原理如下。在模拟调用开始之前，输入触发会排队。对于每个时间步骤，将处理给定步骤的任何内部触发之后的输入。为了处理触发，模拟器会查找目标神经元以及要累积的电荷量。如果这是当前步骤中为目标神经元处理的第一个尖峰，则神经元必须计算任何电荷泄漏。然后，神经元可能会累积传入的尖峰。如果更新后的电荷超过神经元的可编程阈值，则神经元可能会出现尖峰，但直到处理完当前时间的所有尖峰后才能确定这一点。为了处理这种情况，模拟器会跟踪给定步骤中可能出现尖峰的所有神经元，并在发出传出尖峰之前检查步骤结束时的最终电荷。一旦神经元出现尖峰，其电荷就会重置。默认行为是重置为零。然而，Caspian 还支持软重置，它根据神经元的阈值减少电荷，并可能留下残留电荷。

随着进一步发展，Caspian 平台可能支持除当前单线程事件模拟器之外的不同模拟引擎。例如，更大的网络和密集连接的网络可能受益于多线程或基于 GPU 的模拟器。该平台的一个目标是允许这种实现灵活性，同时向最终用户隐藏相关的复杂性。

## 4.3 Programming API
Caspian 的所有性能关键代码都是用 C++ 开发的，以便进行广泛的优化，但与其他机器学习框架类似，主要的开发 API 是基于 Python 的。这提供了一些关键优势。特别是，Python API 允许与各种现有的相关库集成。此外，与基于 C 或 C++ 的 API 相比，它往往更容易使用，原型设计速度更快。

Caspian API 提供多个级别的抽象。用户可以选择实例化 Network 对象并使用函数调用手动添加神经元和突触。这提供了完全的控制权，并促进了非机器学习任务，例如基于脉冲的图形算法 [12, 18]。图 1 演示了使用 Caspian 创建神经元和突触的基础知识。此代码的结果是一个双神经元网络，其中一个输入神经元、一个输出神经元和一个将输入连接到输出的突触。图 2 显示了如何选择模拟前面示例中的网络。可以通过配置软件模拟器或硬件实现来执行网络。然后，用户必须将输入排队到网络并设置运行时间长度。执行后，用户可以自由访问来自任何输出神经元的脉冲数据，包括精确的脉冲时间或仅脉冲计数。虽然这提供了很大的灵活性，但许多用户可能更喜欢直接使用算法级抽象。

一种可用的算法是基于遗传算法的方法，称为 EONS [20]。给定一个适应度函数来评估网络的适用性，EONS 可以确定脉冲神经网络的拓扑和参数。使用 EONS，用户可以训练 Caspian 网络以进行分类和控制风格任务。EONS 产生的网络往往是小型、稀疏连接的网络，非常适合 Caspian 的设计。

Caspian 还支持脉冲反向传播算法 SLAYER。SLAYER 建立在 PyTorch 之上，使用基于脉冲响应模型的自己的模拟引擎。它允许用户训练具有时间动态的深度神经网络。为了使 SLAYER 适应 Caspian，我们添加了一个脉冲响应内核以匹配 Caspian 的神经元模型。我们还加入了权重量化，以生成 Caspian 所需的整数权重。

# 5. 硬件
除了提供软件模拟引擎外，Caspian 还旨在通过相同的 Python API 提供硬件加速后端。与深度学习库以最少的代码更改实现 GPU 加速的方式类似，Caspian 可以提供高级抽象，而用户无需具备任何特定的硬件知识。硬件加速器可以根据所需的用例用于各种目的。==例如，用户可能希望将经过训练的网络部署到边缘应用程序。为此，Caspian 可以提供适合尺寸、重量和功率 (SWaP) 受限环境的小型高效实现。==另一方面，用户可能希望加速 EONS 训练过程，这需要为给定任务运行数千个网络。这样的任务将具有非常不同的要求，并且会优先考虑高吞吐量而不是低 SWaP。

Caspian 旨在提供不同的实现来满足这两组需求。也就是说，==我们正在开发𝜇Caspian，以实现训练有素的脉冲神经网络的高效边缘部署。==我们还有一个扩展到更大实现的路线图，包括一些可以容纳并行运行多个网络或运行由 SLAYER 生成的大型脉冲卷积神经网络的实现。专注于 FPGA 设计，很容易将 Caspian 分发给其他用户，他们只需使用现成的组件就可以利用这项工作。此外，FPGA 允许我们拥有各种设计并以高度自由度迭代这些设计。

## 5.1 𝜇Caspian
𝜇Caspian，或“micro-Caspian”，是一种非常小的 IP 核，适用于最小的 FPGA。我们的主要目标设备是 Lattice iCE40 UP5k，它是一款具有 5280 个 4 输入查找表 (LUT) 和 120 千比特嵌入式块 RAM 的 FPGA [22]。这是一款非常小的 FPGA，因此，它为将 Caspian 集成到系统中提供了一个廉价的切入点。

我们早期实现的这种架构可以支持 256 个神经元和 4096 个突触。每个神经元都可以在突触限制范围内任意连接，并且每个神经元和突触都可以具有独特的独立参数。神经元可能具有 8 位阈值、可配置泄漏和 4 位轴突延迟。每个突触都有 8 位权重，但由于此平台的开销增加，因此不允许突触延迟。由于此 FPGA 尺寸小巧且具有嵌入式特性，我们预计 𝜇Caspian 部署的功耗将在低毫瓦范围内。

==虽然可以通过 Python API 访问和使用 𝜇Caspian，但它的设计确实使得最终用户可以将其作为低 SWaP 神经形态系统集成到他们的整体系统设计中。==在这种情况下，用户要么将 IP 核集成到更大的 FPGA 设计中，要么用户可以将 iCE40 FPGA 以及简单的通信链路（例如 UART）部署到微控制器上。

## 5.2 Future Architectures
除了 𝜇Caspian，我们还计划扩展到更大的架构。我们的目标是适应各种用例。例如，使用反向传播方法训练的网络往往具有大量的神经元和突触，但这些网络也遵循连接模式。通过利用一系列基于 FPGA 的设计，我们可以构建定制的变体来适应这些特征，同时保持通用的神经元模型和通用的编程 API。

未来工作的另一个途径是训练加速器。当使用 EONS 算法解决问题时，必须评估数千个网络。通常，这些网络针对其目标应用在 100 到 1000 个群体中进行测试。大型 FPGA 或多 FPGA 系统可能能够通过许多并行 Caspian 核心同时运行整个群体来加速评估过程。


# 7. 结论
在这项工作中，我们引入了 Caspian 作为面向计算的神经形态平台。我们展示了 Caspian 如何通过默认使用 LIF 样式的神经元模型、通过 Python API 提供不同级别的抽象以及包含高性能事件驱动模拟器，为未来的神经形态开发人员提供简单性和灵活性。此外，我们讨论了基于 FPGA 的硬件实现如何集成到这个生态系统中，从 𝜇Caspian 开始，用于 Caspian 网络的嵌入式部署。我们展示了 Caspian 与两种截然不同的训练算法（EONS 和 SLAYER）的兼容性，并且我们还展示了模拟扩展改进，优于过去基于事件的模拟工作。


---
Caspian 是一个神经形态开发平台，由一个低功耗神经形态处理器和高级 API 组成，可用于为边缘物联网应用模拟小规模 SNN

硬件上
- 正在开发𝜇Caspian，以实现脉冲神经网络的高效边缘部署。

软件上
- 开发了高级 API，使用 Python API 在软件中定义网络大小、连接性和超参数（例如触发阈值、泄漏时间常数、突触延迟和轴突延迟）。
- 提供单线程离散事件模拟。
