开发受大脑启发的神经形态计算架构作为边缘人工智能 (AI) 的范例，是一种候选解决方案，可以满足物联网 (IoT) 应用领域严格的能源和成本降低约束。为了实现这一目标，==我们推出了 µBrain：第一个数字化但完全由事件驱动的无时钟架构，具有共置内存和处理能力，可利用基于事件的处理来降低始终开启系统的总能耗（µW 动态操作）==。40 nm 互补金属氧化物半导体 (CMOS) 数字技术的芯片面积为 2.82 mm2（包括焊盘）（不含焊盘 1.42 mm2）。这种小面积占用空间使 µBrain 能够集成到可重新训练的传感器 IC 中，以执行各种信号处理任务，例如数据预处理、降维、特征选择和特定于应用程序的推理。我们在 40 nm CMOS 数字芯片中展示了 µBrain 架构的实例，并展示了其在基于雷达的手势分类中的效率，功耗为 70 µW，每个分类的能量消耗为 340 nJ。作为数字架构，µBrain 完全可合成，并有助于在专用集成电路 (ASIC) 中实现快速的开发到部署周期。据我们所知，==µBrain 是第一个微型数字、基于尖峰、完全并行、非冯诺依曼架构（没有时间表、时钟或状态机）。出于这些原因，µBrain 具有超低功耗并提供软件到硬件的保真度。µBrain 可在需要依靠电池供电运行多年的物联网传感器节点中实现始终在线的神经形态计算。==

# 1. 介绍
几十年来，大脑中的信息处理一直是研究的热门话题（Cappy，2020）。作为计算基底，大脑结构从工程角度来看令人兴奋。它具有大规模并行性、令人印象深刻的低功耗、可扩展操作，并且内存和计算在同一基底中复用在一起。作为对大脑研究的结果，神经形态计算研究一直在尝试构建受大脑启发的信息处理模型及其相应的硬件实现。

与设计用于执行精确计算的传统计算机架构不同，生物大脑似乎针对存在噪声或不完整输入的信号处理进行了优化。它对损坏和部分故障非常稳健。因此，神经形态计算为执行（统计）信号处理和神经处理任务的算法和计算架构提供了一种替代方案。尽管我们还远未完全理解大脑的功能，但对其运作的研究使我们发现了几个重要的架构特征，我们可以成功有效地将其应用于计算机的硅技术中。

大脑的许多能量和计算效率特征来自其异步和事件驱动操作（Yu 和 Yu，2017），它促进并同时利用稀疏计算。在不可避免的高能耗的传统处理器/加速器架构中，重点是通过增加每单位能耗可能执行的操作数量来最大化效率（和速度）。相比之下，在神经形态架构中，稀疏性利用会导致跳过冗余操作，并且通过直接减少延迟和能耗来实现效率。减少操作意味着神经形态处理器中的计算更少，功率密度更低（即每硅片面积的功率）。此外，异步事件驱动处理允许理论上无限的可扩展性，因为每个神经元都可以独立于其他神经元处理其输入。它还可以让信息尽可能快地流动，从而实现低延迟响应。==在硅片实现中，不需要将动态时钟脉冲路由到每个神经元，因为每个神经元都会立即根据阈值评估其膜电位，而无需全局同步信号（时钟）。==

本文介绍了 ==µBrain，一种用于边缘 AI IoT 应用的超低功耗（<100 µW）神经网络处理的神经形态 IC==。µBrain 采用低成本数字技术，但与大多数其他数字神经形态集成电路 (IC)（如表 2 所示）不同，==它依赖于本地按需振荡器和新型延迟单元，以避免使用全局时钟，并支持事件驱动处理。在没有输入刺激的情况下，µBrain 仅消耗漏电功率，同时保持其内部状态存储在神经元的膜电位、突触权重和网络动态中。此外，µBrain 不利用单独的内存块（无论是片上还是片外内存），但内存和计算在 IC 区域中共存，避免了传统冯诺依曼架构远端内存的数据访问和能量开销。==

数字技术的使用充分利用了可综合性，并为各种物联网应用提供了可靠性。此外，先进工艺节点提供的数字门的高面积效率使模拟神经元的吸引力降低。

µBrain 架构基于分层组织的数字事件型脉冲神经元（也支持循环拓扑）。输入和输出为数字脉冲（速率或时间编码），而突触权重是可编程的，并以可定制的位宽存储在芯片上。根据应用要求，µBrain 架构可以在合成过程中定制位精度、网络拓扑（每层神经元数量和层数）和连接性。相比之下，神经元参数和突触权重是运行时可编程的。

µBrain 在神经形态处理器和加速器领域的应用领域是超低功耗（例如数百 µW）轻量级机器学习数据处理，近传感器或传感器内（我们所说的“传感器内”是指 IC 级集成）。示例目标部署包括雷达信号分类、可穿戴设备上的生物医学信号分析、灯具上的低维图像分类、薄膜电子器件中的音频分析和触觉分析、可摄取传感器上的数据处理以及许多其他物联网应用。


## 1.1 Background and Related Literature
神经形态计算加速器 IC 利用脉冲神经网络 (SNN) 处理，使用状态神经元模型以稀疏异步事件 (脉冲) 的形式交换信息。==最先进的实现基于模拟、数字或混合信号硅技术（例如 Schemmel 等人，2010 年；Qiao 等人，2015 年；Furber，2016 年；Neckar 等人，2018 年），通常与“奇特的”非易失性存储器 (NVM)（Zhang 等人，2018 年）或光子技术（Prucnal 和 Shastri，2017 年）或自旋电子器件（Grollier 等人，2020 年）结合使用。这种广泛的选择范围可以不同程度地模拟真实的大脑结构、集成和特征。==

==模拟神经形态 IC== 比数字 IC 更像生物神经细胞 (Indiveri 等人，2011)。它们模拟钾和钠通道以及 N-甲基-D-天冬氨酸 (NMDA) 受体，具有复杂的动力学。然而，它们存在多变性、设计成本高、灵活性低和神经元密度低的问题。当采用传统硅技术实现时，神经元将其膜电位 (神经元状态) 存储在漏电电容器中，这会占用很大的面积，而模拟突触电路则模拟具有低数字分辨率的可编程突触权重的适应和学习 (Bartolozzi 和 Indiveri，2007)。或者，可以使用密集电阻随机存取存储器 (ReRAM) 交叉开关来建立神经元之间的突触连接 (Liu 等人，2015)。在 ReRAM 交叉开关中，位单元的电阻是连接突触前和突触后神经元的可编程突触权重。由于工艺变化，模拟芯片不能完全再现，并且容易受到温度变化的影响。理论上，可以使用自适应自学习神经元模型和高效的片上自适应/学习机制来补偿变化和噪声（Kuzum 等人，2012 年），从而克服这些变化。然而，这种机制使神经元更加复杂。它们的性能还不够可靠，无法在关键应用中使用这种技术（例如医疗保健、汽车、安全）。模拟方法不适合我们的工作，因为 µBrain 仅针对推理、物联网用例以及利用传感器内处理的简单且经济实惠的可重复性和与其他 IC（例如传感器）的集成。

与模拟电路相比，数字 IC 依靠逻辑门来模拟神经元和突触，并依靠密集内存来存储神经元状态和突触权重 (Frenkel 等人，2018)。这种方法的动机是快速将可合成的架构集成到片上系统 (SoC) 中，从而实现低成本实现。理论上，由于使用逻辑门，这种方法所需的面积可能比模拟芯片更大。然而，使用最先进的技术节点（如 7 nm 及以下）进行数字设计更容易，这可以在合理的功耗下提供更好的密度。==数字设计芯片的一个缺点是将膜电位泄漏作为额外的周期性操作来实现。如果频率足够低，即与输入尖峰速率相同，则此缺点并不那么重要。==除此之外，由于商业电子设计自动化 (EDA) 工具针对同步部署进行了优化，因此实现完全事件驱动的实现并不是一件简单的事情。

同样，在 µBrain 中，我们采用了全数字化方法。但是，我们的泄漏机制是基于事件的，因此不一定需要是周期性的。此外，我们设计了一个轻量级本地振荡器（延迟单元），可以驱动自定时数字块（类似于 Davies 等人，2018 年），以克服电子设计自动化 (EDA) 工具缺乏支持的问题。

在这两种方法的交叉点上，==混合模拟和数字神经形态 IC 可以将模拟电路网络与数字读出层 (Corradi 等人，2019) 或模拟 ReRAM 交叉开关相结合，用于与数字实现的神经元进行突触连接 (Ni 等人，2017)。==在这种情况下，在模拟和数字电路之间的接口处，使用模拟到数字转换器将模拟信号离散化。由于 SNN 中的激活是二进制的（不需要乘法），因此该方法的主要优势是可以在一个存储单元中存储多个位。此外，可以使用电阻式存储单元的物理特性来实现生物启发式学习算法，并且可以促进片上学习。==尽管 µBrain 与非易失性存储器技术兼容，可以替代用于突触权重的分布式存储器（数字触发器），但我们出于前面提到的原因排除了模拟选项。==

由于电子的速度比离子快得多，硅神经元可以比其实时生物等效物快几个数量级地处理脉冲（晶体管的开/关时间为纳秒，而神经元和突触时间常数为毫秒）。这一事实促使神经形态数字 IC 工程师实现==时间复用数字神经形态芯片（Davies 等人，2018 年，Merolla 等人，2011 年）。在数字实现中，可以将处理部分和内存分开。例如，一个物理神经元核心可以模拟许多（虚拟）神经元，一个物理链接可以模拟许多（虚拟）突触连接。==时间复用方法采用快速计算，并不断地将神经元的膜电位移出/移进神经元内存，并将其突触权重从/移出突触内存。此外，这种架构可以承载多神经元核心，每个核心分配一组神经元的模拟，例如一个层，该层可以通过片上网络 (NoC) 以分组交换形式异步交换脉冲；并基于数据包中脉冲的地址事件表示 (AER)。与以前的方法相比，时间复用方法的优势在于更高的神经元和突触密度，并且利用更复杂的神经元模型 [甚至可编程 (Painkras 等，2013)]，但代价是增加内存访问和复杂的数据混洗原语。==时间复用可能不利于超低功耗设计==，因为它需要额外的控制电路，从而增加功耗来管理核心的一致性。此外，与生物神经元相反，内存和计算核心之间的距离会增加功耗。由于每个核心内的事件都是串行处理的，因此在活动高峰期，处理延迟也会增加或无法保证，并可能导致事件丢失（取决于事件队列的深度和占用率）。最后，事件的分组和显式寻址（如 AER 协议）会增加通信开销（功耗），因为在传输过程中排队事件需要额外的地址处理和路由以及内存要求（事件不再是二进制脉冲或直接信号）。==在 µBrain 架构中，我们不会对核心中多个神经元的处理进行时间复用（相反，每个核心专门分配给一个神经元）==，因为对于我们考虑的网络大小，与突触记忆的总面积相比，神经元的总硅面积可以忽略不计。此外，神经元内部不需要基于数据包的事件寻址，但我们选择在芯片与外界接口处进行 AER 通信，以便于与现有的神经形态传感系统集成。

µBrain 区域以内存为主，这不是一个好的特性。然而，µBrain 需要分布式内存，并促使人们寻找替代静态随机存取存储器技术的内存技术。许多新型内存技术目前正在研究作为神经形态技术的候选解决方案，==例如相变存储器 (PCM) (Nandakumar 等人，2018 年)、电阻开关存储器 (RRAM) (Indiveri 等人，2013 年)、电化学金属化存储器 (ECM) (Hao 等人，2021 年)。因此，我们的架构并不专注于内存方面，因为它可能很快就会被一些新技术取代。==

# 2. Materials and Methods
## 2.1 Event-Based Architecture
图 1A 概述了 µBrain 架构的主要构建块及其交互。基于事件的 IF 神经元排列在分层群体的完全并行拓扑中，这意味着每个神经元都是在硅片中物理实现的（不是时间复用的）。在每一层中，可能存在横向突触连接（可以利用循环连接）。每个神经元独立地（没有全局时钟）累积加权传入的突触尖峰，并在神经元的累加器溢出时发出尖峰。输入尖峰触发膜电压积分，并立即进行阈值评估，从而产生分布式粒度激活。由于输入脉冲在神经元层之前异步到达，因此如果尖峰同时到达，事件仲裁器会解决任何排序冲突。突触权重具有固定的位宽（在合成时确定），表示 2 的补码整数量化值，范围为 [−2W−1 − 1, +2W−1 − 1]，其中 W 表示位数。对于给定的位宽，量化权重值的范围可以线性或对数排列（已考虑后一种情况，因为精度对于较小的权重值通常更为关键）。

# 3. Results
本节介绍在 40 nm 技术节点上对 µBrain IP 实例的评估。为了将 µBrain 与其他微型脉冲神经网络处理器进行比较，我们执行了手写数字识别 (MNIST) 的标准基准测试。我们还展示了 µBrain 在执行基于雷达的手势分类任务时的功能。

# 4. Discussion
==本文介绍了 µBrain，一种用于物联网领域超低功耗应用的轻量级神经形态推理引擎。==当输入信号具有高度稀疏性（时间、低速率）时，它可以替代神经网络加速器，从而降低功耗。==现成的边缘推理深度学习加速器，例如 Google EdgeTPU（Cass，2019 年）、Intel Movidius（Ionica 和 Gregg，2015 年）和 Nvidia Jetson（Mittal，2019 年）每瓦执行的操作数量具有竞争力。但是，它们无法有效利用信号的稀疏性来扩展其能耗。这意味着当输入信号非常稀疏时（例如，音频/视频/EEG 等自然信号），它们最终会执行大量冗余操作，这些操作可以跳过。例如，当稀疏度高于 95% 时，需要的操作不到 5%，其余的只是开销。==在深度学习算法中，实现超过 70% 的激活稀疏度，同时保持 2% 以内的准确率是一项挑战 (Wen et al., 2016; Kurtz et al., 2020)。相比之下，在 Yin et al. (2020) 中，SNN 架构实现了非常高的时空稀疏度（超过 95%），而准确率损失可以忽略不计。

与许多典型的边缘 AI ANN 加速器相比，==µBrain 本质上利用了所有类型的稀疏性（空间、结构和时间）来实现其超低功耗信号处理任务。==空间和时间稀疏性与神经元激活有关，而结构稀疏性与突触权重有关。==µBrain 通过以真正的事件驱动方式运行来利用空间稀疏性：仅对输入的非零部分进行计算，并且仅当非零激活通过网络传播时，网络的所有其他横向部分保持沉默以节省能源。它还利用了时间稀疏性，因为它使用有状态的神经元：每个神经元中的记忆潜能都在整合其输入的变化，因此只有当后续输入之间存在变化时，状态才会更新，并且只有当输入中存在足够多的变化（水平交叉）时，神经元才会触发并激活其他下游神经元。在没有任何输入尖峰的情况下，下游没有任何活动（节省能量），直到空间或时间发生变化（尖峰）。最后，结构稀疏性在合成时可在 µBrain 中编程。假设一个模型具有修剪的网络拓扑。在这种情况下，µBrain 可以合成具有减少的突触连接，从而节省面积和静态功率以维持权重内存，否则在运行时会将其设置为零（完全连接的交叉开关架构中的开销）。==为了展示减少尖峰活动（动态功率）和突触连接（静态功率）所带来的相关能源成本和节省，在 MNIST 用例的拓扑结构（第 3.2 节）中，我们平均测量每个分类 11,500 个尖峰（每个图像 6,400 个输入刺激），其中 µBrain 每个尖峰消耗约 26pJ（包括通信、神经元积累和突触读取），其中 30% 是静态功率3。减少网络连接（结构稀疏性）或提高网络速度可线性降低因泄漏而消耗的静态功率。增加神经元参数中的阈值（时空稀疏性）也会降低动态功率。


==µBrain 利用了三种类型的稀疏性：
- 以事件驱动利用空间稀疏性
- 时间稀疏性
- 结构稀疏性

µBrain 不足之处静态功耗
==数字神经形态芯片和 µBrain 的设计面临的一大挑战是静态功耗（泄漏功率）。虽然架构设计为具有事件驱动的动态功耗（仅在发生事件时消耗动态功率），但静态功率没有控制。==由于架构区域主要由内存组成，==因此大部分静态功率都用于保持基于触发器的内存处于活动状态。==但是，可以从各个层面解决这一挑战，例如使用全耗尽绝缘体上硅 (FDSOI)（Carter 等人，2016 年）制造技术、先进的非易失性存储器技术（Burr 等人，2017 年）、数字设计技巧（例如，在没有输入时进行功率门控）以及在合成时修剪不需要的突触连接（如上所述）。

乍一看，µBrain 的另一个限制是使用 Integrate-and-Fire (IF) 神经元。然而，神经元之间存在循环突触连接，神经元中没有泄漏可能会被视为不必要地限制循环网络架构的有效性。然而，在实践中，情况恰恰相反。很容易在细粒度神经元级别引入泄漏（不同的泄漏函数和每个神经元的不同参数）；为此目的，牺牲一个神经元的输入。这种选择主要是出于 µBrain 主要用于实验目的的预期用途。

最后，µBrain 架构的一个当前不便之处在于，延迟单元（关键组件之一）在移植到不同的制造技术时需要重新定制。此外，虽然在功耗和面积方面采用小节点技术具有优势，但延迟单元的速度在实践中将保持不变。虽然这是一个小麻烦，但它与完整数字设计中的可合成性所提供的一般设计可移植性略有不同。

## 4.1 µBrain and Low-Power Neuromorphic Devices
最近还开发了其他几种超低功耗神经形态处理器。表 2 将我们提出的架构与其他最先进的神经形态架构进行了比较，这些架构的功耗报告为 <120 mW。其中，µBrain 实现了具有竞争力的每次预测能耗（308 nJ/MNIST 分类），同时又不影响准确性。==它是一种完全事件驱动的设计（即，在没有输入的情况下仅消耗泄漏功率），并且完全可合成。==

![[Pasted image 20241206215011.png]]
µBrain 应归类为小型神经形态处理器。与功耗为几毫瓦的大型处理器（如 Davies 等人，2018）不同，像 µBrain 这样的小型处理单元仅消耗几微瓦，因此可以与电池供电的常开设备集成（例如，可穿戴或植入式设备）。此外，这些处理器可以与传感器集成，以构建高效的传感器处理器片上系统 (SoC)。

Frenkel 等人 (2018) 设计并实现了一个 256 神经元处理器，该处理器具有在线学习能力，并在单个物理神经元核心中对整个拓扑进行时间复用。此设计中的神经元完全连接（256 × 256 个突触），这允许任意拓扑。==但是，这种大量的突触连接对于许多应用程序来说是不必要的开销。在 µBrain 中，我们的方法是牺牲运行时灵活性来提高效率。因此，我们决定执行映射合成共同优化。在合成和制造芯片后，在 µBrain 中，只能修改 SNN 的突触权重，而不能修改主要配置（突触连接）。这节省了大量面积，并允许为目标应用程序（例如，与雷达传感器集成时）高效地实现处理单元。

此外，与 Frenkel 等人 (2018) 以及 Davies 等人 (2018) 相比，µBrain 不会对神经元核心中的神经元进行时间复用，这利用了内存和计算的共定位（以改善延迟和能耗）。

Park 等人 (2019) 还提出了一种时钟控制的 SNN 架构处理器，但该处理器的功耗超过 20 mW，不能用于始终开启的电池供电应用。与这项工作和 Frenkel 等人 (2018) 相比，µBrain 不使用固定时钟频率，这使其对于基于事件的应用程序更有效率。与其他事件驱动的 ASIC（如 Davies 等人 (2018)）相比，µBrain 的浅层处理管道允许轻量级振荡器在每个事件到达时仅产生几个脉冲。

Moradi 等人 (2017) 提出了一种模拟神经形态处理器。尽管模拟设计比数字设计具有明显的优势，但它不易与其他数字单元（例如传感器）集成和合成，因此与我们提出的解决方案不同。正如我们之前讨论的那样，模拟设计也容易受到制造变化的影响，这使得其在软件中的模拟和训练变得困难。对于医疗保健等关键应用来说，使用它具有挑战性。尽管如此，µBrain 通过采用无时钟架构（真正的事件驱动）并在同一芯片中共定位计算和内存，尽可能接近模拟设计。