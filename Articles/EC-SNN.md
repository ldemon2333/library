深度脉冲神经网络 (SNN) 是一种高级 SNN 形式，以其多层结构为特征，近年来在各个领域的性能上取得了重大突破。SNN 的生物学合理性和能量效率与边缘计算 (EC) 场景的要求自然契合，从而引起了研究人员对将这些深度 SNN 模型迁移到传感器和智能手机等边缘设备的兴趣。然而，由于模型参数的大幅增加以及实际应用中苛刻的计算要求，迁移工作的进展尤为艰难。在本研究中，我们提出了一个名为 EC-SNN 的深度 SNN 拆分框架，用于在边缘设备上运行复杂的 SNN 模型。我们首先将完整的 SNN 模型划分为较小的子模型，以便在多个边缘设备上分配它们的模型参数。然后，我们提出了一种通道剪枝方法来减小每个子模型的大小，从而进一步降低计算负载。
我们在六个数据集（即四个非神经形态数据集和两个神经形态数据集）上进行了广泛的实验，以证明我们的方法可以显著减少边缘设备的推理执行延迟，并降低每个部署设备的整体能耗，平均分别降低60.7%和27.7%，同时保持准确率的有效性。
![[Pasted image 20250702162742.png]]


# 3 Methodology
## 3.1 Design Overview
为了处理多类别分类任务，大型​​ DNN 模型，尤其是 CNN 模型 [Sengupta et al.,
2019]，在实际应用中表现良好。类似地，深度 SNN 模型依赖于复杂的网络结构和大量的参数训练来提升其性能。然而，这种原始的 SNN 模型难以部署，尤其是在资源受限的边缘设备上。为了解决这个问题，我们提出利用 SNN 的特性以及多个边缘设备的协作。具体而言，我们方法的核心思想是将原始 SNN 模型拆分为多个特定于类别的子模型，这些子模型既满足资源受限的限制，又能充分利用多个可用设备。

我们考虑一个分类系统，它包含 N 个用于感知的边缘设备和一个用于分类结果的聚合服务器。图 1 概述了我们提出的方法的工作流程：基于脉冲神经网络的边缘协作 (EC-SNN)，它主要包含四个部分：脉冲模型训练、模型分裂、模型剪枝和融合推理。在脉冲模型训练中，我们训练并将传统的 CNN 模型转换为深度 SNN。在模型分裂中，我们将深度 SNN 模型拆分为包含类别子集的子模型。为了减少计算开销，我们在模型剪枝过程中对子模型进行剪枝。最后，我们将子模型分配到相应的边缘设备上，同时聚合服务器融合提取的特征以获得最终的推理结果。每个部分的细节如下。

## 3.2 Spike-wise Model training
与传统的 CNN 模型不同，卷积脉冲神经网络 (CSNN) 使用脉冲神经元代替 ReLU 激活层，并以相同强度进行再训练 [Deng and Gu, 2020]。CSNN 消除了所有偏差成分，并强烈建议采用平均策略进行池化操作，以模拟神经细胞的行为，整合所有感知到的信息，从而释放脉冲并增强生物逼真度。

在本研究中，我们使用泄漏积分激发 (LIF) 模型 [Gerstner and Kistler, 2002]（该模型是最有前景的脉冲神经元模型之一）来构建 CSNN，因为它计算成本低且具有生物合理性。LIF 神经元并非像人工神经元那样直接将加权输入的总和传递给激活函数，而是利用泄漏随时间对输入进行积分。当积分超过阈值时，神经元会发出一个脉冲 [Eshraghian et al., 2023]，即一个离散事件。这些神经元抽象了各层之间脉冲的分布，因此传输的信息存储在脉冲的频率中，而不是脉冲本身，这也称为时间信息浓缩 [Kim et al., 2023]。
与传统人工神经元相比，这种独特的信息传输方式导致了 CSNN 的节能优势。

## 3.3 Model Splitting
在传统的 CNN 中，每个滤波器在学习和推断特定类别时都有其独特的作用 [Wang et al.,
2020]，这为将原始的 CSNN 模型拆分为多个特定类别的 CSNN 子模型提供了思路。每个子模型都经过精心设计，仅包含与其负责的类别相关的必要滤波器。如算法 1 所示，每个 CSNN 子模型都会根据阈值 ζ 及其对应的类别进行剪枝，并遵循相对公平的工作负载分配。随后，启动贪婪搜索机制，在考虑能耗和内存限制的情况下，识别最适合部署特定子模型的边缘设备。如果未找到合适的设备，则采用迭代方法微调阈值并重复分配过程，直到所有子模型都成功分配到边缘设备上。

![[Pasted image 20250702125646.png]]

