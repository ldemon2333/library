# 摘要
脉冲神经网络 (SNN) 因其生物学上的合理性和提高计算效率的潜力而受到越来越多的关注。为了匹配 SNN 中的高时空动态，神经形态芯片非常需要直接在基于硬件的神经元和突触电路中执行 SNN。本文介绍了一种名为 Darwin3 的大规模神经形态芯片，它具有新颖的指令集架构，包括 10 条主要指令和一些扩展指令。它支持灵活的神经元模型编程和局部学习规则设计。Darwin3 芯片架构采用创新的路由算法设计成计算节点网格。我们使用压缩机制来表示突触连接，大大减少了内存使用量。Darwin3 芯片支持多达 235 万个神经元，是神经元规模上同类芯片中最大的。实验结果表明，Darwin3 的代码密度提高了 28.3 倍，通过连接压缩，神经元核心的扇入和扇出与物理内存深度相比分别提高了 4096 倍和 3072 倍。我们的 Darwin3 芯片在将卷积脉冲神经网络映射到芯片上时还节省了 6.8 倍到 200.8 倍的内存，与其他神经形态芯片相比，在准确率和延迟方面表现出了最先进的性能。

# 介绍
脉冲神经网络 (SNN) 因其能够以高效的事件驱动方式处理时空信息而受到研究人员的广泛关注。为了充分利用 SNN 的功能，已经引入了多个脉冲神经网络模拟平台，例如 Brian2 [1]、NEST [2] 和 SPAIC [3]。然而，这些平台依赖于使用大量 GPU 和 CPU 资源来模拟具有大量时间步骤的脉冲动态，这可能会削弱 SNN 的内在优势。神经形态芯片旨在高效执行脉冲神经网络，这些网络在脑模拟和特定的超低功耗场景中表现出良好的性能。然而，一些限制阻碍了它们充分利用脉冲神经网络的优势。为了更好地利用 SNN 模型的优势，我们在设计神经形态芯片时应该强调以下三个方面。

**神经模型的灵活性**。神经形态芯片的关键功能之一是模拟不同的生物神经元和突触。然而，许多神经形态芯片仅支持单一类型的神经元模型，如基于模拟神经元电路的 Neurogrid [4] 等平台就是明证。一些研究引入了一定程度的可配置性，以适应各种神经元模型。Loihi [5] 通过可配置的跟踪和延迟集实现了增强的学习能力。FlexLearn [6] 构想了一种多功能数据路径，融合了不同模型的关键特征。此外，人们还努力使用指令开发完全可配置的神经元模型。SpiNNaker 的多核处理器 [7] 基于传统的 ARM 内核，提供了显着的灵活性。然而，与其他加速器相比，它的性能和能效有所降低。 Loihi2 [8] 提出了一种指令集，其中包含类似于精简指令集计算机 (RISC) 指令的逻辑和数学运算。然而，为传统神经网络设计的指令集尽管具有灵活性，但对 SNN 来说效率不足。

**突触密度**。为了进一步释放 SNN 的潜力，神经形态芯片需要支持具有更复杂拓扑的大规模 SNN 的表示 [9]。然而，目前的神经形态芯片对这方面的关注较少，主要集中在模拟神经元和突触的行为上。例如，TrueNorth [10] 采用交叉设计进行突触连接，但其扇入/扇出容量有限且固定。Loihi [5] 采用轴突索引来编码拓扑的方法，从而增强了灵活性。Loihi2 [8] 提出优化卷积和分解连接，但对其他连接类型的关注较少。Unicorn [11] 引入了一种合并来自多个核心的突触以扩展单个核心的突触规模的技术。因此，在有限的存储条件下提高各种拓扑的突触密度对于优化芯片的成本效益至关重要。

**片上学习能力**。学习能力是生物神经网络的关键特性。目前，只有少数神经形态芯片支持片上学习。其中，支持的学习规则相当有限。例如，BrainscaleS2 [12] 仅适应固定的学习算法。Loihi [5] 支持用于前、后和奖励轨迹的可编程规则。Loihi2 [8] 扩展了其应用于前、后和广义“第三因素”轨迹的可编程规则的功能。然而，即使 Loihi2 [8] 表现出增强的灵活性，它也无法容纳可能出现的新学习规则。电化学存储器阵列领域的最新研究成果 [13] 也提供了新的参考解决方案。 

在本文中，我们设计了一种具有领域特定指令集架构 (ISA) 的大规模神经形态芯片，名为 Darwin3，以支持芯片的模型灵活性、系统可扩展性和片上学习能力。Darwin3 是我们 Darwin [14] 系列神经形态芯片的第三代，该芯片于 2022 年 12 月成功流片并点亮。我们的主要贡献如下：

- 我们提出了一种用于神经形态系统的领域特定 ISA，能够有效地描述各种模型和学习规则，包括integrate-and-fire 系列 [15]、Izhikevich [16] 和脉冲时间依赖性可塑性 (STDP)[17] 等。所提出的架构在计算操作期间实现高并行性方面表现出色，包括加载参数和更新状态变量（例如膜电位和权重）。

<font color="green">神经模型的灵活性，能解决各种模型和学习规则是如何做到的，所有神经元模型都使用微分方程组，对参数方程的共同特征总结，构建一个共性的电路，来构建更复杂的模型。</font>

- 我们设计了一种新颖的机制来表示SNN 的拓扑结构。该机制有效地压缩了描述突触连接所需的信息，从而减少了总体内存使用量。

本文的结构如下。首先，我们介绍主题并简要概述文章的内容。其次，我们介绍了神经形态计算领域特定的 ISA。然后，我们提供了神经形态芯片的总体架构和每个部分的实现，包括神经元节点的架构和拓扑表示机制。最后，我们展示了实验结果。

# THE DARWIN3 DOMAIN-SPECIFIC ISA 
## Model abstraction of neurons, synapses and learning
在计算神经科学领域，提出了许多神经元模型。The leaky integrate-and-fire (LIF) 家族 [15,18–20] 是一组脉冲神经元模型，可以用一维或二维微分方程描述，并广泛应用于硬件加速器。这些模型已被开发用于许多实际应用。霍奇金-赫胥黎模型 [21,22] 被认为具有生物学合理性，并能用四维微分方程准确捕捉神经元行为的复杂性，这些四维微分方程表示离子在神经元膜上的转移。然而，这种模型会导致非常高的计算成本。Izhikevich 模型 [16] 专门设计用于复制霍奇金-赫胥黎模型中观察到的bursting和spiking行为，用二维微分方程表示。

所有这些神经元模型都使用微分方程组表示，其中仅在方程数量以及每个方程中的变量和参数上发生变化。解决它们所需的主要运算符是相同的。<font color="green">因此，识别复杂 LIF 模型所共有的共同特征并通过引入额外的状态变量和计算步骤来利用它们构建更复杂的模型是一种实用的方法</font>。我们选择了adaptive leaky integrate-and-fire 模型 [20] 作为基线，具有相对更多的变量和参数。从数学上讲，它可以用以下方程组来表示，这些方程捕捉了模型的动态及其适应性：

![[Pasted image 20241026103748.png]]

这里，$v_m$ 为膜电位，$τ_m$ 为膜时间常数，$E_L$ 为泄漏反转电位，$g$ 为突触电导，$v_{adp}$ 为适应电流，$τ_{adp}$ 为适应电流的时间常数，$a$ 为对膜电位亚阈值波动的敏感度，$b$ 为尖峰产生的 $v_{adp}$ 增量，$v_0$ 为尖峰后的复位电位，$I$ 为突触尖峰电流。

与具有不同计算复杂度的各种神经元模型设计类似，也存在多种突触模型，例如 delta 和 alpha 突触模型[23]。一种复杂且常用的模型是基于电导的 (COBA) 双指数模型[23,24]，其公式为:
![[Pasted image 20241026104258.png]]
其中 $δ$ 是时间 $t_0$ 处的脉冲，$h$ 是离子通道的门控变量，$g$ 是突触电导，$τ_{decay}$ 是突触衰减阶段的时间常数，$τ_{rise}$ 是突触上升阶段的时间常数，$I$ 是突触脉冲电流，$v_m$ 是膜电位，$E_L$ 是leaky reversal 电位。COBA 双指数模型的计算复杂度与 (1) 相似。我们选择此模型作为我们的代表性突触模型。

突触可塑性 [25]，即突触改变其强度的能力，最早由 Donald Hebb [26] 提出作为学习和记忆的一种机制。此后，人们提出了许多学习规则。STDP 规则 [17] 及其变体是最广泛使用的。一个相对复杂的变体考虑了三重态 [27] 相互作用，并受到奖励调节 [28]。我们选择该模型作为基线，通过选择不同的状态变量和参数，同一组方程可以描述大多数 STDP 及其变体规则。该规则可以用数学形式表示为:
![[Pasted image 20241026104915.png]]

其中 $x_0$ 是突触前脉冲踪迹，$y_0$ 是第一个突触后脉冲踪迹，$y_1$ 是第二个突触后脉冲踪迹，$r$ 是调节突触踪迹的奖励，$τ *$ 是 $x_0、y_0、y_1$ 和 $r$ 的时间常数。

方程 (1)–(3) 描述了三个代表性模型。要使用数字电路实现这些模型，我们需要将微分方程转换为离散形式。通过应用欧拉方法，方程 (1) 变为

![[Pasted image 20241026105224.png]]
方程（2）变为：
![[Pasted image 20241026105613.png]]
其中 $p_0, …, p_7$ 为固定系数参数，而 $c_0, …, c_2$ 为常数。类似地，方程 (3) 变为:
![[Pasted image 20241026105848.png]]
![[Pasted image 20241026105858.png]]
其中 $P^∗_0 ,... , P^∗_6$ 为固定系数参数而 $C^∗_0 ,... ,C^∗_3$ 为常数。

公式 (4)、(5) 和 (6) 表明，复杂的 LIF 模型和 STDP 变体都可以表示为涉及多个乘法和加法运算的多项式。为了在数字电路中实现这些多项式计算，我们将它们映射到相应的数据路径以进行进一步分析。图 1a-c 说明，公式 (4) 中的 $v_{adp}$ 和 $v_m$ 以及公式 (6) 中的 $w$ 的数据路径几乎相同，只是来自选择器和输入源的控制信号不同，这使我们能够使用统一的数据路径在电路中有效地实现这些计算，其中参数可以静态预先配置，并且状态变量会随着时间的推移不断更新。对于更复杂的情况，例如 Izhikevich 模型 [16]，在计算过程中乘以状态变量的参数也是状态变量。因此，我们得到了图 1d 所示的统一数据路径。

![[Pasted image 20241026110216.png]]


## The proposed Darwin3 ISA
为了有效地管理数据路径并最大限度地提高性能和并发性，设计一个高效的控制器至关重要。首先，我们将状态变量和参数映射到一组寄存器中，如表 1 所示。它涵盖了与神经元和突触相关的状态变量和参数，其中常量是静态参数。为了为用户提供实现不同模型的灵活性，我们提出了一种专门的 ISA，如表 2 所示。
![[Pasted image 20241026111246.png]]

![[Pasted image 20241026111422.png]]

该 ISA 的核心原则是将常见操作合并为一条指令，同时考虑到 SNN 的计算特性。这样做不仅可以减少指令所需的内存使用量，还可以最大限度地减少计算过程中指令解码所需的时间。我们定义了表 2 中列出的一组指令。该指令集包含 10 个主要命令。第一组侧重于加载和存储操作，包括 LSIS、LDIP、LSLS 和 LDLP。具体而言，LSIS 和 LSLS 适用于并行执行的推理和学习过程的状态变量的加载或写回。另一方面，LDIP 和 LDLP 分别用于并行加载推理和学习阶段的参数。

第二组专门用于更新状态变量，包括 UPTIS、UPTVM、UPTLS、UPTWT 和 UPTTS。其中，UPTIS 更新状态变量，不包括膜电位。UPTVM 专门用于调整膜电位。UPTLS 强调特定于学习阶段的状态变量，而 UPTWT 管理突触权重的调整。UPTTS 监督临时状态变量的更新。最后，GSPRS 指令专用于生成脉冲。通过这些指令，我们可以有效地管理计算单元并支持构建灵活 SNN 模型所需的过程。

AdEx [20] 和 HH [21] 等模型需要复杂的运算，包括指数和除法函数。表 2 中列出的指令不直接支持这些运算。该设计使用户能够使用移位、乘法和查找表等计算单元执行除法和指数运算，从而节省硬件资源。因此，我们在我们的指令集中添加了几个通常在精简指令集架构中找到的指令，如表 3 中所述。

<font color="green">tips： 对于指数和除法运算，硬件使用软件操作替代</font>

![[Pasted image 20241026112645.png]]
在表 4 中，我们提供了一系列超出基本加载和存储操作的代码示例，以说明所提出的 ISA 的有效性。此选择表明，简单的 LIF 模型和更复杂的三重 STDP 规则可以用最少的指令简洁地表示。此外，诸如 SDSP [29] 之类的专用规则可以通过战略性指令组合进行有效编码。这种多功能性凸显了我们的指令集设计的高度灵活性和有效性，使其成为研究人员和开发人员在 SNN 中实现各种模型的可行工具。

![[Pasted image 20241026113315.png]]

# DARWIN3 芯片架构
## Overview
Darwin3 芯片架构的特点是计算节点的二维网格，形成一个 24 × 24 的网格，通过片上网络 (NoC) 互连，如图 2a 所示。位置 (0,0) 处的节点具有用于芯片管理的 RISC-V 处理核心，而其他节点则充当神经元核心，处理大部分计算，每个节点最多支持 4096 个脉冲神经元。芯片间通信模块位于与外围路由器连接的芯片的四个边缘，充当压缩和解压缩单元。这种设计使 NoC 能够在所有四个基本方向上扩展与其他芯片的连接，从而增强系统的可扩展性。


![[Pasted image 20241026162709.png]]

本研究实现了低延迟 NoC 架构，该架构采用了 [31] 中详述的 XY 路由。通过集成 CXY [32] 和 OE-FAR [33] 路由策略来解决拥塞问题，进一步改进了设计。此外，本研究还引入了一种新的路由算法，该算法使用源地址和目标地址之间的相对偏移量作为其路由方案的基础。这一战略决策简化了数据包传输到相邻芯片的过程，从而无需复杂的路由协议和地址转换。

图 2 中用绿色圆圈表示的异步通信接口将本地同步模块互连，从而将 Darwin3 建立为全局异步本地同步系统。这增强了芯片上每个节点在高性能水平上独立运行的能力。

## Architecture of neuron cores
图 2b 所示的神经元核心架构由五个组件组成：控制器单元、模型执行单元、时间管理单元、寄存器和内存单元以及尖峰事件处理单元。

控制器单元负责获取、解码和执行流控制。模型执行单元可以执行各种算术和逻辑运算。如表 1 所定义，寄存器存储状态变量、参数、常量和临时变量。

时间管理单元有两个主要职责。首先，它根据全局时间步长信息生成内部tick 信号，指示核心内时间步长的进展。其次，它根据配置信息为 1-4096 个逻辑神经元实现时分复用。

<font color="green">4096个逻辑神经元的实现通常涉及硬件虚拟化和时间分割复用（TDM）。通过这种方法，多个逻辑神经元共享同一物理硬件资源，但在不同的时间片上交替使用。这种设计能够有效地增加神经元的数量，同时保持资源利用率。</font>

每个神经元核心都有用于存储不同内容的内存，例如轴突输入、轴突输出、神经元状态变量、突触状态变量和指令。指令仅用于描述神经元和突触的工作方式。神经元的 ID 决定了指令和相关状态变量的地址。轴突输入和轴突输出的内存存储神经元的连接方式，其组织如图 2d 所示。当芯片启动时，我们需要设置工作节点的内存。配置数据将通过芯片间通信模块从外部控制器（例如 PC 或现场可编程门阵列 (FPGA)）传输到相应的节点。

与使用时钟在每个周期获取指令的传统处理器不同，Darwin3 的神经元核心由脉冲事件驱动。当一个神经元获得一个脉冲时，地址事件表示 (AER) IN 会查询相应的轴突输入条目以查找神经元 ID 和权重，计算状态变量 h。当时间步长推进时，控制器单元会根据指令对每个神经元的推理或学习阶段执行计算。如果一个神经元发出一个脉冲，AER OUT 会从轴突输出获取突触后神经元的地址和 ID，并将其打包在脉冲数据包中。

图 2b 中的虚线说明了神经元核心接收、处理、生成和传输脉冲的过程。乘法运算需要两个周期，而加法运算需要一个周期。例如，常用的 LIF 神经元模型需要四个周期（<font color="red">??两个乘法和两个加法运算）</font>，而 CUBA Delta 模型需要三个周期（一个乘法和一个加法运算）。传输延迟表示为 2N + 2(N + 1)，其中 2N 表示通过 N 个路由器的延迟，2(N + 1) 表示通过突触前和突触后神经元之间的 N + 1 个异步互连的延迟。

图 2c 显示了基于所提出的 ISA 为推理和学习量身定制的架构。在推理模式下，控制器单元更新当前时间步骤内由指令描述的每个神经元的状态变量。在学习模式下，控制器单元提取学习参数和状态变量以执行必要的计算和更新，计算新的权重。axon-in 内存区域已重新配置为容纳与学习相关的参数和状态变量，以优化硬件资源。

传统的冯诺依曼架构与上述神经元核心的架构存在几个关键区别：

1. **数据与指令分离**：
   - 冯诺依曼架构中，数据和指令存储在同一内存中，通过程序计数器顺序执行指令。
   - 神经元核心采用事件驱动的方式，脉冲信号触发神经元的计算，数据流动不依赖于时钟。

2. **执行方式**：
   - 冯诺依曼架构依赖于周期性的时钟信号，逐条取指令并执行。
   - 神经元核心通过脉冲事件驱动计算，允许更高效的并行处理，减少延迟。

3. **处理单元**：
   - 在冯诺依曼架构中，处理单元（CPU）通常是通用的，设计用于执行广泛的操作。
   - 神经元核心则专为模拟生物神经元而设计，支持特定的算术和逻辑操作，适合神经网络的需求。

4. **内存管理**：
   - 冯诺依曼架构通过统一的内存管理处理数据和指令，可能导致“冯诺依曼瓶颈”。
   - 神经元核心采用分散的内存管理，专门针对神经元和突触状态进行优化，提升了存储效率和访问速度。

5. **可扩展性**：
   - 冯诺依曼架构在扩展时通常需要增加更多的CPU或内存。
   - 神经元核心通过时间分割复用和硬件虚拟化，可以在现有硬件上模拟更多的逻辑神经元，提升系统的可扩展性。

## Representation of neuronal connections
灵活的连接表示机制对于开发能够支持复杂网络的神经形态计算芯片至关重要。几种连接拓扑在 SNN 中经常应用。
（1）多个神经元组连接到一组神经元，类似于具有共享权重的卷积神经网络 (CNN) 排列。
（2）单个神经元连接到整个神经元组。
（3）一组神经元完全连接到另一组神经元。

在全面检查了常用的连接表达机制（如表 5 所示）后，我们发现 Loihi [5] 使用的方法以其出色的灵活性脱颖而出，具有强大的扇入和扇出功能。结合这些有利属性，我们引入了一种新颖的方案，可以高度压缩地表示连接拓扑，如图 2d 所示。为了有效地表示连接的拓扑结构，每个神经元核心在这个框架内都有独立的轴突输出和轴突输入存储器。

脉冲通过 AER 方法传递。突触前神经元产生脉冲后，访问轴突输出 (axon-out) 以获取目标节点的地址和目标节点的轴突输入 (axon-in) 索引信息。随后，AER OUT 模块封装并通过本地连接端口将此信息传输到路由器。路由器依次将数据包定向到指定的目标节点。在接收到数据包后，目标节点查询轴突输入 (axon-in) 以获取有关目标神经元和连接权重的相关信息。

在轴突输出结构的框架内，每个操作神经元都与一个链接器相关联。链接器的条目保留包含详细连接信息的条目的地址和神经元的特定索引。此索引区分了多个神经元连接到同一目标节点的情况。这种结构配置优化了超出点对点场景的连接类型的信息压缩。
<font color="red"> 该linker就代表了整个网络的拓扑结构，整个网络有（[（24X24）-1]X4096）节点，该linker类似于网络的邻接表，那么问题是这个linker是如何初始化的，后续进行压缩，或者说，我们如何已知整个网络的拓扑结构，还有网络权重是如何初始化的？这个linker是否存在于每个core中的 axon-out，axon-in，如果是，为什么不设计一个共享内存，将这个全局拓扑信息linker存储在这，并且linker只能读不能写，也不存在读写一致性问题了。这样内存开销能更小。 </font>
![[Pasted image 20241026171839.png]]

 - 当一个神经元连接到多个节点时，last flag 设置为 0，表示非终端节点，并有助于高效压缩冗余信息。如图 2d 所示，这种情况用 1# 表示。
 - 当多个神经元连接到同一个节点时，单个条目就足以提供它们的连接信息。如图 2d 所示，这种情况用 2# 表示。
<font color="red">这个fan-in与fan-out 优化是在做什么，和linker 有什么联系。通过压缩linker表，最终使得core的输入与输出管脚变得少，但能驱动的其他core的数量尽可能变多？</font>

每个接收到的轴突索引都与轴突结构上下文中的相应链接器对齐。链接器中的条目封装了条目的地址，包含详细的连接信息和连接类型。此结构经过战略性设计，可优化信息压缩，特别适合超出点对点场景的连接类型。

- 当节点内的所有 4096 个神经元都连接到一个突触前神经元时，无需单独存储神经元索引。在这种情况下，可以按顺序存储 4096 个权重。如图 2d 所示，这种情况表示为 1*。
- 在多个神经元连接到节点内的特定神经元并共享相同权重的情况下，存储单个神经元索引以及相应的权重就足够了。如图 2d 所示，这种情况表示为 2*。
- 当远程集群中的神经元连接到目标节点内的一组神经元时，只需要有一个神经元索引实例，并且可以根据源神经元的顺序系统地存储权重。如图 2d 所示，这种情况表示为 3*。
- 当目标神经元按顺序排列时，仅存储初始神经元的索引和目标神经元的数量就足够了，从而进一步减少存储需求。如图 2d 所示，情况表示为 4*。

这种结构还有利于合并具有不同位宽的权重，从而允许在共享条目中容纳不同的权重，从而提高存储密度。

<font color="green">映射ANN中神经元连接的拓扑结构方法和压缩存储</font>

# EXPERIMENTAL RESULTS
为了评估所提出的 ISA 和架构，我们首先在寄存器传输级别使用 Verilog 实现了整个架构。使用 GLOBAL FOUNDRIES 22 纳米全耗尽绝缘体上硅工艺，我们在完成物理设计和验证后生成了一个符合签核要求的 GDSII 文件。

在 2022 年 12 月进行初始芯片板载测试后，该芯片使用倒装芯片球栅阵列重新封装，并组装了一个带有 Xilinxseven 系列 FPGA 的专用测试系统板。图 3a 说明了系统板、芯片布局和主要模块。芯片的结构组织成一个由 6×6 组组成的网格，每组由 4×4 个图块组成。每个图块包含一个连接到路由器的节点。除了 RISC-V 节点外，芯片上的所有节点都是神经元核心，共同驱动它们的计算功能。值得注意的是，存在两种不同的 Tile 类型，主要区别在于其轴突内存的大小。
![[Pasted image 20241026183647.png]]

Wuyuan 框架是一个定制的软件工具链，旨在基于参考软件架构 [41] 满足 Darwin3 的要求。图 3b 说明了应用程序开发的主要阶段。用户可以使用此工具链将现有的人工神经网络 (ANN) 模型转换为 SNN 模型，或从头开始创建新的 SNN 模型。开发过程涉及合并不同的业务逻辑。此外，该工具链允许用户编译和部署可在 Darwin3 芯片上运行的应用程序。
![[Pasted image 20241026183958.png]]

我们首先将一些重要指标与当前最先进的工作进行比较，然后运行一些应用程序演示来验证芯片的功能和性能。


# Comparison with the state-of-the-art neuromorphic chips
![[Pasted image 20241026184234.png]]
表 6 总结了最先进的神经形态芯片的性能和规格。具有模拟神经元和突触计算以及高速数字外设的混合信号设计分组在左侧 [4,12,34]，包括 Darwin3 在内的数字设计分组在右侧 [5–8,10,11,30,35–37]。高效脉冲神经形态硬件平台的关键指标是神经元和突触的规模、模型构建能力、突触可塑性和每个突触操作的能量。

## Neuron number
神经元和突触的数量直接决定了神经形态芯片能够支持的脉冲神经网络的大小和复杂度，这一点非常重要。然而，由于 SpiNNaker 芯片 [7,35] 采用 ARM 处理器，其规模与片外存储器的大小有关，因此无法直接与 SpiNNaker 芯片进行比较。在其他芯片中，NeuroGrid [4] 的单个神经元核心中的神经元数量最多，达到 64K。Loihi [5]、Unicorn [11]、Loihi2 [8] 和 Darwin3 处于类似水平，神经元数量超过 1K。在芯片级别，Darwin3 最多可支持 235 万个神经元，是 TrueNorth [10] 和 Loihi2 [8] 规模的两倍多。

## Synapse capacity
每个神经元核心内的扇入和扇出能力对芯片的整体突触容量有重大影响，如表 5 所示。Darwin3 以其自适应的轴突输出和轴突输入内存配置以及高效的压缩机制而独树一帜，可实现高达 $(D_1 − 1)MN$ 和 $(D_2 − N)N^2$ 的显著扇入和扇出容量。对于 Darwin3 而言，与物理内存深度相比，压缩机制可使扇入最大改进为 1024 ×，扇出最大改进为 2048 ×。

虽然之前的讨论深入探讨了扇入和扇出功能，重点关注突触连接潜力，但有效存储突触权重参数的挑战仍然至关重要。在图 4(a) 中，我们对权重存储要求进行了比较分析，突出了 Darwin3 与现有方法在应用于从 CNN 转换而来的典型网络时的鲜明对比。缺乏专门压缩机制的芯片表现出密集的权重矩阵，使内存使用量比原始方法大 6.8 倍到 200 倍。在交叉开关设计中，神经元始终占据其独特的空间，导致额外的低效率。

![[Pasted image 20241026185245.png]]

Darwin3 采用一种多功能机制，将卷积连接分类为权重共享的多对多形式，并获得与初始参数相同的存储奇偶校验，从而实现与 Loihi2 [8] 相当的效率。重要的是，这种优势扩展到具有共享权重参数的非卷积连接。Darwin3 通过乘法运算实现了对完整轴突的指令访问，从而实现了 Loihi2 [8] 也支持的分解属性。此外，Darwin3 还兼容不同的权重位宽，增强了其适应性和存储效率

## Code density
代码密度是一个有意义的 ISA 指标，因此我们将 Darwin3 的代码密度与 SpiNNaker 芯片 [7,35] 和 Loihi2 [8]（基于 ISA 的优秀神经形态芯片）进行比较。我们使用 C 代码描述模型，并使用 SpyNNaker [48] 集成的 spinnaker 工具为 SpiNNaker 芯片生成汇编代码。然后，我们比较图 4（b）中汇编代码的长度。Loihi2 的 RISC 指令集类似于 ARM 的 Thumb，其中尖峰指令有助于缩短与尖峰相关的指令代码，比 SpiNNaker [7] 略有优势。由于我们提出的指令，Darwin3 在代码密度方面表现出优势。该指令集同时加载参数并加快多个参数的乘法和加法。令人印象深刻的是，Darwin3 在不同模型中获得了显著的 2.2 × 到 28.3 × 代码密度优势。

## Inference and learning performance
对于从事 SNN 的研究人员来说，在最终确定模型后，主要关注点在于评估芯片在应用程序执行过程中的性能，特别关注延迟和准确性。为了评估 Darwin3 的功能，我们在两种不同的场景下进行了几次实验：推理和学习。表 7 将 Darwin3 与最先进的神经形态芯片在典型应用中的性能进行了比较。这些应用是从训练和量化的 ANN 转换而来的 SNN。我们在 Darwin3 上实现了相同类型的网络模型，性能指标表明 Darwin3 在准确性和延迟方面处于领先地位。准确率比其他产品高出 6.76%，延迟比其他产品高出 4.5 倍。Darwin3 的优势在于它具有灵活高效的连接构建能力，对转换后的卷积网络非常友好。由于连接存储效率高，不会增加冗余脉冲传输延迟。Darwin3采用的异步互连方法显著降低了神经元核之间的通信延迟。Darwin3利用点击元素[49]构建跨时钟域结构，仅用两个周期即可完成跨时钟域数据传输。此外，相关的拓扑结构可以拆分并与更多神经元核并行计算。我们将观察到的差异归因于将这些模型映射到硬件时的量化操作，而所采用的量化方法可能因方法而异。值得注意的是，通过优化映射方法，仍有提高延迟性能的空间。

为了进一步评估 Darwin3 的片上学习能力，我们基于 Diehl 和 Cook [50] 提出的架构构建了一个网络。我们添加了一个监督层，该层根据训练过程中网络输出与目标的比较提供正或负奖励，实现 RSTDP 规则的整体实现。该网络直接在 Darwin3 上进行训练，权重精度为 16 位，分类准确率达到 96.0%。表 8 展示了与先前研究相比的实验结果，表明 Darwin3 在准确率方面处于领先地位。Mod.SD 算法是硬件特定的，性能略好，而 Darwin3 允许灵活构建多种学习规则。我们计划优化当前的学习算法或引入新的算法来提高性能。

## Energy efficiency
每个突触操作（SOP）的能耗是神经形态芯片最关键的能耗指标。我们在运行两层神经网络时测量了 Darwin3 芯片的能耗，其中第一层的神经元可以在没有输入的情况下发射脉冲，第二层的神经元接收脉冲并执行计算。我们选择常用方法 [39] 来评估能耗，详情见
![[Pasted image 20241026190257.png]]
其中 $P_I$ 是 Darwin3 芯片在未配置任何应用程序的情况下上电后耗散的功率，$P_B$ 是基线功率，包括所有启用节点且未运行任何神经元时耗散的功率，$P_N$ 是以 1 毫秒时间步长模拟 LIF 神经元所需的功率，$n$ 是神经元总数，$P_S$ 是每个突触事件（激活神经连接）消耗的能量，$s$ 是总突触事件。该芯片的工作频率为 333 MHz，核心电压为 0.8 V，IO 电压为 1.8 V，如表 6 所示。测得的平均 SOP 功耗为 5.47 pj/SOP。该指标直接受到制造工艺、电源电压和工作频率等因素的影响，因此很难进行公平的比较。但从前作公布的典型场景数据来看，Darwin3 的成绩是领先的。Darwin3 的优势在于其内部采用了异步互联电路，使得芯片在没有尖峰传输或计算时功耗非常低。另外，在空闲阶段，Darwin3 的所有存储器都会关闭，从而降低功耗。

# Applications with a million of neurons
为了进一步说明该芯片的功效，我们在 Darwin3 上开发了两个广泛的应用程序，即脉冲 VGG-16 集成和直接训练的基于 [51] SNN 的迷宫求解，如图 5 所示。我们使用投票机制集成了通过 ANN2SNN [52] 获得的五个 VGG-16 模型的输出，最终形成一个包含约 105 万个神经元并采用 8 位权重精度的复合模型。

![[Pasted image 20241026190638.png]]

我们对输入应用了随机变换，并在隐藏层中使用了五个独立的 VGG 进行分类任务。投票层根据隐藏层各个输出的集体投票产生最终的分类结果。与原始的单个 VGG-16 相比，在 CIFAR-10 数据集上的准确率测试从 92.98% 提高到了 93.48%。

我们还开发了一个用于迷宫求解的应用程序。我们将迷宫映射到一组神经元上[9]，兴奋性神经元代表自由行走的网格点，抑制性神经元代表障碍物。相互连接的兴奋性神经元可以按顺序传递脉冲，在STDP规则的作用下，突触权重不断增加，形成稳定的突触强度。而与抑制性神经元相连的突触无法加强，遇到抑制性神经元时会终止脉冲的传递。经过学习，模型可以通过观察脉冲传播的路径来快速找到路径。我们使用不同大小的迷宫进行了实验，比较了在我们的芯片和CPU服务器上搜索路径所需的时间。一幅15 434×1534大小的地图需要超过235万个神经元，接近Darwin3可以模拟的神经元的上限。结果如表 9 所示。使用基于 STDP 的 SNN 方法，所消耗的时间随迷宫大小线性增加。相比之下，传统的 CPU 服务器上的搜索方法由于依赖于许多递归操作而消耗大量时间。

# CONCLUSION
本文提出了一种新的指令集和连接压缩机制，以创建一个可以支持大规模神经网络的芯片。与现有的工作相比，该芯片在可容纳的神经元数量和突触计算性能方面设计得更为高效。实验结果表明，该芯片在推理和学习模式的准确性和延迟性能指标方面已达到与最先进工作相同的领先水平。通过在其上运行迷宫搜索应用程序，还证明了该芯片的实际效果。

由于该芯片具有多功能的芯片通信机制，可以将不同的Darwin3芯片集成到单个板上，我们可以将多个板互连以配置一个大机箱。这些机箱可以通过网络基础设施互连，以支持构建广泛的SNN。当与合适的软件框架结合使用时，此配置可以支持构建广泛的SNN。
