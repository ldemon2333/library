# 3 系统架构
OS 向下管理神经元计算硬件存算一体芯片，对大量硬件资源进行统一管理和分配使用；
![[Pasted image 20250304230533.png]]
神经元计算机包括神经元计算应用开发环境和神经元计算应用运行环境。神经元计算应用通过 OS 提供的接口控制神经元计算硬件存算一体芯片。

## 3.2 总体架构
神经元计算机 OS 对上负责运行神经元计算应用（app），每一个神经元计算应用包括若干数量的 SNN 网络模型，多个模型之间相互配合实现神经元计算应用的功能。当神经元计算应用实例启动后，会与神经元计算机 OS 交互，为每一个模型分配硬件资源，并将模型部署到硬件资源上，每一个实例化的神经网络模型称为一个任务（task）。

簇级 OS 负责启动神经元计算应用实例化运行，以任务为单位与神经元计算应用进行交互。不同层级的 OS 之间通过网络通信方式进行数据的交互。
![[Pasted image 20250304231326.png]]
接收到安装应用请求的 Cluster 启动神经元计算应用实例并与其绑定，神经元计算应用实例直接与绑定的 Cluster 通信，发出创建任务请求，Cluster 收到创建任务请求后根据资源分配策略分配神经元计算硬件资源，并将任务部署请求发送到管理所分配硬件资源的 Node 上。
![[Pasted image 20250304204915.png]]
图中有误，节点级 OS 部署在跟芯片相连的 ZYNQ 开发板上。系统级 OS 与簇级 OS 之间通过网络进行通信，簇级 OS 与节点级 OS 之间通过网络或者 USB 进行通信。Cluster 部署在 Linux 环境的通用服务器上。

簇级操作系统启动神经元计算应用时，会在本物理机或者本物理机的 docker 上启动神经元计算应用。神经元计算应用跟本物理机上的簇级操作系统之间通过网络进行通信。

每个 Cluster OS 管理若干数量的节点级 OS，每个节点级 OS 对应一个神经元计算硬件，cluster 按照负载均衡策略将神经元计算应用的多个任务分布到各节点级 OS 管理的神经元计算硬件上。

在通讯上，选取了开源的高速并发通讯框架 ZeroMQ 作为通讯中间件，在通讯消息的编码方式上，在簇级 OS 及以上，通讯采用 JSON 的编码；簇级以下，采用二进制的编码方式。==类脑硬件语言描述模型使用的是逻辑资源信息，经过神经元计算机 OS 的**资源分配模块**和任务运行模块处理之后，神经元计算机应用会真实的映射到物理硬件资源上==，最后经过神经元 OS 中的任务运行模块和中继路由模块，将计算机应用真实的部署到芯片上运行。
![[Pasted image 20250304232725.png]]

当应用部署完成后，应用在运行过程中也需要完成神经元描述语言到硬件指令之间的相互转换。在部署完成之后，cluster 中会保存全局神经元到节点级 OS 通讯端口和硬件指令的转换关系，在应用运行过程中，cluster 会直接完成两者之间的转换。
![[Pasted image 20250304233525.png]]
## 3.3 Master
提供统一的 OS 对外接口，同时提供了应用管理、资源管理以及可视化功能。
![[Pasted image 20250305112841.png]]
其中应用运行等接口则根据应用分配部署结构调用簇级的相应功能接口来进行实现；资源管理从系统级、簇级以及节点级三个视角展示不同层级的资源状态以及任务数量等信息；
### 3.3.1 外部访问接口
master 定义了标准化的外部访问接口，通过远程过程调用方式提供给外部组件调用。主要包括如下接口：
- 应用安装接口：通过安装接口可以将应用开发者开发的应用，采取负载均衡策略部署到 cluster，并返回应用部署的信息，包括所部署的 cluster IP 地址、端口、应用 ID。
- 应用卸载接口：用户通过调用该接口可以停止部署在cluster 上的应用，并将应用 DPK 文件进行物理删除，同时 OS 自动执行资源回收；

### 3.3.2 应用管理
应用管理负责将应用分发并部署到簇级，并管理应用队列以及应用状态。部署成功后，返回簇级为应用分配的访问地址，包括 IP 地址、端口、簇级应用 ID，系统级将簇级应用 ID 映射为全局的应用 ID，并返回给用户部署信息，同时将此应用加入到应用队列。当应用卸载时，在应用队列中找到相应的应用全局 ID，将其转成对应的簇级应用 ID，并调用簇级卸载功能接口进行应用卸载。

### 3.3.3 资源管理
全局资源视图和任务资源视图。从计算机角度来看，全局资源视图包括通用计算资源和神经元计算资源，其中通用计算资源是指传统计算资源如 CPU、内存等，而神经元计算资源则包括神经拟态核心内神经元和突触等，神经拟态核心是最小的神经元计算资源管理单元。

## 3.4 Cluster
==一个应用只能部署在一个簇级上==，由 cluster 来统一编排应用的各个子任务来实现其功能。应用在运行过程中会创建多个子任务，其中预处理、脉冲编解码等子任务基于 cluster 的 CPU 来实现，而神经元计算子任务则由节点级的神经元计算硬件来完成。应用管理层实现了上述应用各个子任务的创建、运行、销毁等过程，同时通过复杂计算任务并行调度支持多个应用任务的高效并行执行，以提高系统的整体任务吞吐率。
![[Pasted image 20250305113957.png]]

### 3.4.1 应用管理层
![[Pasted image 20250305114453.png]]
应用部署模块在接收到系统级 OS 分发的应用时，首先解析应用并检查应用的合法性，接着为应用分配通用计算资源和神经元计算资源，计算资源分配成功后，将应用的神经元计算任务加载到硬件上，接着构建子任务链并启动任务运行；应用状态管理模块负责统一管理应用状态、任务状态和应用的神经元状态。

（1）应用部署
应用部署过程包括应用解析与启动、任务加载、子任务链生成三个环节，应用解析对应应用的逻辑和模型解析，解析成功后启动应用逻辑，并基于应用解析的模型数据进行任务创建和加载，在此阶段，cluster 将神经元计算任务划分为多个子任务步，并组成运行链，以支撑任务的分布式运行。

（3）应用状态管理
应用状态管理生成神经元计算应用的信息结构，分为应用运行状态、应用的关键信息、应用内任务状态信息、应用资源信息四个部分；==应用运行状态包括应用 Installing、Running、Pausing、Terminating 四个状态==，其中 Installing 阶段将包括资源申请、环境初始化、应用启动、应用部署成功等子状态；应用的关键信息包括应用 ID 信息、应用通讯信息、应用任务运行信息等；应用内任务状态信息则包括任务数量、任务占用资源信息（通用/神经元）、任务运行状态、任务流量状态等；应用资源管理包括对端口资源、容器资源、文件资源的分配与回收，以及对 CPU、GPU 等资源利用率的评估与监控。

（4）任务管理
应用启动成功后，应用运行对象通过接口访问任务管理模块，任务管理包括运行支撑和并行调度两个方面。其中运行支撑为任务创建、任务销毁、任务运行、任务迁移提供运行环境，而并行调度则建立了多任务并发调度框架，包含对大量的任务数据的输入、计算、输出的组织流程与软件框架。

在创建神经元计算任务时，需指定绑定的应用 ID 信息和该应用的具体二进制文件模型，任务在生命周期内与应用绑定。==任务状态包括创建（Create）、就绪（Ready）、运行（Run）、暂停（Suspend）、销毁（Terminal）五个状态==，当任务的创建请求处理成功后，该任务将置为 Create 状态，并加入任务调度队列；触发神经元计算任务周期结束的场景有以下三种：用户主动卸载应用、应用业务逻辑内销毁任务、在故障或者资源需要调度时任务管理模块强制清除任务，任务管理接收到任务销毁指令后，会在当前数据处理周期结束后销毁任务；任务销毁过程包括资源释放、任务出队和任务冗余清除三个流程，其中任务冗余清除则包括清除任务运行产生的临时文件和缓存信息。神经元计算任务主要依据预处理、编解码、神经元计算等过程组成的子任务链运行的，预处理过程是将输入的源数据处理成特定格式数据，减少冗余特征信息以匹配编码构件可以接收的数据格式；编码过程是将预处理后的数据编码为脉冲数据；解码过程是将神经元计算任务输出的脉冲解码为用户期望的数据格式。

任务并行调度涉及多方面协同，内部模块关系如图 3-11 所示，对应用的管理过程会产生应用安装、卸载、状态控制等请求，应用部署成功后，任务管理将输入输出数据缓存成数据 I/O 队列，由事件驱动的任务调度管理调度，调度机则结合脉冲到达、神经网络状态获取、多任务协同、资源协同等事件有序执行各任务。

任务并行调度算法主要分为两个流程，一个是调度信息反馈，基于神经元计算计算机系统的支撑，监听各任务队列深度、任务饥饿状况、节点负载、资源更新等相关事件，及时获取调度所需的环境信息；第二个是调度决策执行，该模块根据反馈的调度信息生成调度序列，并保证任务队列按照调度序列执行，包括任务编排、任务状态控制与转换、任务配置与分发执行等流程。
![[Pasted image 20250305121052.png]]
任务运行过程中会产生大量信息和数据交互，任务并行调度将这些 I/O 交互信息定义为==事件==。对这些事件的触发和响应机制是影响系统整体运行性能的关键；由事件驱动的任务调度算法，将结合应用控制、脉冲 I/O、多任务协同、神经元状态、资源协同等事件有序且高效地执行各任务。==根据触发模块可将事件分为应用类事件、任务类事件、资源类事件==，应用类事件包括应用启/停产生应用控制事件，任务类事件包括任务启/停、任务间协同、数据流量、任务饥饿等事件，资源类事件包括资源变更、资源整合、资源预警等事件。根据不同的事件类型和优先级，将匹配不同的回调处理。

簇级系统的输入和输出包括应用控制请求、应用任务运行数据 I/O 两种处理通道。

### 3.4.2 资源管理层
资源管理层包括异质异构神经元计算资源的抽象、大规模资源动态分配、资源状态和资源回收。cluster 系统管理多个节点，每个节点包含一定数量的神经元计算资源，不同节点的神经元计算资源可能是异质异构的，为了屏蔽底层硬件差异，==异质异构神经元计算资源的抽象层以神经元簇为单位将所有节点的神经元计算资源抽象成统一编址的逻辑资源==；
![[Pasted image 20250305121821.png]]
计算任务所需的资源为包含多个计算核心的矩形，神经元计算机资源也抽象为二维矩阵，因此，给任务分配资源就是在计算二维核心矩阵中找到满足计算任务所需资源块，类似二维装箱问题。

针对神经元计算应用高并发、神经元计算资源有限等特点，采用基于最大空矩形等方法实现资源的高效分配，降低资源碎片率，提高神经元计算 OS 吞吐量。


## 3.5 Node
簇级系统完成任务的通用计算部分，节点级系统则完成神经元计算部分。簇级-节点系统协同计算过程如图所示，
![[Pasted image 20250305122622.png]]
# 4 OS SDK 设计
## 4.1 需求分析
![[Pasted image 20250306230924.png]]
## 4.2 方案设计
接口设计方案包括接口协议、接口框架和接口调用逻辑三个部分。

### 4.2.2 接口框架
接口框架的设计展示于图 4-3。该框架的实现核心包含几个主要部分：基础类
（DarwinOSApiBase）、扩展基类（FunctionProxy）、协议定义类（DrwMsgProtocol）、消息处理类（DrwMessage）以及通信库操作类（MsgHandle）等。接口集成组件（ApiAssembly）利用继承机制，有效地融合了协议层、消息处理层及系统功能代理层，形成了一个调用关系密集且高效的结构体系，确保各部分之间的紧密配合和顺畅交互。
![[Pasted image 20250306233047.png]]
系统接口集的实现及注册方式如图 4-4 所示，接口集的实现包括服务端和客户端两个方面，均遵循 2.2.1 中协议框架，此外，按照调用方式可以分为同步或异步异步接口。具体在新增接口时，需要继承 DarwinOSApiBase 基类，实现所需的服务端或客户端接口形式，再将实现的接口名称通过 ApisAssembly::Init 函数注册到接口组件 ApisAssembly 中，即可通过接口组件统一启动或调用（图 4-5）：
![[Pasted image 20250306233308.png]]
![[Pasted image 20250306233317.png]]
## 4.3 接口设计
### 4.3.1 install_app
#### 4.3.1.1 应用场景
开发者完成应用开发后，通过云平台完成部署动作
拟解决以下问题：
- 指定安装某个应用，启动应用进程服务；
- 部署运行神经网络，与用户进程动态交互，实现脉冲 IN/OUT;
- 反馈安装信息，包括应用启动信息、错误信息等；
- 支持分布式部署及运行应用。

#### 4.3.3 task_create
创建接口提供给应用使用，用于创建一个类脑任务，任务是神经元 OS 分配资源及运行的基本单位。
解决问题：
- 应用创建类脑任务运行实例，支撑 SNN 应用的模型运行；
- 为类脑应用创建程序载体，用以加载神经网络信息、配置和运行信息，并分配全局唯一标识：任务 ID
- 指定部署 DPK 应用内的某个模型，创建的神经任务与该模型绑定；
- 根据 SNN 进行资源配置，给网络分配真实的类脑芯片资源（NPU）
- 将 DPK 占用核心的资源格式映射至实际分配的硬件资源上，并能实际运行和计算脉冲 IO；
- 调用创建接口的次数，由应用决定，一个任务可以服务于多个调用者，也可以为每个应用创建多个任务。

### 4.3.5 task_input_spike
#### 4.3.5.1 应用场景
面向类脑应用运行业务的交互接口，解决问题：
- 运行单次输入的多个时间步的发放脉冲的神经元序列，在 OS 内部需要将全局神经元序列映射到类脑任务对应的物理类脑硬件资源路由信息，并结合脉冲的时间步封装成微片发送给类脑硬件；
- 支持在没有脉冲时运行给定的时间步；因为类脑应用支持芯片内的编码，即处理后的数据通过神经元状态接口 neuron_state_write 写入到指定的神经元，再通过 task_input_spike 接口的 time 参数指定网络运行的时间步，OS 在封装微片时，只封装 tikadd 和其他与芯片的握手数据；
- 在 OS 内部微片发送与接收是异步的。
![[Pasted image 20250307142310.png]]

## 5.3 应用管理
### 5.3.1 方案分析
Cluster_ID + APP_ID 

### 5.3.2 算法设计
介绍 Master 中选取空闲 Cluster 的负载均衡算法，该算法在 Master 的 CLB 模块中实现。在介绍该负载均衡算法之前，先明确两点前提：1、该负载均衡算法是在 Master 中实现，目的是为了选取一个相对空闲的 Cluster，在计算过程中，并不关心 Cluster 以下管理资源的详细负载情况，这应该是 Cluster 中负载资源分配应该考虑和实现的部分，因此 Master 中负载均衡算法需要的输入数据是 Cluster 的总体负载情况；2、Master 中的负载均衡无法保证选取的 Cluster 一定能满足应用的运行，因为该应用会部署多少神经元计算任务是应用内逻辑的实现，Master 无法预估该应用会占用多少硬件资源，因此 Master 负载均衡只能做到分配一个相对空闲度最高的 Cluster。在以上两点前提下，下面介绍 Master 中负载均衡算法的实现。

Master 中负载均衡算法目的是要选取一个相对空闲的 Cluster，评价 Cluster 空闲程度的信息来自 Cluster 压力负载情况，此压力负载包含两个方面：通用计算资源的压力负载和神经元计算机硬件资源的压力负载，详细来说，我们挑选了以下 6 个压力指标作为评价 Cluster压力负载的数据：Cluster 中神经元计算应用的数量、Cluster 中神经元计算任务的数量、Cluster 所管理的神经元计算硬件资源中空闲核心的数量、Cluster 运行的通用服务器的 CPU 使用率、内存使用率、网络速度。在簇级操作系统 Cluster 运行时，会周期性检测上述 6 项压力负载数据，并将数据维护在其内存中，同时向外提供 API 接口供 Master 采集 Cluster 的压力负载数据。当应用安装时，Master 调用所有在线的 Cluster 的 API 接口，获取这些 Cluster 的压力负载情况，举例假设获取到的 8 个在线的 Cluster 压力负载情况如表 5-1 所示，需要根据这些数据选取相对空闲的一个 Cluster。

![[Pasted image 20250305124358.png]]

选取熵权法作为 Master 中负载均衡的算法。

## 5.4 资源管理
### 5.4.1 方案分析
资源管理功能需要 Master 将系统中所有的 Cluster OS 接入，并维护和检查其在线状态。

对每一个 Cluster 实例都有一个唯一标识 Cluster id 与之对应，该 Cluster id 在 Cluster 的配置文件中配置。同时每一个 Cluster 实例作为 API 的服务端都通过特定端口往外提供服务，所以 Cluster 所在环境的 IP 地址加 API 端口也可以需要保证唯一。当 Cluster 实例启动后，从其配置文件中读取 Cluster id、API 端口以及从环境中获取指定网卡的 IP 地址，周期性的向 Master 发送心跳信息，Master 的 IP 地址和接收心跳消息的端口从 Cluster 的配置文件中获取，心跳消息中携带 Cluster id、API 端口以及 Cluster 所在环境的 IP 地址，Master 收到心跳消息并处理后，会回复响应，若回复成功响应，则 Cluster 将其在线状态置为在线，若回复失败响应，则 Cluster 将其在线状态置为离线。

Master 作为接收 Cluster 心跳请求的服务器端，在启动后监听处理心跳消息的端口，当收到 Cluster 发来的心跳消息后，根据消息中携带的 Cluster id 从在线簇级 OS 列表中查询该 Cluster 是否已经在线，若不在线，则认为是第一次注册心跳消息，则将此 Cluster 信息记录到在线 Cluster OS 的列表中，并为此 Cluster 生成一个在线检查次数的计数，将此计数初始化为 0；若已经在线，再比较内存中记录的 API 端口和 IP 地址与心跳消息中携带的信息是否一致，若一致，则认为此次是 Cluster 的保活心跳消息，则回复成功响应，若不一致，则认为此次心跳的 Cluster 与另一个已经在线的 Cluster 唯一标识 ID 重复，则回复失败响应。同时在 Master 存在一个独立线程，周期性检查所有在线 Cluster 列表中每一个元素的在线状态，每次检查时，针对每一个在线的 Cluster，先将在线检查次数的计数加 1，然后检查其在线检查次数，若此计数超过阈值，则认为此 Cluster 离线，将其从在线 Cluster 列表中删除；若此计数没有超过阈值，则跳过检查下一个 Cluster。
![[Pasted image 20250305130231.png]]

# 6 Cluster 详细设计
## 6.1 总体设计
### 6.1.2 方案分析
![[Pasted image 20250305130355.png]]
对外接口模块负责对外提供 Cluster 的功能接口，包括应用安装、应用卸载、任务创建、任务释放、脉冲输入、脉冲输出、神经元状态读写、神经元计算资源查询等接口，对外接口可由客户端进行远程调用，交互采用 ZeroMQ 的传输方式和 JSON 的编码方式。

任务运行模块是实现单任务的运行，对任务调度模块属于是底层功能支撑。在任务运行模块中，需要与下层节点级操作系统对接，实现任务初始化、任务部署、脉冲收发、神经元状态读写和重置、任务销毁等任务有关的动作。

序列化管理模块是负责实现内存数据与硬件指令的序列化和反序列化转换，是任务运行模块的支撑模块。

中继管理模块是为了适配 Darwin3 芯片的硬件特性，针对外界与硬件上内部核心通信的中继路径进行规划和部署，为大规模硬件核心资源的有效利用提供了支撑，同时为资源分配模块起到了支撑的作用。

![[Pasted image 20250305130657.png]]

## 6.3 应用管理
操作系统软件的业务流程是将开发平台生成的应用部署至芯片，并保证应用环境（用户逻辑）的运行。在 wuyuan 开发平台采用 Dpk 文件作为应用的载体媒介，记录了 SNN 应用编译后的网络参数、应用预处理/后处理、编/解码算法、数据集（必要）、神经元状态采样计划、全局神经元编排、占用神经形态资源以及用户逻辑代码等信息。

应用的根目录包括 3 个主要的子目录：META-INF、script 和 config 文件夹，META-INF 目录中存放有 “configure.json”文件，config 目录存放的是构建（component）的配置信息及对应的编译文件，包括网络权重、二进制代码、bin 文件、神经元状态采样及计划。

编译的 bin 文件，其中 bin 文件则会涉及如下：
（1）hardware.bin：拟态核心的配置二进制文件
（2）neneuromorphic_grid.json：文件提供了该模型所占核心集群的最大 X 边界和最大 Y 边界
（3）input_neuron.json：文件存放了输入层神经元的连接信息，当这个虚拟输入层神经元发放脉冲时（脉冲输入），由 OS 按照连接信息分发至突触后目标神经元；
![[Pasted image 20250306125536.png]]
（4）neuron_to_core_dict.data：文件提供了全局神经元 ID 与拟态核心局部神经元 ID 的转换关系，主要用于；
![[Pasted image 20250306125644.png]]
（5）node-graph.data：文件包含核心直接的连接关系，是 SNN 的网络连接拓扑的编译映射结果，OS 将根据这种链接关系给应用分配芯片上的核心资源；
![[Pasted image 20250306125804.png]]
（6）output_axon_terminal.json：文件说明了输出层核心的输出脉冲的神经元 ID 转换信息，当 OS 接收到芯片的脉冲数据时，将依据该文件所描述的输出层连接关系转换全局神经元 ID 等信息；
![[Pasted image 20250306125928.png]]

![[Pasted image 20250306125056.png]]

## 6.4 资源管理-资源状态监控
### 6.4.1 需求分析
广义的资源管理模块主要完成以下 5 个方面内容：
- 资源状态监测：实时监控神经元计算硬件节点的动态加入和退出，以及硬件节点上神经元计算资源的占用情况。状态监控 Cluster 监控 Node。
- 资源抽象：根据 SNN 应用的需求，将硬件资源抽象为可由神经元计算机操作系统调度的资源单元。
- 资源分配和回收：在 SNN 应用动态加入时，分配空闲且合适的神经元计算资源，以满足应用部署和运行的需求；在 SNN 应用退出时，动态回收其占用的神经元计算资源。
- 资源可视化：为了方便用户和管理员查看资源实时情况，根据资源状态监测情况，采用分布式、层次化显示 Master-Cluster-Node 的实时资源，包括 Master 下所有 Cluster 资源、Cluster 下所有板级资源、板级下所有 Node 资源、Node 下所有核心全景图以及核心的占用信息，核心的占用信息包括核心是否可用、核心类型等。
- 资源高可用性保障：在神经元计算资源发送异常的情况下，确保 SNN 应用能够正常迁移和无感运行。
#### 6.4.2.1 硬件形态
基于 Darwin3 不同硬件形态的同质异构神经元计算节点包括如下 2 种形态：
（1）单芯片开发板
单芯片开发板由一个 Node 组成，Node 包含一个单芯片和 4 个方向的DMA 通道。DMA 通道是软件与片上网络之间进行脉冲传输的通道，单个芯片由 576 个通过路由节点相互连接的同质同构神经形态核心组成，每个神经形态核心都能并行地模拟神经元行为并存储突触权重. 每个神经形态核心与一个路由节点绑定，并通过双向链路将其与 4个方向上的邻居节点连接起来，从而形成了一个具有 2D 网格拓扑结构的互联网络；每个神经形态核心与其绑定的路由节点都有一个坐标，神经形态核心之间通过路由节点传输脉冲包，脉冲包在片上网络采用 XY 算法进行路由，即通过目标神经形态核心与源核心在 X 和 Y 方向上的差值来完成传输。

#### 6.4.2.2 心跳监控
（1）Node 上线管理
Node 每 3 秒向 Cluster 发送一次心跳，Cluster 在收到 Node 的心跳后，分以下几种情况处理：
- 收到板子上第 1 个 Node 的心跳时，创建该板子信息，并根据 Node 配置信息初始化板子上所有 Node 资源。并更新该 Node 为上线状态。
- 收到未上线 Node 心跳，但该 Node 所在的板子资源已经创建，则更新该 Node 上线。
- 收到已上线 Node 心跳，只更新时钟信息。
（2）Node 下线管理
启动一个线程，每 3 秒监测该 Cluster 下所有 Node 的心跳时钟，如果最近一次心跳已经超过 3 秒，则任务该 Node 发生异常，需要检查该 Node 上待迁移的应用。
1. Node 状态机
节点上下线的状态有如下几种：
（1）kCreate：创建状态。收到 board 上第 1 个 node 心跳时，创建 board 和 n 个 node 的对象，创建完成后，将 n 个node的状态置为：kCreateinit：节点初始化状态。收到节点的第 1 次心跳包时，初始化节点，如 DMA 初始化、中继配置初始化。
（2）kInit：初始化状态。进入 node 初始化的状态（dma 初始化 + riscv 配置 + relay 配置）。转换到此状态的情况如下：
在

#### 6.5.2.1 硬件资源抽象
将硬件资源抽象为核心粒度的资源，针对不同的硬件形态，抽象的资源如下：
（1）单芯片开发板
单芯片资源定义为一个集合：
![[Pasted image 20250305193214.png]]

软件与片上网络输入输出脉冲通过芯片边缘的 4 个直接内存访问 DMA 通道进行通信，将 DMA 抽象为片上网络同行同列的虚拟输入输出核心，虚拟输入输出核心定义为 4 个边缘核心的坐标集合：
![[Pasted image 20250305193439.png]]
由于单芯片内任一核心都可以通过 1 个脉冲输入输出通道到达，因此在单芯片资源时不需要使用中继路由。

#### 6.5.2.2 空闲核心管理
把为 SNN 应用分配资源理解为在神经形态计算资源中找到一块空闲的矩形区域核心集。

### 6.5.4 算法设计
本节将介绍 3 中动态分配算法，算法 1 针对单芯片开发板资源的分配策略，算法 2 针对刀片服务器资源的分配策略，

#### 6.5.4.1 算法 1 ： 最优适配算法

## 6.6 中继管理
### 6.6.1 需求分析
受 Darwin3 芯片硬件特性约束，芯片中每个核心的信息承载量是有限的，对于大型的神经网络模型，需要多个核心承载。不同核心上承载神经元之间的通信，需要通过核心之间的通信实现。但是受硬件特性约束，核心与核心之间的通信存在距离限制，在二维核心矩阵中，核心之间 x 和 y 方向都存在最大为 15 的通信距离限制。另外，核心与外部之间的通信须经由二维核心矩阵的边缘。

cluster OS 负责将神经元计算任务部署到硬件芯片上，并保证任务正常运行，就需要进行外部 DMA 通道与内部核心通信的路径规划。
![[Pasted image 20250305135648.png]]

### 6.6.2 硬件背景
在序列化管理章节中描述了 flit 包的结构，其中可以发现包头中的 src_x 和 src_y 都只有 4bit 的存储空间，能表示的数值范围为 [0, 15]。

当两个核心之间的距离超过 15 时，可以在两者之间的传输路径上，部署若干中继核心，在这些中继核心上配置好中继规则，中继核心根据包中的信息和其自身存储的中继规则，将 flit 包转发出去，最终通过若干中继核心将 flit 包送达目的核心。Darwin3 芯片中的核心都可以作为计算核心和中继核心使用，但是二者只能选其一。中继核心中存储的中继规则分为两者：配置中继和脉冲中继，配置中继用于对核心的读写操作，进行读包和写包的传输，脉冲中继用于脉冲的转发，进行脉冲包的传输。

在核心的存储区域中，有一个字段代表核心的 relay_id，relay_id 的有效范围为[0,7]，若将某个核心的 relay_id 配置为 0，则该核心为非中继核心；若将某个核心的 relay_id 配置为 1~7，则该核心为中继核心。需要额外说明的是，当此核心收到写包或者读包时（此处收到指 flit 包中 dst_x 和 dst_y 都为 0 时，而并未核心中的路由模块进行转发时），因为 flit 包中存在 relay_id 字段，所以本核心会校验自身的 relay_id 跟包中的 relay_id 是否一致，若核心自身的 relay_id 为 0，则不论包中的 relay_id 为何值，本核心都会自行处理；若核心自身的 relay_id 不为 0，那么如果自身的 relay_id 和包中的 relay_id 相等，则该核心认为此包是自身应该处理，如果自身的 relay_id 和包中的 relay_id 不相等，那么该核心认为此包应该根据中继规则转发出去，而非自己处理。下面分别介绍配置中继和脉冲中继的实现。

#### 6.6.2.1 配置中继
首先介绍配置中继的实现。配置中继规则针对的是读包和写包，参考序列化管理章节中的 flit 包结构描述，可以发现读包和写包中都有关于中继相关的参数描述：relay_id、relay_link、relay_direct。其中 relay_id 的含义表示此包最终目的核心的 relay_id，relay_link 对应中继核心中存储的中继规则的索引，relay_direct 表示该 flit 包在被中继核心进行中继转发时是发往源核心位置还是目的核心位置。另外，可以观察到 relay_id 占 3bit 的存储空间，可以表示的数值范围是[0,7]，即对应核心中存储的 relay_id 范围[0,7]，relay_link 占 6bit 的存储空间，可以表示的数值范围是[0,63]，说明一个中继核心中存储的配置中继规则数量最多有 64 条。

中继核心中的中继规则存储在核心中的轴突存储区中，该存储区是一个深度为2^14 的存储空间，每个行存储 26 bit 的配置，在存储配置中继规则时，该存储空间中的存储结构如图所示：
![[Pasted image 20250305141856.png]]
配置中继规则的存储分为中继索引区和中继转发表体两部分，flit 包中的 relay_link 对应的就是中继索引区中某条中继规则的首地址。首先找到的是中继索引区的信息，该区域中存储有一个 axon_id 字段，占用 26bit 中的低 14bit 空间，可以存储最大 2^14 个数字，刚好对应轴突存储区的空间深度，该字段代表当前这一条中继规则的转发表体在轴突存储区的空间深度，该字段代表当前这一条中继规则的转发表体在轴突存储区中的起始地址。中继转发表体中包括以下字段，![[Pasted image 20250305142400.png]]![[Pasted image 20250305142425.png]]
如果这是一个读包，那么读的返回包也需要经过若干中继核心到达外部。按照序列化章节中对读的返回包的描述，最终目的核心在处理完读操作后，会给读包中的源核心返回一个写包（即读的返回包），在有中继的情况下，最终目的核心返回的写包会发到最后一个中继核心上，但由于核心内部硬件处理逻辑的实现，这种操作会产生死锁，因此读的返回包不能回复到最后一个中继核心上，而要为读的返回包重新搭建一条中继路线。如图 6-25 所示：
![[Pasted image 20250305143533.png]]
图中 IN 的核心为输入包的中继路径，OUT 的核心为输出包的中继路径。当输入包在经过输入路径中最后一个中继核心时，转发到最终目的核心的 flit 包中的 src_y 字段需要用中继规则中的 RY 字段替换，新的 flit 包中 src_y 应该为最终目的核心与输出包中继路径中第一个中继核心的 y 坐标的相对偏移，同时，输入中继路径的最后一个中继核心中的中继规则中的 RF 要填写 1 。

另外需要说明的是，因为 RY 替换 flit 包中的 src_y 字段只有绝对值，无符号位，因此在选取输入中继核心和输出中继核心时要注意，输出中继核心只能在对应输入中继核心的上面。在实际使用中，通常配置中继的输入中继核心和输出中继核心是成对存在的。

#### 6.6.2.2 脉冲中继
单向，无返回路径

### 6.6.3 方案设计
中继分为配置中继和脉冲中继，配置中继的目标是一个核心，脉冲中继的目标是核心上的一个树突。一个中继核心最多存储 64 条配置中继规则，最多存储约 2^13 条脉冲中继规则，对于配置中继，中继核心与计算核心的比例是 1:64，即一条配置中继路线可以服务于 64 个计算核心，对于脉冲中继，中继核心与计算核心的比例大约是 1:1，即一条配置中继路线可以服务于 1 个计算核心，但是神经网络模型部署到神经元计算机硬件芯片上后，不是所有的树突都需要脉冲中继，只有输入神经元和输出神经元需要与外界进行通信，需要依赖脉冲中继路径。因此，基于配置中继和脉冲中继不同的特点，对两者的实现上簇级操作系统采取不同的实现策略。

#### 6.6.3.2 配置中继
一条配置中继路线最多可以配置 64 个核心，
#### 6.6.3.3 脉冲中继
脉冲中继核心的选取是在部署神经网络模型时，才能知道哪些核心上的突触属于输入神经元和输出神经元，才会进行脉冲中继核心的选取和配置。其次在需要用到中继策略的硬件芯片形态上限时，会预留部分脉冲中继核心。脉冲中继核心规则的计算和配置的写入主要在任务运行模块实现。
![[Pasted image 20250305225605.png]]
在任务部署阶段，当资源分配模块将模型的逻辑核心映射到物理核心后，根据映射后物理核心所在的区域，需要查询计算核心的配置中继路径，以及选取并配置输入神经元和输出神经元与外部通信的脉冲中继路径。

## 6.7 任务调度
### 6.7.2 方案设计
#### 6.7.2.1 调度对象


## 6.8 任务运行
### 6.8.1 需求分析
对于任务创建分为两个动作完成：任务初始化和任务部署。==任务初始化过程中，包含解析神经网络模型文件，向资源分配模块申请任务需要的资源，构建脉冲中继核心中的中继规则，完成任务数据在内存中的存储，完成内存中数据与硬件指令的序列化与反序列化映射；==任务部署过程中，需要将用到的计算核心和脉冲中继核心中的数据通过节点级 OS 写入硬件芯片核心的存储中。任务部署完成后，即可开始使用此任务中的神经网络模型进行计算。

脉冲收发指应用任务中的 SNN 的输入神经元输入脉冲，并在硬件处理后从输出神经元接收返回的脉冲。神经元状态的读写指应用中读取和写入某个神经元的数据，以此实现神经元状态监控或者硬件编解码等功能。神经元状态的重置指将神经元状态恢复到初始值，常用于多次推理之间的状态清除。

任务释放时，任务运行模块需要到资源分配模块释放此任务占用的资源，并通过节点级 OS 与硬件通信，将任务中使用的脉冲中继核心释放，最后清除自身在内存中存储的数据。


### 6.8.2 方案设计
基于以上需求，下面介绍 Cluster 中对任务运行模块的设计与实现方案。任务运行的生命周期内，主要包含以下几个动作：任务初始化、任务部署、脉冲收发、神经元状态写、神经元状态读、神经元状态重置、任务释放。这几个动作的进行伴随着 task 状态的转换，因此为任务运行设计状态机如图 6-54 所示，共有 kCreate(创建)、kInitting(初始化中)、kTaskErr(任务出错)、kInitted(初始化完成)、kDeploy(部署中)、kIdle(空闲)、kSpike(脉冲收发中)、kCoreReset(神经元状态重置中)、kNeuronRead(神经元状态读中)、kNeuronWrite(神经元状态写中)、kTerminal(终止)这 11 个状态。
![[Pasted image 20250306113835.png]]

#### 6.8.2.1 任务初始化
首先描述几个概念：
（1）全局神经元 ID：在每一个神经网络模型中，为每一个神经元分配的全局唯一 ID；
（2）逻辑核心坐标：神经网络模型编译成模型文件后，会将神经元聚合成神经元簇存储在核心上，每个核心都对应一个坐标，此坐标为逻辑核心坐标；
（3）物理核心坐标：当模型经过资源分配模块分配后，每一个逻辑核心都会有一个物理核心与之对应，该物理核心的坐标称为物理核心坐标，物理核心坐标包括核心在其所在 node 内的局部物理核心坐标，以及若干 board 组成的大型二维核心矩阵中的全局物理核心坐标。
（4）边界虚拟核心：在模型文件中，为了描述输入输出神经元的脉冲传递关系，模型文件中会存在边界虚拟核心，边界虚拟核心向到逻辑核心的脉冲传递就是外界脉冲输入，逻辑核心向边界虚拟核心的脉冲传递就是脉冲输入到外界。同样，在资源分配时，也会选择边界虚拟核心与真实的物理核心进行通信，这种通信同样表示脉冲的输入和输出。
（5）输入神经元和输出神经元：输入神经元存在于边界虚拟核心中，其轴突指向芯片内部的真实物理核心；输出神经元存在于真实物理核心中，其轴突指向边界虚拟核心。

任务初始化包含以下几个子过程：1、读取神经网络模型文件。2、通过资源分配模块获取该任务分配的资源。3、计算和组织数据为后续的部署的任务执行提供方便使用的数据结构。下面详细介绍这三个过程：
（1）读取模型文件
每一个 task 对应一个 NeuralTask 对象，每一个 NeuralTask 对象中都有一个成员变量 NeuralTaskModel 对应神经元模型解析的结果，其内部主要包含以下数据：
![[Pasted image 20250307204010.png]]
![[Pasted image 20250307204022.png]]

（2）申请硬件资源
在读取完模型文件之后，任务运行模块会调用资源分配模块的接口为本次任务申请需要的资源，资源分配算法在资源分配模块。
![[Pasted image 20250307204126.png]]
![[Pasted image 20250307204220.png]]
![[Pasted image 20250307204236.png]]

（3）计算和组织数据
在读取模型文件和申请硬件资源之后，利用前两步的结果进行 task 内部数据的计算和整理，下面介绍任务数据的存储结构。任务中存储的数据主要有两大类，一类是核心信息，一类是输入输出神经元突触的信息，二者之间是包含与被包含的关系，核心中包含神经元突触信息，神经元突触属于某个核心。

核心分为 3 类：计算核心、边缘虚拟核心、脉冲中继核心。
神经元突触分为 2 类：轴突与树突，一个轴突指向多个树突。
还有一些信息，比如脉冲中继规则的存储，脉冲中继规则既属于某一个脉冲中继核心，也为某一个输入输出脉冲的树突服务。

![[Pasted image 20250307204413.png]]
![[Pasted image 20250307204430.png]]
![[Pasted image 20250307204436.png]]
![[Pasted image 20250307204447.png]]

对于输入神经元的轴突，可能指向不同的树突，这些树突所在的核心可能被分配到不同的 relay_block 中，那么逻辑上的一个输入神经元轴突在真实硬件上就可能处于不同的边界虚拟核心上，因此在神经元轴突数据结构中存在 next_axon_in_neuron 字段，它将同一个输入神经元的轴突在不同边界核心上的实例用单向链表串联起来，
#### 6.8.2.2 任务部署
对于任务部署，主要需要说明有以下两个方面：1、异步请求响应的控制，2、硬件指令 flit 写包内容的拼装。
（1）首先介绍异步请求响应的控制方法。任务运行模块向外提供的任务部署接口是一个异步处理的接口，该接口返回只能代表任务的部署请求都已经发给了节点级 OS，当节点级 OS 返回部署完成后，需要再调用上层提供的部署完成回调函数。另外，一次部署可能涉及到若干 node，同时由于每个 node 上存在若干核心需要部署，且部署时数据量较大，因此暂定一次部署只能最大部署 64 个核心，若一个 node 上存在超过 64 个待部署的核心，则需分多次部署请求发放。因此一次部署可能会对多个 node 发请求，一个 node 上也会发多次请求，多次请求发到 node 之后，node 会回复多次响应，只有所有 node 上的所有响应都收齐并且全部成功之后，才认为这次部署成功，才能回调上层函数。

因为要满足这种情况，所以任务运行模块会将请求抽象为父子关系，以上述任务部署流
程为例，父请求在上层调用任务部署接口后产生，该父请求对应一个 request_id，每当往 node发送一个请求，都会重新生成一个新的 request_id，对应新的一个子请求，并且为此子请求与父请求建立对应关系。当从 node 收到响应时，根据响应消息中的 request_id 找到等待响应的子请求信息，标记此子请求已经结束。只有当所有的子请求都结束并且收到成功响应后，才会以父请求的 request_id 回调上层的回调函数，通知上层部署已经成功完成。并且在真实实现过程中，为了防止新的子请求还没有发出去时就已经收到了之前发出去的所有子请求的响应，在创建父请求时就计算好子请求的数量，只有当收到的响应数量等于计算出的子请求的数量时，才会回调上层函数。

父请求在上层调用任务部署接口后产生，该父请求对应一个 request_id，每当往 node 发送一个请求，都会重新生成一个新的 request_id，对应新的一个子请求，并且为此子请求与父请求建立对应关系。当从 node 收到响应时，根据响应消息中的 request_id 找到等待响应的子请求信息，标记此子请求已经结束。只有当所有的子请求都结束并且收到成功响应后，才会以父请求的 request_id 回调上层的回调函数，通知上层部署已经成功完成。并且在真实实现过程中，为了防止新的子请求还没有发出去时就已经收到了之前发出去的所有子请求的响应，在创建父请求时就计算好子请求的数量，只有当收到的响应数量等于计算出的子请求的数量时，才会回调上层函数。

### 6.8.3 接口设计
![[Pasted image 20250307205833.png]]
![[Pasted image 20250307205844.png]]
![[Pasted image 20250307205853.png]]




### 6.9.2 硬件背景
![[Pasted image 20250306102114.png]]
神经拟态核分大、小核，大核可模拟 2^16 个树突，小核可模拟 2^13 个树突。在二维网格的每个位置上，都存在一个路由模块和一个神经元节点，其中路由模块可以向东西南北，以及 Local 5 个方向进行通信，Local 方向的通信是将通信消息发到当前节点上的神经元节点处理。大部分时间通信消息是在底层路由模块之间传递，当路由模块发现收到的通信消息是自身处理时，就会将消息向上投递到神经元节点处理。路由模块之间通信的消息就是硬件指令，硬件指令只能传递给相邻的核心，所以距离较远的两个核心之间传递硬件指令是通过中间路径中每一个核心的传导实现的。在传输过程中，Darwin3 芯片中核心的路由模块首先会沿 x 再沿 y 方向走到目标核心。

核心之间传递的硬件指令的最小单位为微片（flit），不同类型微片可以组成不同的业务包（package），芯片之间传递的 flit 结构都是片间包交换。

微片有四种类型：包头、包体、包尾、命令微片。每一个 flit 都是由 32 bit 组成的。
常用的片间包有三种：脉冲包、写包、读包。
![[Pasted image 20250306102958.png]]
（1）首先看写包，
![[Pasted image 20250306110246.png]]


编号为 0、1、2、3 的 DMA 分别与 west、east、north、south 的芯片方向通信。
![[Pasted image 20250306103540.png]]
（1）示例 1：从单芯片的左侧与芯片中的（4，8）核心通信，将核心中其实地址为 0x10000 的 48 个 bit 写为 0x0123456789ab。

在芯片左侧的虚拟边界核心中，选取（-1，2）作为源核心，目的核心为（4，8），由于第一个 flit 包是外层软件控制的，不是必须遵循 x 方向，后 y 方向的路由模块的传输包原则，但是源核心（-1，2）距离最近的真实物理核心为（0，2），因此选取（0，2）为第一个进入芯片的物理核心。

所以，现在我们要构造一个

### 6.9.3 方案设计
可以发现无论是哪种类型的包，其包头 flit 的结构都是一样的，因此抽象出两个函数（GenInFlitHead 和 GenOutFlitHead）用来生成输入包的 flit 包头和输出包的 flit 包头。另外，对于读包和写包，

另一方面，从芯片输出的包理论上应该进行反序列化操作，根据反序列化的结果推算出返回的信息，但是在模型部署时就已经计算好输出包的格式，将计算好的输出包作为 key 存储到内存中，当收到芯片的输出包时，通过 key 在 Cluster 的内存中查找，用查找到的 value 代替一部分反序列化的结果。