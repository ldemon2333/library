Linux 版本 2.6.24

### 1.3.2 UNIX 进程
命名空间

启用命名空间之后，以前的全局资源现在具有不同分组。每个命名空间可以包含一个特定的 PID集合，或可以提供文件系统的不同视图，在某个命名空间中挂载的卷不会传播到其他命名空间中。

命名空间很有用处。举例来说，该特性对虚拟主机供应商是有益的。他们不必再为每个用户准备一台物理计算机，而是通过称为容器的命名空间来建立系统的多个视图。从容器内部看来这是一个完整的Linux系统，而且与其他容器没有交互。容器是彼此分离的。每个容器实例看起来就像是运行Linux的一台计算机，但事实上一台物理机器可以同时运转许多这样的容器实例。这有助于更有效地使用资源。与完全的虚拟化解决方案（如KVM）相比，计算机上只需要运行一个内核来管理所有的容器。

### 1.3.3 地址空间与特权级
IA-32体系结构使用4种特权级别构成的系统，各级别可以看作是环。内环能够访问更多的功能，外环则较少，如图1-4所示。

尽管英特尔处理器区分4种特权级别，但Linux只使用两种不同的状态：核心态和用户状态。两种状态的关键差别在于对高于TASK_SIZE的内存区域的访问。

进程上下文，中断上下文。与在进程上下文中运行的主要区别是，在中断上下文中运行不能访问虚拟地址空间中的用户空间部分。

除了普通进程，系统中还有内核线程在运行。内核线程也不与任何特定的用户空间进程相关联，因此也无权处理用户空间。不过在其他许多方面，内核线程更像是普通的用户层应用程序。与在中断上下文运转的内核相比，内核线程可以进入睡眠状态，也可以像系统中的普通进程一样被调度器跟踪。内核线程可用于各种用途：从内存和块设备之间的数据同步，到帮助调度器在CPU上分配进程。


### 1.3.5 物理内存的分配
在内核分配内存时，必须记录页帧的已分配或空闲状态，以免两个进程使用同样的内存区域。由于内存分配和释放非常频繁，内核还必须保证相关操作尽快完成。内核可以只分配完整的页帧。将内存划分为更小的部分的工作，则委托给用户空间中的标准库。标准库将来源于内核的页帧拆分为小的区域，并为进程分配内存。

#### 1. 伙伴系统
内核中很多时候要求分配连续页。为快速检测内存中的连续区域，内核采用了一种古老而历经检验的技术：伙伴系统。

系统中的空闲内存块总是两两分组，每组中的两个内存块称作伙伴。伙伴的分配可以是彼此独立的。但如果两个伙伴都是空闲的，内核会将其合并为一个更大的内存块，作为下一层次上某个内存块的伙伴。图1-8示范了该系统，图中给出了一对伙伴，初始大小均为8页。
![[Pasted image 20241204222604.png]]
在应用程序释放内存时，内核可以直接检查地址，来判断是否能够创建一组伙伴，并合并为一个更大的内存块放回到伙伴列表中，这刚好是内存块分裂的逆过程。这提高了较大内存块可用的可能性。

在系统长期运行时，服务器运行几个星期乃至几个月是很正常的，许多桌面系统也趋向于长期开机运行，那么会发生称为碎片的内存管理问题。频繁的分配和释放页帧可能导致一种情况：系统中有若干页帧是空闲的，但却散布在物理地址空间的各处。换句话说，系统中缺乏连续页帧组成的较大的内存块，而从性能上考虑，却又很需要使用较大的连续内存块。通过伙伴系统可以在某种程度上减少这种效应，但无法完全消除。如果在大块的连续内存中间刚好有一个页帧分配出去，很显然这两块空闲的内存是无法合并的。在内核版本2.6.24开发期间，增加了一些有效措施来防止内存碎片，我会在第3章更详细地讨论相关的底层实现机制。

#### 2. slab 缓存
内核本身经常需要比完整页帧小得多的内存块。由于内核无法使用标准库的函数，因而必须在伙伴系统基础上自行定义额外的内存管理层，将伙伴系统提供的页划分为更小的部分。该方法不仅可以分配内存，还为频繁使用的小对象实现了一个一般性的缓存——slab缓存。它可以用两种方法分配内存。
- 对频繁使用的对象，内核定义了只包含了所需类型对象实例的缓存。
- 对小内存块的分配，内核针对不同大小的对象定义了一组slab缓存，可以像用户空间编程一样，用相同的函数访问这些缓存。不同之处是这些函数都增加了前缀k，表明是与内核相关联的：kmalloc和kfree。

虽然slab分配器在各种工作负荷下的性能都很好，但在真正规模庞大的超级计算机上使用时，出现了一些可伸缩性问题。另一方面，对真正微小的嵌入式系统来说，slab分配器的开销可能又太大了。内核提供了slab分配器的两种备选方案，可用于在相应的场景下替换slab分配器并提供更好的性能。对内核的其他部分而言，这3种方案的接口相同，因而不必关注内核中实际编译进来的底层分配器是哪一个。由于slab分配仍然是内核的标准方法，因此我不会详细讨论备选方案。图1-9综述了伙伴系统、slab分配器以及内核其他方面之间的关联。
![[Pasted image 20241204223210.png]]


### 1.3.6 计时
内核必须能够测量时间以及不同时间点的时差，进程调度就会用到该功能。jiffies是一个合适的时间坐标。名为jiffies_64和jiffies（分别是64位和32位）的全局变量，会按恒定的时间间隔递增。每种计算机底层体系结构都提供了一些执行周期性操作的手段，通常的形式是定时器中断。对前述的两个全局变量的更新可使用底层体系结构提供的各种定时器机制执行。

jiffies递增的频率同体系结构有关，取决于内核中一个主要的常数HZ。该常数的值通常介于100和1 000中间。换言之，jiffies的值每秒递增的次数在100至1 000次之间。

基于jiffies的计时相对粒度较粗，因为目前1 000 Hz已经算不上很高的频率了。在底层硬件能力允许的前提下，内核可使用高分辨率的定时器提供额外的计时手段，能够以纳秒级的精确度和分辨率
来计量时间。

计时的周期是可以动态改变的。在没有或无需频繁的周期性操作的情况下，周期性地产生定时器中断是没有意义的，这会阻止处理器降低耗电进入睡眠状态。动态改变计时周期对于供电受限的系统是很有用的，例如笔记本电脑和嵌入式系统。


### 1.3.7 系统调用
传统的系统调用按不同类别分组，如下所示：
- 进程管理
- 信号
- 文件
- 目录和文件系统
- 保护机制
- 定时器函数

### 1.3.8 设备驱动程序、块设备和字符设备
对外设的访问可利用/dev目录下的设备文件来完成，程序对设备的处理完全类似于常规的文件。设备驱动程序的任务在于支持应用程序经由设备文件与设备通信。换言之，使得能够按适当的方式在设备上读取/写入数据。


### 1.3.9 网络
网卡也可以通过设备驱动程序控制，但在内核中属于特殊状况，因为网卡不能利用设备文件访问。原因在于在网络通信期间，数据打包到了各种协议层中。在接收到数据时，内核必须针对各协议层的处理，对数据进行拆包与分析，然后才能将有效数据传递给应用程序。在发送数据时，内核必须首先根据各个协议层的要求打包数据，然后才能发送。

为支持通过文件接口处理网络连接（按照应用程序的观点），Linux使用了源于BSD的套接字抽象。套接字可以看作应用程序、文件接口、内核的网络实现之间的代理。

### 1.3.10 文件系统
内核必须提供一个额外的软件层，将各种底层文件系统的具体特性与应用层（和内核自身）隔离开来。该软件层称为VFS（Virtual Filesystem或Virtual Filesystem Switch，虚拟文件系统或虚拟文件系统交换器）。VFS既是向下的接口（所有文件系统都必须实现该接口），同时也是向上的接口（用户进程通过系统调用最终能够访问文件系统功能）。如图1-10所示。
![[Pasted image 20241204224029.png]]

### 1.3.11 模块和热插拔
模块用于在运行时动态地向内核添加功能，如设备驱动程序、文件系统、网络协议等，实际上内核的任何子系统几乎都可以模块化。这消除了宏内核与微内核相比一个重要的不利之处。

模块还可以在运行时从内核卸载。模块在本质上不过是普通的程序，只是在内核空间执行。模块必须提供某些代码段在模块初始化（和终止）时执行，以便向内核注册和注销模块。另外，模块代码与普通内核代码的权利（和义务）都是相同的，可以像编译到内核中的代码一样，访问内核中所有的函数和数据。

只提供二进制代码的模块加载到内核，可以将必要的驱动程序自动添加到内核中。加载只提供二进制代码的模块会污染内核，每当发生点坏事，过错自然会归咎于相应的模块。如果内核被污染，则故障转储文件中会标记出来，而内核开发者一般不愿意解决此类导致崩溃的问题。因为二进制模块可能使内核的每个部分都发生了充分的震荡，不能假定内核仍然可以按预定的设计工作，所以这种情况下的支持工作最好留给相关模块的厂商处理。

### 1.3.12 缓存
由于内核是通过基于页的内存映射来实现访问块设备的，因此缓存也按页组织，也就是说整页都缓存起来，故称为页缓存（page cache）。

### 1.3.14 对象管理和引用计数
内核中很多地方都需要跟踪记录C语言中结构的实例。尽管这些对象的用法大不相同，但各个不同子系统的某些操作非常类似，例如引用计数。这导致了代码复制。由于这是个糟糕的问题，因此在
内核版本2.5的开发期间，内核采用了一般性的方法来管理内核对象。所引入的框架并不只是为了防止代码复制，同时也为内核不同部分管理的对象提供了一致的视图，在内核的许多部分可以有效地使用相关信息，如电源管理。

一般性的内核对象机制可用于执行下列对象操作：
- 引用计数；
- 管理对象链表（集合）；
- 集合加锁；
- 将对象属性导出到用户空间（通过sysfs文件系统）。

#### 1. 一般性的内核对象
![[Pasted image 20241204225441.png]]
kobject与面向对象编程语言（像C++或Java）中的对象概念的相似性决不是巧合。kobject抽象实际上提供了在内核使用面向对象技术的可能性，而无需C++的所有额外机制（以及二进制代码大小的膨胀和额外开销）。

kref 类型为 struct kref，用于简化引用计数的管理。

表1-1列出了内核提供用于操作kobject实例的标准操作，实质上是作用于包含kobject的结构。用于管理引用计数的kref结构如下所示：
![[Pasted image 20241204225823.png]]
refcount是一个原子数据类型，给出了内核中当前使用某个对象的计数。在计数器到达0时，就不需要该对象了，可以从内存中删除。
![[Pasted image 20241204225902.png]]

在kref的设计中，将一个值封装在结构中，防止直接操纵该值。必须使用kref_init来初始化 kref。如果要使用某个对象，则需要首先调用kref_get对引用计数器加1。在对象不再使用时，则需要调用kref_put将计数器减1。

#### 2. 对象集合
在很多情况下，必须将不同的内核对象归类到集合中，例如，所有字符设备集合，或所有基于PCI
的设备集合。用到的数据结构定义如下：
![[Pasted image 20241204230035.png]]

### 1.3.15 数据类型
#### 3. per-cpu 变量
有若干CPU的SMP系统上，会为每个CPU分别创建变量的一个实例。用于某个特定CPU的实例可以通过get_cpu(name, cpu)获得，其中smp_processor_id()可以返回当前活动处理器的ID，用作前述的cpu参数。

采用per-cpu变量有下列好处：所需数据很可能存在于处理器的缓存中，因此可以更快速地访问。
如果在多处理器系统中使用可能被所有CPU同时访问的变量，可能会引发一些通信方面的问题，采用上述概念刚好绕过了这些问题。

#### 4. 访问用户空间
源代码中的多处指针都标记为__user，该标识符对用户空间程序设计是未知的。内核使用该记号来标识指向用户地址空间中区域的指针，在没有进一步预防措施的情况下，不能轻易访问这些指针指向的区域。这是因为内存是通过页表映射到虚拟地址空间的用户空间部分的，而不是由物理内存直
接映射的。因此内核需要确保指针所指向的页帧确实存在于物理内存中。


## 1.4 为什么内核是特别的
附录B讨论了在内核开发中使用调试器的各种技巧，但与用户层对应的方法相比都需要更多的工作

# 2.进程管理和调度
## 2.2 进程生命周期
僵尸是如何产生的？其原因在于UNIX操作系统下进程创建和销毁的方式。在两种事件发生时，程序将终止运行。第一，程序必须由另一个进程或一个用户杀死（通常是通过发送SIGTERM或SIGKILL信号来完成，这等价于正常地终止进程）；进程的父进程在子进程终止时必须调用或已经调用wait4（读做wait for）系统调用。 这相当于向内核证实父进程已经确认子进程的终结。该系统调用使得内核可以释放为子进程保留的资源。

只有在第一个条件发生（程序终止）而第二个条件不成立的情况下（wait4），才会出现“僵尸”状态。在进程终止之后，其数据尚未从进程表删除之前，进程总是暂时处于“僵尸”状态。有时候（例如，如果父进程编程极其糟糕，没有发出wait调用），僵尸进程可能稳定地寄身于进程表中，直至下一次系统重启。从进程工具（如ps或top）的输出，可以看到僵尸进程。因为残余的数据在内核中占据的空间极少，所以这几乎不是问题。

在内核2.5开发期间，一个称之为内核抢占（kernel preemption）的选项添加到内核。 该选项支持在紧急情况下切换到另一个进程，甚至当前是处于核心态执行系统调用（中断处理期间是不行的）。尽管内核会试图尽快执行系统调用，但对于依赖恒定数据流的应用程序来说，系统调用所需的时间仍然太长了。内核抢占可以减少这样的等待时间，因而保证“更平滑的”程序执行。但该特性的代价是增加内核的复杂度，因为接下来有许多数据结构需要针对并发访问进行保护，即使在单处理器系统上也是如此。

## 2.3 进程表示
task_struct 中对进程管理的实现特别重要的一些成员。

state 指定了进程的当前状态，可使用下列值：
- TASK_RUNNING 意味着进程处于可运行状态
- TASK_INTERRUPTIBLE是针对等待某事件或其他资源的睡眠进程设置的。在内核发送信号给该进程表明事件已经发生时，进程状态变为TASK_RUNNING，它只要调度器选中该进程即可恢复执行。
- TASK_UNINTERRUPTIBLE用于因内核指示而停用的睡眠进程。它们不能由外部信号唤醒，只能由内核亲自唤醒。
- TASK_STOPPED 表示进程特意停止运行，例如，由调试器暂停。
- TASK_TRACED 本来不是进程状态，用于从停止的进程中，将当前被调试的那些与常规的进程区分开来。
等等

Linux提供资源限制（resource limit，rlimit）机制，对进程使用系统资源施加某些限制。该机制利用了task_struct中的rlim数组，数组项类型为struct rlimit。
![[Pasted image 20241205154057.png]]
- rlim_cur 是进程当前的资源限制，也称之为软限制（soft limit）
- rlim_max 是该限制的最大容许值，因此也称之为硬限制（hard limit）

系统调用 setrlimit 来增减当前限制，但不能超出 rllim_max 指定的值。getrlimits 用于检查当前限制。

rlim 数组中的位置标识了受限制资源的类型。

![[Pasted image 20241205161234.png]]
![[Pasted image 20241205161427.png]]

如果某一类资源没有使用限制，则将 rlim_max 设置为 RLIM_INFINITY。以下是例外情况：
- 打开文件的数目（RLIMIT_NOFILE，默认限制在1024）
- 每用户的最大进程数（RLIMIT_NPROC），定义为 max_threads/2。max_threads 是一个全局变量，指定了在把八分之一可用内存用于管理线程信息的情况下，可以创建的线程数目

init进 程 的 限 制 在 系 统 启 动 时 即 生 效 ， 定 义 在 include/asm-generic-resource.h中 的 INIT_RLIMITS。

### 2.3.1 进程类型
clone 系统调用，但新进程不是独立于父进程的，而可以与其共享某些资源。clone 用于实现线程。

### 2.3.2 命名空间
命名空间提供了虚拟化的一种轻量级形式。
#### 1.概念
命名空间提供了一种不同的解决方案，所需资源较少。在虚拟化的系统中，一台物理计算机可以运行多个内核，可能是并行的多个不同的操作系统。而命名空间则只使用一个内核在一台物理计算机上运作，前述的所有全局资源都通过命名空间抽象起来。这使得可以将一组进程放置到容器中，各个容器彼此隔离。隔离可以使容器的成员与其他容器毫无关系。但也可以通过允许容器进行一定的共享，来降低容器之间的分隔。例如，容器可以设置为使用自身的PID集合，但仍然与其他容器共享部分文件系统。

本质上，命名空间建立了系统的不同视图。此前的每一项全局资源都必须包装到容器数据结构中，只有资源和包含资源的命名空间构成的二元组仍然是全局唯一的。
![[Pasted image 20241204234044.png]]

子容器不了解系统中的其他容器，但父容器知道子命名空间的存在，也可以看到其中执行的所有进程。

chroot 系统调用，该方法可以将进程限制到文件系统的某一部分，是一种简单的命名空间机制。

新的命名空间可以用下面两种方法创建：
- 在用fork或clone系统调用创建新进程时，有特定的选项可以控制是与父进程共享命名空间，还是建立新的命名空间。
- unshare系统调用将进程的某些部分从父进程分离，其中也包括命名空间。

在进程已经使用上述的两种机制之一从父进程命名空间分离后，父子进程就虚拟化了。

#### 2. 实现
命名空间的实现需要两个部分：每个子系统的命名空间结构，将此前所有的全局组件包装到命名空间中；将给定进程关联到所属各个命名空间的机制。
![[Pasted image 20241205163100.png]]

子系统此前的全局属性现在封装到命名空间中，每个进程关联到一个选定的命名空间。每个可以感知命名空间的内核子系统都必须提供一个数据结构，将所有通过命名空间形式提供的对象集中起来。struct nsproxy用于汇集指向特定于子系统的命名空间包装器的指针：
![[Pasted image 20241205163243.png]]
- UTS 命名空间包含了运行内核的名称、版本、底层体系结构等信息。UTS 是UNIX Timesharing System 的简称
- 保存在 struct ipc_namespace 中的所有与进程间通信（IPC）有关的信息
- 已经装载的文件系统的视图，在 struct mnt_namespace 中给出
- 有关进程ID的信息，pid_namespace
- user_namespace 保存的用于限制每个用户资源使用的信息
- net_ns 包含所有网络相关的命名空间参数

由于在创建新进程可使用 fork 建立一个新的命名空间，因此必须提供控制该行为的适当的标志。每个命名空间都有一个对应的标志：
![[Pasted image 20241205171950.png]]
init_nsproxy定义了初始的全局命名空间，其中维护了指向各子系统初始的命名空间对象的指针：
![[Pasted image 20241205191053.png]]

to do

### 2.3.3 进程 ID 号
UNIX 进程总是会分配一个号码用于在其命名空间中唯一地标识它们。称为PID
#### 1. 进程ID
其他ID
- 处于某个线程组中的所有进程都有统一的线程组ID（TGID）。如果进程使用线程，则其PID 和 TGID 相同。线程组中的主进程被称作组长（group leader）。通过clone创建的所有线程的task_struct的group_leader成员，会指向组长的task_struct实例。
- PGID, 独立进程可以合并成进程组（使用setpgrp系统调用）。进程组成员的task_struct的pgrp属性值都是相同的，即进程组组长的PID。进程组简化了向组的所有成员发送信号的操作。使用管道连接的进程包含在同一个进程组中。
- 几个进程组可以合并成一个会话，会话中的所有进程都有同样的会话ID，保存在task_struct的session成员中。SID可以使用setsid系统调用设置。它可以用于终端程序设计。
命名空间中的所有PID对父命名空间都是可见的，但子命名空间无法看到父命名空间的PID。区分局部 ID 和全局 ID。
- 全局 ID 是在内核本身和初始命名空间中的唯一ID号。
- 局部 ID 属于某个特定的命名空间，不具备全局有效性。

全局PID和TGID直接保存在task_struct中，分别是task_struct的pid和tgid成员：
![[Pasted image 20241205164403.png]]
会话和进程组ID不是直接包含在task_struct本身中，但保存在用于信号处理的结构中。task_struct->signal->\_\_session表示全局SID。

#### 2. 管理 PID
PID 分配器
![[Pasted image 20241205165014.png]]
- 每个PID命名空间都具有一个进程，其发挥的作用相当于全局的init进程。init的一个目的是对孤儿进程调用wait4，命名空间局部的init变体也必须完成该工作。child_reaper保存了指向该进程的task_struct的指针。
- parent是指向父命名空间的指针，level表示当前命名空间在命名空间层次结构中的深度。初始命名空间的level为0，该命名空间的子空间level为1，下一层的子空间level为2，依次递推。level的计算比较重要，因为level较高的命名空间中的ID，对level较低的命名空间来说是可见的。从给定的level设置，内核即可推断进程会关联到多少个ID。

![[Pasted image 20241205165330.png]]
![[Pasted image 20241205165341.png]]

在 Linux 内核中，`struct pid` 是内核对进程标识符（PID，Process ID）的内部表示，封装了与进程标识相关的信息。它为内核提供了一种更灵活和高效的方式来管理进程、线程和相关的调度机制，而不是直接使用整数型的 PID。

---

### 为什么需要 `struct pid`？

尽管用户空间使用简单的整数型 PID 来标识进程，但在内核中，需要更复杂的数据结构来处理以下问题：

1. **多种 PID 类型**：
    
    - 一个进程可能属于多个 PID 类型，例如：
        - 普通进程 ID（`PIDTYPE_PID`）。
        - 线程组 ID（`PIDTYPE_TGID`）。
        - 会话 ID（`PIDTYPE_SID`）。
    - `struct pid` 支持将一个进程的多个 PID 类型组织在一起，方便管理。
2. **PID 命名空间**：
    
    - Linux 支持 PID 命名空间（PID Namespace），不同的命名空间可以有相同的 PID。
    - `struct pid` 支持这种命名空间的隔离，使得不同命名空间的 PID 可以独立管理。
3. **高效管理**：
    
    - 内核需要高效地在不同的进程组或命名空间中查找和管理 PID。
    - 使用 `struct pid` 可以通过链表或哈希表快速找到与 PID 相关的结构或信息。

---

### `struct pid` 的定义

`struct pid` 的定义位于内核源代码的 `include/linux/pid.h` 文件中（在现代内核中可能有一些变化）。以下是其核心结构：

```c
struct pid {
    struct hlist_node tasks[PIDTYPE_MAX]; // 不同类型的任务链表
    struct rcu_head rcu;                 // 用于 RCU（Read-Copy-Update）机制的销毁操作
    atomic_t count;                      // 引用计数
    unsigned int level;                  // 命名空间的层级
    struct upid numbers[1];              // 进程的 PID 信息（可能会动态扩展）
};
```

---

### `struct pid` 各成员的作用

1. **`tasks[PIDTYPE_MAX]`**：
    
    - 这是一个哈希链表数组，用于将该 `pid` 关联到不同类型的任务。
    - 每种类型（如 `PIDTYPE_PID`, `PIDTYPE_TGID`, `PIDTYPE_SID`）都有一个单独的链表。
    - 通过 `tasks`，内核可以快速找到属于该 PID 的所有任务。
2. **`rcu`**：
    
    - RCU（Read-Copy-Update）机制是 Linux 内核中一种高效的同步机制，用于处理并发访问。
    - 当一个 `pid` 被删除时，`rcu` 确保其引用的对象在安全的情况下被销毁。
3. **`count`**：
    
    - 引用计数，用于记录有多少地方引用了该 `pid`。
    - 当引用计数降到 0 时，`struct pid` 可以安全地被释放。
4. **`level`**：
    
    - 表示 `pid` 所属的命名空间的层级。
    - 命名空间是一种内核虚拟化机制，不同层级的命名空间可以拥有不同的 PID。
5. **`numbers[1]`**：
    
    - 这是一个变长数组，包含了与 `pid` 相关的所有命名空间的 PID。
    - 每个 `upid` 包含一个 PID 值和指向该命名空间的指针。
    - `upid` 的定义通常如下：
        
        ```c
        struct upid {
            int nr;                     // 实际的 PID 值
            struct pid_namespace *ns;  // 所属的 PID 命名空间
            struct hlist_node pid_chain; // 哈希链表节点
        };
        ```
        

---

### `struct pid` 的用法

1. **创建和分配 `struct pid`**： 内核通过函数如 `alloc_pid()` 分配一个新的 `struct pid`。
    
    ```c
    struct pid *alloc_pid(struct pid_namespace *ns);
    ```
    
2. **获取 PID 的任务链表**： 可以通过 `tasks` 查找与该 PID 相关的所有任务。例如，所有属于一个线程组的任务。
    
3. **管理 PID 命名空间**： `struct pid` 的设计允许进程同时拥有多个命名空间的 PID，使得进程管理更加灵活。
    
4. **引用计数和销毁**： 在内核中，引用计数的增加和减少使用 `get_pid()` 和 `put_pid()` 函数：
    
    ```c
    struct pid *get_pid(struct pid *pid);  // 增加引用计数
    void put_pid(struct pid *pid);        // 减少引用计数
    ```

![[Pasted image 20241205165124.png]]

一个进程可能在多个命名空间中可见，而其在各个命名空间中的局部ID各不相同。level表示可以看到该进程的命名空间的数目（换言之，即包含该进程的命名空间在命名空间层次结构中的深度），而numbers是一个upid实例的数组，每个数组项都对应于一个命名空间。注意该数组形式上只有一个数组项，如果一个进程只包含在全局命名空间中，那么确实如此。由于该数组位于结构的末尾，因此只要分配更多的内存空间，即可向数组添加附加的项。

辅助数据结构pid_link可以将task_struct连接到表头在struct pid中的散列表上。
![[Pasted image 20241205192913.png]]
![[Pasted image 20241205193114.png]]
假如已经分配了 struct pid 的一个新实例，并设置用于给定的 ID 类型。它会如下附加到 task_struct:
![[Pasted image 20241205193727.png]]

这段代码是一个 `fastcall` 调用的函数，名为 `attach_pid`，它用于将 `pid`（进程 ID）关联到指定进程 `task` 的进程组或线程组中。具体来说，它将 `pid` 添加到目标 `task` 的 PID 链表中。


### 1. `struct pid_link *link;`

```c
struct pid_link *link;
```

- `struct pid_link` 是用来管理进程和进程组（或线程组）之间关系的结构体。每个进程的 `pids` 数组中都有一个 `pid_link` 结构，表示不同类型的 PID 和它们的关联信息。
- `link` 是一个指针，后面用来存储 `task->pids[type]` 的引用。

### 2. `link = &task->pids[type];`

```c
link = &task->pids[type];
```

- `task->pids[type]` 是 `task_struct` 结构体中的一个数组，`pids` 数组用于存储不同类型的 PID（如线程组 PID、进程组 PID 等）。每个 `task_struct` 结构体包含一个 `pids` 数组，数组的每一项表示该进程的不同 PID 类型。
- `link` 指向这个数组中的 `type` 对应的项，获取到的是该进程与 `type` 类型的 PID 之间的链接信息（即 `pid_link`）。

### 3. `link->pid = pid;`

```c
link->pid = pid;
```

- 这一行将 `link` 结构体中的 `pid` 成员设置为 `pid`，即将传入的 `pid` 结构体与 `task` 的 `pids[type]` 关联起来。
- `link->pid` 是 `task_struct` 结构体中 `pids` 数组元素的一个成员，表示与当前进程 `task` 关联的 `pid`。这里将 `task` 进程与传入的 `pid` 绑定。

### 4. `hlist_add_head_rcu(&link->node, &pid->tasks[type]);`

```c
hlist_add_head_rcu(&link->node, &pid->tasks[type]);
```

- `hlist_add_head_rcu` 是一个用于将一个节点添加到哈希链表头部的函数，采用了 **RCU（Read-Copy Update）** 机制，确保在并发访问时的安全性。
- `link->node` 是 `link` 结构体中的一个 `hlist_node` 类型的成员，用于将 `link` 连接到一个哈希链表中。
- `pid->tasks[type]` 是一个哈希链表，存储所有属于该 `pid` 类型的任务（即，属于该 `pid` 的所有进程或线程）。通过这行代码，`link` 被插入到与 `pid` 对应的任务链表中，确保进程与其 PID 类型之间的关联在链表中得到维护。



### 总结：

这段代码的功能是将一个进程（由 `task` 指定）与一个指定类型的进程 ID（由 `pid` 给出）关联起来，并把这个关系添加到内核中的进程哈希链表中。具体步骤如下：

1. 从 `task` 的 `pids` 数组中获取指定类型的 PID 关联信息（`pid_link`）。
2. 将传入的 `pid` 结构体与该 `task` 进程的 PID 进行绑定。
3. 将这个关联信息添加到 `pid` 类型对应的进程任务链表中。


#### 函数
内核的两个任务：
- 给出局部 ID 和对应的命名空间，查找此二元组描述的 task_struct
- 给出 task_struct, ID 类型，命名空间，取得命名空间局部的ID

首先是如何将 task_struct 实例变为ID
1. 获得与task_struct 关联的 pid 实例
![[Pasted image 20241205194438.png]]

获取tgid类似，tgid 是线程组组长的 PID 而已，只要将上述实现替换为task->
group_leader->pids\[PIDTYPE_PID\].pid即可。

找出进程组ID则需要使用 PIDTYPE_PGID 作为数组索引，但该 ID 仍然需要从线程组组长的 task_struct 实例获取：
![[Pasted image 20241205194820.png]]
2. 在获得pid实例之后，从struct pid 的numbers数组中 uid 信息，获得ID
![[Pasted image 20241205195132.png]]
因为父命名空间可以看到子命名空间中的PID，反过来却不行，内核必须确保当前命名空间的level小于或等于产生局部PID的命名空间的level。

内核其他辅助函数：
- pid_vnr 返回该ID所属的命名空间所看到的局部PID
- pid_nr 则获取从init 进程看到的全局PID
这两个函数都依赖于pid_nr_ns，并自动选择适当的level：0用于获取全局PID，而pid->level则用于获取局部PID。
![[Pasted image 20241205195552.png]]

内核如何将数字 PID 和命名空间转换为 pid 实例
1. 给出进程的局部 PID和关联的命名空间，为确定 pid 实例（这是PID的内核表示）。首先根据PID和命名空间指针计算在 pid_hash 数组中的索引，然后遍历散列表直至找到所要的元素。这是通过辅助函数find_pid_ns处理的：
![[Pasted image 20241205200547.png]]
这里 nr 就是局部 PID，进程关联的命名空间 ns
2. pid_task 取出pid->tasks\[type\] 散列表中的第一个 task_struct 实例。

这两个步骤可以通过辅助函数find_task_by_pid_type_ns完成：
![[Pasted image 20241205200902.png]]
一些简单一点的辅助函数基于最一般性的find_task_by_pid_type_ns：
- find_task_by_pid_ns(pid_t nr, struct pid_namespace * ns)根据给出的数字PID和进程的命名空间来查找task_struct实例。
- find_task_by_vpid(pid_t vnr)通过局部数字PID查找进程
- find_task_by_pid(pid_t nr)通过全局数字PID查找进程。
内核源代码中许多地方都需要find_task_by_pid，因为很多特定于进程的操作（例如，使用kill发送一个信号）都通过PID标识目标进程。

#### 3. 生成唯一的 PID
为跟踪已经分配和仍然可用的 PID，内核使用一个大的位图，其中每个 PID 由一个比特标识。PID 的值为对应比特在位图中的位置计算而来。

分配一个空闲的 PID，本质上就等同于寻找位图中第一个值为 0 的比特，接下来将该比特设置为1。反之，释放一个 PID。
![[Pasted image 20241208231441.png]]

在建立一个新进程时，进程可能在多个命名空间中是可见的。对每个这样的命名空间，都需要生成一个局部 PID。这是在 alloc_pid 中处理的：
![[Pasted image 20241208231601.png]]
起始于建立进程的命名空间，一直到初始的全局命名空间，内核会为每个命名空间分别创建一个局部PID。包含在struct pid中的所有upid都用重新生成的PID更新其数据。每个upid实例都必须置于PID散列表中：
![[Pasted image 20241208231939.png]]
### 2.3.4 进程关系
除了源于ID连接的关系之外，内核还负责管理建立在UNIX进程创建模型之上“家族关系”。相关讨论一般使用下列术语。
- 父子进程
- 兄弟关系
![[Pasted image 20241208232122.png]]
- children 是链表表头，该链表中保存进程的所有子进程
- sibling 用于将兄弟进程彼此连接起来

## 2.4 进程管理相关的系统调用
从用户状态切换到核心态的方法，依不同的体系结构而各有不同。在附录A中，我详细讲述了用于在这两种状态之间切换的机制，并解释了用户空间和内核空间之间如何交换参数。就目前而言，将内核视为由C标准库使用的“程序库”即可，我在第1章简要地提到过这一点。

### 2.4.1 进程复制
传统的UNIX中用于复制进程的系统调用是fork。但它并不是Linux为此实现的唯一调用，实际上Linux实现了3个
1. fork 是重量级调用，因为它建立了父进程的一个完整副本，然后作为子进程执行。为减少与该调用相关的工作量，Linux使用了写时复制（copy-on-write）技术。
2. vfork类似于fork，但并不创建父进程数据的副本。相反，父子进程之间共享数据。这节省了大量CPU时间（如果一个进程操纵共享数据，则另一个会自动注意到）。
vfork设计用于子进程形成后立即执行execve系统调用加载新程序的情形。在子进程退出或开始新程序之前，内核保证父进程处于堵塞状态。

引用手册页vfork(2)的文字，“非常不幸，Linux从过去复活了这个幽灵”。由于fork使用了写时复制技术，vfork速度方面不再有优势，因此应该避免使用它。
3. clone产生线程，可以对父子进程之间的共享、复制进行精确控制。

#### 1. 写时复制
内核可以使用技巧规避该问题。并不复制进程的整个地址空间，而是只复制其页表。这样就建立了虚拟地址空间和物理内存页之间的联系。

当然，父子进程不能允许修改彼此的页，这也是两个进程的页表对页标记了只读访问的原因，即使在普通环境下允许写入也是如此。假如两个进程只能读取其内存页，那么二者之间的数据共享就不是问题，因为不会有修改。只要一个进程试图向复制的内存页写入，处理器会向内核报告访问错误（此类错误被称作缺页异
常）。内核然后查看额外的内存管理数据结构（参见第4章），检查该页是否可以用读写模式访问，还是只能以只读模式访问。如果是后者，则必须向进程报告段错误。读者会在第4章看到，缺页异常处理程序的实际实现要复杂得多，因为还必须考虑其他方面的问题，例如换出的页。如果页表项将一页标记为“只读”，但通常情况下该页应该是可写的，内核可根据此条件来判断该页实际上是COW页。因此内核会创建该页专用于当前进程的副本，当然也可以用于写操作。

#### 2. 执行系统调用
fork、vfork和clone系统调用的入口点分别是sys_fork、sys_vfork和sys_clone函数。其定义依赖于具体的体系结构，因为在用户空间和内核空间之间传递参数的方法因体系结构而异（更多细节请参见第13章）。上述函数的任务是从处理器寄存器中提取由用户空间提供的信息，调用体系结构无关的do_fork函数，后者负责进程复制。该函数的原型如下：
![[Pasted image 20241208233048.png]]
![[Pasted image 20241208233100.png]]
- clone_flags 是一个标志集合，用来指定控制复制过程的一些属性。最低字节指定了在子进程终止时时发给父进程的信号号码。其余的高位字节保存了各种常数。
- stack_start 是用户状态下的起始地址。
- regs是一个指向寄存器集合的指针，其中以原始形式保存了调用参数。该参数使用的数据类型是特定于体系结构的struct pt_regs，其中按照系统调用执行时寄存器在内核栈上的存储顺序，保存了所有的寄存器（更详细的信息，请参考附录A）。
- stack_size是用户状态下栈的大小。该参数通常是不必要的，设置为0。
- parent_tidptr和child_tidptr是指向用户空间中地址的两个指针，分别指向父子进程的PID。NPTL（Native Posix Threads Library）库的线程实现需要这两个参数。

不同的fork变体，主要是通过标志集合区分。在大多数体系结构上，典型的fork调用的实现方式与IA-32处理器相同。
![[Pasted image 20241208233552.png]]

唯一使用的标志是SIGCHLD。这意味着在子进程终止后发送SIGCHLD信号通知父进程。最初，父子进程的栈地址相同（起始地址保存在IA-32系统的esp寄存器中）。但如果操作栈地址并写入数据，则COW机制会为每个进程分别创建一个栈副本。

如果do_fork成功，则新建进程的PID作为系统调用的结果返回，否则返回错误码（负值）。

sys_vfork的实现与sys_fork只是略微不同，前者使用了额外的标志（CLONE_VFORK和CLONE_VM，其语义下文讨论）。

sys_clone的实现方式与上述调用相似，差别在于do_fork如下调用：
![[Pasted image 20241208233735.png]]
标志不再是硬编码的，而是可以通过各个寄存器参数传递到系统调用。因而该函数的第一部分负责提取这些参数。另外，也不再复制父进程的栈，而是可以指定新的栈地址（newsp）。在生成线程时，可能需要这样做，线程可能与父进程共享地址空间，但线程自身的栈可能在另一个地址空间。另外还指定了用户空间中的两个指针（parent_tidptr和child_tidptr），用于与线程库通信。

#### 3. do_fork 的实现
所有3个fork机制最终都调用了kernel/fork.c中的do_fork（一个体系结构无关的函数），其代码流程如图2-7所示。
![[Pasted image 20241208233958.png]]
do_fork以调用copy_process开始，后者执行生成新进程的实际工作，并根据指定的标志重用父进程的数据。在子进程生成之后，内核必须执行下列收尾操作：
- 由于fork要返回新进程的PID，因此必须获得PID。这是比较复杂的，因为如果设置了CLONE_NEWPID标志，fork操作可能创建了新的PID命名空间。如果是这样，则需要调用task_pid_nr_ns获取在父命名空间中为新进程选择的PID，即发出fork调用的进程所在的命名空间。如果PID命名空间没有改变，调用task_pid_vnr获取局部PID即可，因为新旧进程都在同一个命名空间中。
![[Pasted image 20241208234143.png]]
- 如果将要使用Ptrace（参见第13章）监控新的进程，那么在创建新进程后会立即向其发送 SIGSTOP信号，以便附接的调试器检查其数据。
- 子进程使用wake_up_new_task唤醒。换言之，即将其task_struct添加到调度器队列
- 如果使用vfork机制（内核通过设置的CLONE_VFORK标志识别），必须启用子进程的完成机制（completions mechanism）。子进程的task_struct的vfork_done成员即用于该目的。借助于wait_for_completion函数，父进程在该变量上进入睡眠状态，直至子进程退出。在进程终止（或用execve启动新应用程序）时，内核自动调用complete（vfork_done）。这会唤醒所有因该变量睡眠的进程。在第14章中，我会非常详细地讨论完成机制的实现。
- 通过采用这种方法，内核可以确保使用vfork生成的子进程的父进程会一直处于不活动状态，直至子进程退出或执行一个新的程序。父进程的临时睡眠状态，也确保了两个进程不会彼此干扰或操作对方的地址空间。

#### 4. 复制进程
![[Pasted image 20241208234615.png]]
复制进程的行为受到相当多标志的控制。clone(2)的手册页详细讲述了这些标志。我们更感兴趣的是，某些标志组合没有意义，内核必须捕获这种情况。例如，一方面请求创建一个新命名空间（CLONE_NEWNS），而同时要求与父进程共享所有的文件系统信息（CLONE_FS），就是没有意义的。捕获这种组合并返回错误码并不复杂：
![[Pasted image 20241208234721.png]]
此处很适宜回忆简介部分提到的：Linux有时候在操作成功时需要返回指针，而在失败时则返回错误码。遗憾的是，C语言每个函数只允许一个直接的返回值，因此任何有关可能错误的信息都必须编码到指针中。虽然一般而言指针可以指向内存中的任意位置，而Linux支持的每个体系结构的虚拟地址空间中都有一个从虚拟地址0到至少4 KiB的区域，该区域中没有任何有意义的信息。因此内核可
以重用该地址范围来编码错误码。如果fork的返回值指向前述的地址范围内部，那么该调用就失败了，其原因可以由指针的数值判断。ERR_PTR是一个辅助宏，用于将数值常数（例如EINVAL，非法操作）编码为指针。

还需要进一步检查一些标志。
- 在用 CLONE_THREAD 创建一个线程时，必须用 CLONE_SIGHAND 激活信号共享。通常情况下，一个信号无法发送到线程组中的各个线程。
- 只有在父子进程之间共享虚拟地址空间时（CLONE_VM），才能提供共享的信号处理程序。因此类似的想法是，要想达到同样的效果，线程也必须与父进程共享地址空间。
在内核建立了自洽的标志集之后，则用dup_task_struct来建立父进程task_struct的副本。用于子进程的新的task_struct实例可以在任何空闲的内核内存位置分配。

父子进程的task_struct实例只有一个成员不同：新进程分配了一个新的核心态栈，即task_struct->stack。通常栈和thread_info一同保存在一个联合中，thread_info保存了线程所需的所有特定于处理器的底层信息。
![[Pasted image 20241208235115.png]]
在大多数体系结构上，使用一两个内存页来保存一个thread_union的实例。在IA-32上，两个内存页是默认设置，因此可用的内核栈长度略小于8 KiB，其中一部分被thread_info实例占据。不过要注意，配置选项4KSTACKS会将栈长度降低到4 KiB，即一个页面。如果系统上有许多进程在运行，这样做是有利的，因为每个进程可以节省一个页面。另一方面，对于经常趋向于使用过多栈空间的外部驱动程序来说，这可能导致问题。标准发布版所提供的内核，其所有核心部分都已经设计为能够在4KiB栈长度配置下运转流畅，但一旦需要只提供二进制代码的驱动程序，就可能引发问题（糟糕的是，过去已经发生过这类问题），此类驱动通常习于向可用的栈空间乱塞数据。

thread_info保存了特定于体系结构的汇编语言代码需要访问的那部分进程数据。尽管该结构的定义因不同的处理器而不同，大多数系统上该结构的内容类似于下列代码。
![[Pasted image 20241208235457.png]]
- flags可以保存各种特定于进程的标志，我们对其中两个特别感兴趣，如下所示。
	- 如果进程有待决信号则置位TIF_SIGPENDING。
	- TIF_NEED_RESCHED表示该进程应该或想要调度器选择另一个进程替换本进程执行。
- cpu说明了进程正在其上执行的CPU数目
- preempt_count实现内核抢占所需的一个计数器，我将在2.8.3节讨论。
- addr_limit指定了进程可以使用的虚拟地址的上限。如前所述，该限制适用于普通进程，但内核线程可以访问整个虚拟地址空间，包括只有内核能访问的部分。
- restart_block用于实现信号机制

图2-9给出了task_struct、thread_info和内核栈之间的关系。在内核的某个特定组件使用了过多栈空间时，内核栈会溢出到thread_info部分，这很可能会导致严重的故障。此外在紧急情况下输出调用栈回溯时将会导致错误的信息出现，因此内核提供了kstack_end函数，用于判断给出的地址是否位于栈的有效部分之内。
![[Pasted image 20241209000159.png]]
dup_task_struct会复制父进程task_struct和thread_info实例的内容，但stack则与新的thread_info实例位于同一内存区域。这意味着父子进程的task_struct此时除了栈指针之外是完全相同的，但子进程的task_struct实例会在copy_process过程中修改。

此外所有体系结构都将两个名为current和current_thread_info的符号定义为宏或函数。其语义如下所示。
- current_thread_info可获得指向当前执行进程的thread_info实例的指针。其地址可以根据内核栈指针确定，因为thread_info实例总是位于栈顶。指向内核栈的指针通常保存在一个特别保留的寄存器中，因为每个进程分别使用各自的内核栈，进程到栈的映射是唯一的。
- current给出了当前进程task_struct实例的地址。该函数在源代码中出现非常频繁。该地址可以使用current_thread_info()确定：current = current_thread_info()->task。

我们继续讨论copy_process。在dup_task_struct成功之后，内核会检查当前的特定用户在创建新进程之后，是否超出了允许的最大进程数目：
![[Pasted image 20241209000518.png]]
拥有当前进程的用户，其资源计数器保存一个user_struct实例中，可通过task_struct->user访问，特定用户当前持有进程的数目保存在user_struct->processes。如果该值超出rlimit设置的限制，则放弃创建进程，除非当前用户是root用户或分配了特别的权限（CAP_SYS_ADMIN或CAP_SYS_
RESOURCE）。检测root用户很有趣：回想上文，每个PID命名空间都有各自的root用户。上述检测必须考虑这一点。



