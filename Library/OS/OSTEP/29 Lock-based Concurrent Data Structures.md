在讨论锁之前，我们先来介绍一下如何在一些常见的数据结构中使用锁。在数据结构中添加锁，使其可供线程使用，可以使数据结构线程安全。当然，如何添加这些锁决定了数据结构的正确性和性能。因此，我们的挑战是：

当给定一个特定的数据结构时，我们应该如何向其添加锁，才能使其正常工作？此外，我们如何添加锁，以便数据结构获得高性能，使许多线程能够同时（即并发）访问该结构？

当然，我们很难涵盖所有数据结构或添加并发性的所有方法，因为这是一个研究多年的主题，有数千篇关于它的研究论文发表。因此，我们希望对所需的思维类型进行充分的介绍。

# 29.1 并发计数器
计数器是最简单的数据结构之一。它是一种常用且具有简单接口的结构。我们在图 29.1 中定义了一个简单的非并发计数器。

![[Pasted image 20241025203911.png]]

## 简单但不可扩展
如您所见，非同步计数器是一种简单的数据结构，只需少量代码即可实现。现在我们面临下一个挑战：如何使此代码线程安全？图 29.2 显示了我们如何做到这一点。

![[Pasted image 20241025204022.png]]

这个并发计数器很简单，而且工作正常。事实上，它遵循最简单、最基本的并发数据结构所共有的设计模式：它只是添加了一个锁，在调用操作数据结构的例程时获取该锁，并在从调用返回时释放该锁。以这种方式，它类似于使用监视器构建的数据结构，其中在您调用和从对象方法返回时会自动获取和释放锁。

此时，您有一个有效的并发数据结构。您可能遇到的问题是性能。如果您的数据结构太慢，您必须做的不仅仅是添加一个锁；如果需要，此类优化将是本章其余部分的主题。请注意，如果数据结构不太慢，您就大功告成了！如果简单的东西能起作用，就不需要做一些花哨的事情。

为了了解简单方法的性能成本，我们运行了一个基准测试，其中每个线程更新单个共享计数器固定次数；然后我们改变线程数。图 29.5 显示了总耗时，其中有一到四个线程处于活动状态；每个线程更新计数器一百万次。该实验是在一台配备四个 Intel 2.7 GHz i5 CPU 的 iMac 上运行的；随着更多 CPU 处于活动状态，我们希望在单位时间内完成更多总工作。

![[Pasted image 20241025204612.png]]

从图中的顶行（标记为“精确”），您可以看到同步计数器的性能很差。虽然单个线程可以在很短的时间内（大约 0.03 秒）完成百万次计数器更新，但两个线程同时更新计数器一百万次会导致速度大幅下降（耗时超过 5 秒！）。线程越多，情况只会变得更糟。

理想情况下，您希望看到线程在多个处理器上的完成速度与单个线程在一个处理器上的完成速度一样快。实现这一目标被称为完美扩展；即使完成了更多工作，它也是并行完成的，因此完成任务所需的时间不会增加。

## Scalable Counting
令人惊讶的是，研究人员多年来一直在研究如何构建更具可扩展性的计数器。更令人惊讶的是，可扩展计数器非常重要，正如操作系统性能分析的最新研究所表明的那样；如果没有可扩展计数，在多核机器上运行的某些工作负载会遭受严重的可扩展性问题。

已经开发出许多技术来解决这个问题。我们将描述一种称为近似计数器的方法。

近似计数器的工作原理是通过多个本地物理计数器（每个 CPU 核心一个）以及一个全局计数器来表示单个逻辑计数器。具体来说，在具有四个 CPU 的机器上，有四个本地计数器和一个全局计数器。除了这些计数器之外，还有锁：每个本地计数器一个，全局计数器一个。

近似计数的基本思想如下。当在给定核心上运行的线程希望增加计数器时，它会增加其本地计数器；对此本地计数器的访问通过相应的本地锁进行同步。由于每个 CPU 都有自己的本地计数器，跨 CPU 的线程可以无争用地更新本地计数器，因此对计数器的更新是可扩展的。

但是，为了使全局计数器保持最新（以防线程希望读取其值），本地值会定期传输到全局计数器，方法是获取全局锁并将其增加本地计数器的值；然后将本地计数器重置为零。

这种从本地到全局的传输发生的频率由阈值 S 决定。S 越小，计数器的行为越像上面的不可扩展计数器；S 越大，计数器的可扩展性越高，但全局值可能与实际计数相差越大。可以简单地获取所有本地锁和全局锁（按指定顺序，以避免死锁）以获得精确的值，但这是不可扩展的。

为了清楚起见，让我们看一个例子（图 29.3）。在此示例中，阈值 S 设置为 5，并且四个 CPU 上都有线程更新其本地计数器 L1 ... L4。全局计数器值 (G) 也显示在跟踪中，时间向下增加。在每个时间步骤中，本地计数器可能会递增；如果本地值达到阈值 S，则本地值将传输到全局计数器并重置本地计数器。

图 29.5 中的下一行（标记为“近似”）显示了阈值 S 为 1024 的近似计数器的性能。性能非常出色；在四个处理器上更新计数器四百万次所需的时间几乎不高于在一个处理器上更新计数器一百万次所需的时间。
![[Pasted image 20241025205442.png]]

![[Pasted image 20241025205608.png]]

图 29.6 显示了阈值 S 的重要性，其中四个线程在四个 CPU 上分别将计数器增加 100 万次。如果 S 较低，则性能较差（但全局计数始终非常准确）；如果 S 较高，则性能很好，但全局计数会滞后（最多为 CPU 数量乘以 S）。这种准确性/性能权衡正是近似计数器所实现的。图 29.4中有一个近似计数器的粗略版本。请阅读它，或者更好的是，自己在一些实验中运行它，以更好地了解它的工作原理。

![[Pasted image 20241025205908.png]]

提示：并发性越高并不一定越快

如果您设计的方案增加了大量开销（例如，通过频繁获取和释放锁，而不是一次），那么并发性越高这一事实可能并不重要。简单的方案往往效果很好，特别是如果它们很少使用昂贵的例程。增加更多的锁和复杂性可能会导致您的失败。尽管如此，有一种方法可以真正了解：构建两种替代方案（简单但并发性较低，复杂但并发性较高）并衡量它们的表现。最后，您不能在性能上作弊；您的想法要么更快，要么不更快。

# 29.2 并发链表
接下来我们研究一个更复杂的结构，即链表。让我们再次从基本方法开始。为简单起见，我们将省略这种链表所具有的一些明显的例程，而只关注并发插入和查找；我们将让读者思考删除等。图 29.7 显示了此基本数据结构的代码。
![[Pasted image 20241025210544.png]]

正如您在代码中看到的，代码只是在进入时在插入例程中获取锁，并在退出时释放它。如果 malloc() 碰巧失败（罕见情况），就会出现一个小的棘手问题；在这种情况下，代码还必须在插入失败之前释放锁。

这种异常控制流已被证明很容易出错；最近对 Linux 内核补丁的研究发现，大量的错误（近 40%）都出现在这种很少使用的代码路径上（事实上，这一观察结果引发了我们自己的一些研究，我们从 Linux 文件系统中删除了所有内存故障路径，从而产生了一个更强大的系统）。

因此，一个挑战是：我们能否重写插入和查找例程，使其在并发插入下保持正确，但避免出现故障路径也要求我们添加解锁调用的情况？

在这种情况下，答案是肯定的。具体来说，我们可以稍微重新安排代码，使锁定和释放仅围绕插入代码中的实际关键部分，并且在查找代码中使用公共退出路径。前者有效，因为插入的一部分实际上不需要锁定；假设 malloc() 本身是线程安全的，每个线程都可以调用它，而不必担心竞争条件或其他并发错误。只有在更新共享列表时才需要保持锁定。有关这些修改的详细信息，请参见图 29.8。

至于查找例程，只需进行简单的代码转换即可跳出主搜索循环到单个返回路径。这样做再次减少了代码中的锁获取/释放点的数量，从而减少了意外将错误（例如在返回之前忘记解锁）引入代码的可能性。

---
在并发环境下实现链表结构时，插入和查找的代码需要小心处理，以确保数据的正确性。这个代码优化的关键在于减少锁的使用范围，从而避免在一些异常情况下忘记释放锁的错误。这种改进基于以下几点：

1. **锁的简单应用**：在原始版本中，插入操作（insert）在进入时获取锁，并在退出时释放锁。如果 `malloc()` 分配内存失败，则需要在返回失败前手动释放锁。这种错误控制流程可能会引入错误，例如忘记解锁，从而导致死锁。研究表明，在稀有的代码路径上出现的错误（如内存分配失败路径）约占大量Linux内核补丁中的40%，这些路径往往在设计上容易被忽视。

2. **优化后的插入实现**：为了降低错误的可能性，优化版本在插入操作中重新组织了锁的使用流程。具体来说，将锁的获取和释放仅围绕关键代码部分，即更新共享链表的部分。这样，`malloc()` 的调用不需要锁保护，只在链表真正更新时获取锁。假设 `malloc()` 是线程安全的，各线程可以并发地调用它而不会引发竞态条件或其他并发问题。这样既保证了线程安全，又减少了锁的持有时间，从而提高了性能。

3. **查找例程的优化**：对于查找操作（lookup），可以采用一种“单一退出路径”的方式来简化代码。通过在主循环外设置一个单一的返回路径，可以减少获取和释放锁的点，从而降低忘记解锁的风险。这一优化通过将锁的获取/释放集中在少数代码点，降低了意外引入错误的可能性。

---

![[Pasted image 20241025211251.png]]

## Scaling Linked Lists
虽然我们再次拥有一个基本的并发链表，但我们再次处于无法很好地扩展的情况。研究人员探索的一种可以在列表中实现更多并发的技术是所谓的 hand-over-hand 锁定（又称锁耦合）。

这个想法很简单。您不必对整个列表使用单个锁，而是为列表的每个节点添加一个锁。在遍历列表时，代码首先获取下一个节点的锁，然后释放当前节点的锁（这启发了 hand-over-hand 这个名称）。

从概念上讲，hand-over-hand 链表是有一定道理的；它使列表操作具有高度的并发性。然而，在实践中，很难使这种结构比简单的单锁方法更快，因为获取和释放列表遍历的每个节点的锁的开销是令人望而却步的。即使列表非常大，线程数量也很多，通过允许多次进行遍历实现的并发性不太可能比简单地获取单个锁、执行操作并释放锁更快。也许某种混合方法（每隔一定数量的节点获取一个新的锁）值得研究。

## 提示：警惕锁和控制流
一个通用的设计技巧在并发代码和其他方面都很有用，那就是警惕控制流变化，因为这些变化会导致函数返回、退出或其他类似的错误情况，从而停止函数的执行。因为许多函数一开始会获取锁、分配一些内存或执行其他类似的有状态操作，所以当出现错误时，代码必须在返回之前撤消所有状态，这很容易出错。因此，最好构造代码以尽量减少这种模式。

# 29.3 并发队列
正如您现在所知道的，始终有一种标准方法来创建并发数据结构：添加一个大锁。对于队列，我们​​将跳过该方法，假设您能弄清楚。

相反，我们将研究由 Michael 和 Scott 设计的稍微更并发的队列。此队列使用的数据结构和代码如图 29.9 所示。

![[Pasted image 20241026122904.png]]

如果您仔细研究此代码，您会注意到有两个锁，一个用于队列的头部，一个用于队列的尾部。这两个锁的目标是启用入队和出队操作的并发性。在常见情况下，入队例程将仅访问尾部锁，并且仅出队头部锁。

Michael 和 Scott 使用的一个技巧是添加一个虚拟节点（在队列初始化代码中分配）；这个虚拟节点可以分离头部和尾部操作。研究代码，或者更好的方法是输入代码、运行代码并测量代码，以深入了解其工作原理。

队列通常用于多线程应用程序。但是，这里使用的队列类型（仅带锁）通常不能完全满足此类程序的需求。更完善的有界队列（如果队列为空或过满，则允许线程等待）是我们在下一章条件变量中深入研究的主题。请留意！

# 29.4 并发哈希表
我们以一个简单且广泛适用的并发数据结构哈希表来结束我们的讨论。我们将重点介绍一个不调整大小的简单哈希表；处理调整大小需要做更多的工作，我们将其作为练习留给读者（抱歉！）。

这个并发哈希表（图 29.10）很简单，使用我们之前开发的并发列表构建，并且工作得非常好。其性能良好的原因是，它不是对整个结构使用单个锁，而是对每个哈希桶使用一个锁（每个哈希桶由一个列表表示）。这样做可以进行许多并发操作。

![[Pasted image 20241026124433.png]]

图 29.11显示了哈希表在并发更新下的性能（在具有四个 CPU 的同一台 iMac 上，四个线程中的每个线程从 10,000 到 50,000 个并发更新）。为了进行比较，还显示了链接列表（具有单个锁）的性能。
从图中可以看出，这个简单的并发哈希表的扩展性非常好；相比之下，链表则不然。

![[Pasted image 20241026124518.png]]

# 29.5 总结
我们介绍了一些并发数据结构，从计数器到列表和队列，最后到无处不在且使用频繁的哈希表。在此过程中，我们学到了一些重要的经验教训：在控制流更改时要小心获取和释放锁；启用更多并发性并不一定会提高性能；性能问题只有在存在时才应该得到补救。最后一点，即避免过早优化，对于任何注重性能的开发人员来说都至关重要；如果这样做不会提高应用程序的整体性能，那么让某些东西更快就没有任何价值。

## 提示：避免过早优化（KNUTH 定律）
构建并发数据结构时，从最基本的方法开始，即添加单个大锁以提供同步访问。通过这样做，您很可能会构建一个正确的锁；如果您发现它存在性能问题，您可以对其进行改进，从而仅在需要时使其变快。正如 Knuth 的名言：“过早优化是万恶之源。”

许多操作系统在首次过渡到多处理器时都使用单个锁，包括 Sun OS 和 Linux。在后者中，这个锁甚至有一个名字，即大内核锁 (BKL)。多年来，这种简单的方法是一种好方法，但当多 CPU 系统成为常态时，内核中一次只允许一个活动线程成为性能瓶颈。因此，终于到了为这些系统添加改进并发性的优化的时候了。在 Linux 中，采用了更直接的方法：用多个锁替换一个锁。在 Sun 内部，他们做出了一个更激进的决定：构建一个全新的操作系统，即 Solaris，从第一天起就更彻底地融入并发性。阅读 Linux 和 Solaris 内核书籍，了解有关这些迷人系统的更多信息。

---