当我们使用磁盘时，有时我们希望它更快； I/O 操作很慢，因此可能成为整个系统的瓶颈。当我们使用磁盘时，有时我们希望它更大；越来越多的数据被上传到网上，因此我们的磁盘越来越满。当我们使用磁盘时，有时我们希望它更可靠；当磁盘发生故障时，如果我们的数据没有备份，所有有价值的数据都会消失。

How to make a large, fast reliable disk? How can we make a large, fast, and reliable storage system? What are the key techniques? What are trade-offs between different approaches?

在本章中，我们将介绍廉价磁盘冗余阵列（RAID），这是一种使用多个磁盘协同构建更快、更大、更可靠的磁盘系统的技术。该术语由加州大学伯克利分校的一组研究人员于 20 世纪 80 年代末提出（由 David Patterson 教授和 Randy Katz 教授以及当时的学生 Garth Gibson 领导）；大约在这个时候，许多不同的研究人员同时提出了使用多个磁盘构建更好的存储系统的基本想法。

从外部来看，RAID 类似于磁盘：一组可以读取或写入的块。从内部来看，RAID 是一个复杂的系统，由多个磁盘、内存（易失性和非易失性）以及一个或多个用于管理系统的处理器组成。硬件 RAID 非常类似于计算机系统，专门用于管理一组磁盘。

与单个磁盘相比，RAID 具有许多优势。其中一个优势是性能。并行使用多个磁盘可以大大加快 I/O 时间。另一个好处是容量。大型数据集需要大型磁盘。最后，RAID 可以提高可靠性；将数据分散到多个磁盘上（没有 RAID 技术）会使数据容易受到单个磁盘丢失的影响；通过某种形式的冗余，RAID 可以容忍磁盘丢失并继续运行，就像什么都没有发生一样。

令人惊讶的是，RAID 为使用它们的系统透明地提供了这些优势，也就是说，对于主机系统来说，RAID 看起来就像一个大磁盘。当然，透明性的优点在于，它使人们能够简单地用 RAID 替换磁盘，而无需更改任何软件；操作系统和客户端应用程序继续运行而无需修改。通过这种方式，透明性大大提高了 RAID 的可部署性，使用户和管理员能够使用 RAID 而不必担心软件兼容性。

我们现在讨论 RAID 的一些重要方面。我们从接口、故障模型开始，然后讨论如何沿着三个重要轴评估 RAID 设计：容量、可靠性和性能。然后，我们讨论对 RAID 设计和实施很重要的许多其他问题。

# 38.1 Interface And RAID Internals
对于上面的文件系统，RAID 看起来像一个大容量、（希望）快速且（希望）可靠的磁盘。就像单个磁盘一样，它呈现为一个线性块阵列，每​​个块都可以由文件系统（或其他客户端）读取或写入。

当文件系统向 RAID 发出逻辑 I/O 请求时，RAID 必须在内部计算要访问哪个磁盘（或哪些磁盘）才能完成请求，然后发出一个或多个物理 I/O 来完成此操作。这些物理 I/O 的确切性质取决于 RAID 级别，我们将在下文详细讨论。但是，作为一个简单的示例，考虑一个 RAID，它保留每个块的两个副本（每个副本位于单独的磁盘上）；当写入这样的镜像 RAID 系统时，RAID 必须为发出的每一个逻辑 I/O 执行两个物理 I/O。

RAID 系统通常构建为一个单独的硬件盒，通过标准连接（例如 SCSI 或 SATA）连接到主机。然而，RAID 的内部相当复杂，由运行固件的微控制器组成，用于指导 RAID 的操作，易失性存储器（例如 DRAM）用于在读取和写入数据块时对其进行缓冲，在某些情况下，非易失性存储器用于安全地缓冲写入，甚至可能还有专门的逻辑来执行奇偶校验计算（在某些 RAID 级别中很有用，我们将在下面看到）。从高层次上讲，RAID 是一个专门的计算机系统：它有处理器、内存和磁盘；但是，它运行的不是应用程序，而是专门为操作 RAID 而设计的软件。

# 38.2 Fault Model
要理解 RAID 并比较不同的方法，我们必须在心中有一个故障模型。RAID 旨在检测和恢复某些类型的磁盘故障；因此，准确了解预期会出现哪些故障对于制定可行的设计至关重要。

我们将假设的第一个故障模型非常简单，被称为`fail-stop fault`模型。在此模型中，磁盘可以处于两种状态之一：工作或故障。对于工作正常的磁盘，可以读取或写入所有块。相反，当磁盘发生故障时，我们假设它永久丢失。

故障停止模型的一个关键方面是它对故障检测的假设。具体来说，当磁盘发生故障时，我们假设这很容易检测到。例如，在 RAID 阵列中，我们假设 RAID 控制器硬件（或软件）可以立即观察到磁盘发生故障的时间。

因此，目前，我们不必担心更复杂的“静默”故障，例如磁盘损坏。我们也不必担心单个块在原本正常工作的磁盘上变得无法访问（有时称为潜在扇区错误）。稍后我们将考虑这些更复杂（不幸的是，更现实）的磁盘故障。

# 38.3 How to Evaluate A RAID
我们很快就会看到，构建 RAID 的方法有很多种。每种方法都有不同的特点，值得评估，以了解它们的优点和缺点。

具体来说，我们将从三个方面评估每个 RAID 设计。第一个轴是容量；给定一组 N 个磁盘，每个磁盘有 B 个块，RAID 的客户端可以使用多少有用容量？如果没有冗余，答案是 N ·B；相反，如果我们有一个系统保留每个块的两个副本（称为镜像），我们将获得 (N · B)/2 的有用容量。不同的方案（例如基于奇偶校验的方案）往往介于两者之间。

第二个评估轴是可靠性。给定的设计可以容忍多少个磁盘故障？根据我们的故障模型，我们只假设整个磁盘可能会发生故障；在后面的章节（即关于数据完整性的章节）中，我们将考虑如何处理更复杂的故障模式。

最后，第三个轴是性能。性能的评估有些困难，因为它在很大程度上取决于磁盘阵列的工作负载。因此，在评估性能之前，我们将首先介绍一组应该考虑的典型工作负载。

我们现在考虑三种重要的 RAID 设计：RAID 级别 0（条带化）、RAID 级别 1（镜像）和 RAID 级别 4/5（基于奇偶校验的冗余）。

# 38.4 RAID Level 0: Striping
第一个 RAID 级别实际上根本不是 RAID 级别，因为没有冗余。但是，RAID 级别 0（或更广为人知的条带化）是性能和容量的极佳上限，因此值得了解。

最简单的条带化形式是将块条带化到系统的磁盘上，如下所示（此处假设为 4 个磁盘阵列）：
![[Pasted image 20241203111459.png]]
从图 38.1 中，您可以了解基本思想：以循环方式将阵列的块分散到磁盘上。这种方法旨在当请求阵列的连续块时（例如，在大型顺序读取中），从阵列中提取最多的并行性。我们将同一行中的块称为条带；因此，块 0、1、2 和 3 位于上面的同一条带中。

在示例中，我们做了简化假设，即每个磁盘上只放置 1 个块（每个块大小为 4KB），然后才移动到下一个磁盘。但是，这种安排不一定是这样的。例如，我们可以像图 38.2 中那样跨磁盘排列块：
![[Pasted image 20241203111602.png]]

在此示例中，我们在每个磁盘上放置两个 4KB 块，然后再移至下一个磁盘。因此，此 RAID 阵列的块大小为 8KB，因此，一个条带由 4 个块或 32KB 的数据组成。

## ASIDE: The RAID Mapping Problem
This problem arises in all RAID arrays; simply put, given a logical block to read or write, how does the RAID know exactly which physical disk and offset to access?

## Chunk Sizes
块大小主要影响阵列的性能。例如，较小的块大小意味着许多文件将被条带化到多个磁盘上，从而增加了对单个文件的读写并行性；但是，跨多个磁盘访问块的定位时间会增加，因为整个请求的定位时间由跨所有驱动器的请求定位时间的最大值决定。

另一方面，较大的块大小会降低这种文件内并行性，因此依赖于多个并发请求来实现高吞吐量。但是，较大的块大小会减少定位时间；例如，如果单个文件适合一个块并因此被放置在单个磁盘上，则访问它时产生的定位时间将只是单个磁盘的定位时间。

因此，确定“最佳”块大小很难，因为它需要大量有关磁盘系统负载的知识。在后续讨论中，我们将假设数组使用单个块（4KB）的块大小。大多数数组使用较大的块大小（例如 64 KB），但对于我们下面讨论的问题，确切的块大小并不重要；因此，为了简单起见，我们使用单个块。

## Back to RAID-0 Analysis
现在让我们评估一下条带化的容量、可靠性和性能。从容量的角度来看，它是完美的：给定 N 个磁盘，每个磁盘大小为 B 个块，条带化可提供 N ·B 个有用容量块。从可靠性的角度来看，条带化也是完美的，但有缺点：任何磁盘故障都会导致数据丢失。最后，性能非常出色：所有磁盘都被利用（通常是并行的）来处理用户的 I/O 请求。

## Evaluating RAID Performance
在分析 RAID 性能时，可以考虑两个不同的性能指标。第一个是**单请求延迟**。了解单个 I/O 请求对 RAID 的延迟很有用，因为它可以揭示在单个逻辑 I/O 操作期间可以存在多少并行性。第二个是 RAID 的**稳态吞吐量**，即许多**并发请求的总带宽**。由于 RAID 通常用于高性能环境中，因此稳态带宽至关重要，因此将成为我们分析的主要重点。

为了更详细地了解吞吐量，我们需要提出一些感兴趣的工作负载。在本次讨论中，我们假设有两种类型的工作负载：**顺序工作负载**和**随机工作负载**。对于顺序工作负载，我们假设对阵列的请求以大块连续的数据块的形式出现；例如，访问 1 MB 数据的请求（或一系列请求），从块 x 开始，到块 (x+1 MB) 结束，将被视为顺序工作负载。顺序工作负载在许多环境中很常见（想想在大型文件中搜索关键字），因此被认为很重要。

对于随机工作负载，我们假设每个请求都相当小，并且每个请求都指向磁盘上的不同随机位置。例如，随机请求流可能首先访问逻辑地址 10 处的 4KB，然后访问逻辑地址 550,000，然后访问 20,100，依此类推。一些重要的工作负载（例如数据库管理系统 (DBMS) 上的事务性工作负载）表现出这种访问模式，因此它被视为重要的工作负载。

当然，实际的工作负载并非如此简单，通常混合了顺序和看似随机的组件以及两者之间的行为。为简单起见，我们只考虑这两种可能性。

正如您所看到的，顺序和随机工作负载将导致磁盘的性能特征大不相同。==顺序访问时，磁盘以最高效的模式运行，很少花时间寻找和等待旋转，大部分时间都在传输数据。随机访问时则恰恰相反：大部分时间都花在寻找和等待旋转上，而传输数据的时间相对较少。==为了在分析中捕捉到这种差异，我们假设磁盘在顺序工作负载下可以以 S MB/s 的速度传输数据，在随机工作负载下可以以 R MB/s 的速度传输数据。一般来说，S 远大于 R（即 S ≫ R）。

为了确保我们理解这种差异，让我们做一个简单的练习。具体来说，让我们根据以下磁盘特征计算 S 和 R。假设平均顺序传输大小为 10 MB，随机传输大小为 10 KB。此外，假设以下磁盘特征：
![[Pasted image 20241203112553.png]]

要计算 S，我们首先需要弄清楚典型的 10 MB 传输中花费的时间。首先，我们花费 7 毫秒进行寻道，然后花费 3 毫秒进行旋转。最后，传输开始；10 MB @ 50 MB/s 导致传输花费 1/5 秒，即 200 毫秒。因此，对于每个 10 MB 请求，我们花费 210 毫秒完成请求。要计算 S，我们只需除以：
![[Pasted image 20241203112641.png]]
我们可以看到，由于传输数据花费了大量时间，S 非常接近磁盘的峰值带宽（寻道和旋转成本
已被摊销）。

我们可以类似地计算 R。寻道和旋转相同；然后我们计算传输所花费的时间，即 10 KB @ 50 MB/s，或 0.195 毫秒。

![[Pasted image 20241203112731.png]]

## Back To RAID-0 Analysis, Again
现在让我们评估一下条带化的性能。正如我们上面所说，它通常很好。例如，从延迟角度来看，单块请求的延迟应该与单个磁盘的延迟几乎相同；毕竟，RAID-0 只会将该请求重定向到其磁盘之一。

从稳定状态顺序吞吐量的角度来看，我们希望获得系统的全部带宽。因此，吞吐量等于 N（磁盘数量）乘以 S（单个磁盘的顺序带宽）。对于大量随机 I/O，我们可以再次使用所有磁盘，从而获得 N · R MB/s。正如我们将在下面看到的，这些值都是最容易计算的，并且将作为与其他 RAID 级别相比的上限。

# 38.5 RAID 1: Mirroring
除了条带化之外，我们的第一个 RAID 级别称为 RAID 级别 1，或镜像。使用镜像系统，我们只需为系统中的每个块制作多个副本；当然，每个副本都应放在单独的磁盘上。通过这样做，我们可以容忍磁盘故障。

在典型的镜像系统中，我们假设 RAID 为每个逻辑块保留两个物理副本。以下是示例：

![[Pasted image 20241203112927.png]]
在本例中，磁盘 0 和磁盘 1 的内容相同，磁盘 2 和磁盘 3 的内容也相同；数据在这些镜像对上进行条带化。事实上，您可能已经注意到，在磁盘上放置块副本有多种不同的方法。上面的安排很常见，有时称为 RAID-10（或 RAID 1+0，镜像条带），因为它使用镜像对（RAID-1），然后在其顶部使用条带（RAID-0）；另一种常见安排是 RAID-01（或 RAID 0+1，条带镜像），它包含两个大型条带化（RAID-0）阵列，然后在其顶部使用镜像（RAID-1）。现在，我们只讨论假设上述布局的镜像。

当从镜像阵列读取块时，RAID 有一个选择：它可以读取任一副本。例如，如果向 RAID 发出对逻辑块 5 的读取，则可以自由地从磁盘 2 或磁盘 3 读取它。但是，在写入块时，不存在这样的选择：RAID 必须更新数据的两个副本，以保持可靠性。但请注意，这些写入可以并行进行；例如，对逻辑块 5 的写入可以同时进行到磁盘 2 和 3。

## RAID-1 Analysis
让我们评估一下 RAID-1。从容量角度来看，RAID-1 价格昂贵；当镜像级别 = 2 时，我们只能获得峰值可用容量的一半。如果 N 个磁盘包含 B 个块，则 RAID-1 的可用容量为 (N · B)/2。

从可靠性角度来看，RAID-1 表现不错。它可以容忍任何一个磁盘发生故障。您可能还会注意到，如果运气好一点，RAID-1 实际上可以做得更好。想象一下，在上图中，磁盘 0 和磁盘 2 都发生故障。在这种情况下，没有数据丢失！更一般地说，镜像系统（镜像级别为 2）可以容忍 1 个磁盘故障，并且最多可以容忍 N/2 个磁盘故障，具体取决于哪些磁盘发生故障。在实践中，我们通常不喜欢把这样的事情留给运气；因此大多数人认为镜像适合处理单个故障。

最后，我们分析一下性能。从单个读取请求的延迟角度来看，我们可以看到它与单个磁盘上的延迟相同；RAID-1 所做的只是将读取定向到其副本之一。写入略有不同：它需要完成两次物理写入才能完成。这两次写入是并行发生的，因此时间大致相当于单个写入的时间；但是，由于逻辑写入必须等待两次物理写入完成，因此它会遭受两次请求的最坏情况寻道和旋转延迟，因此（平均而言）会略高于对单个磁盘的写入。

要分析稳定状态吞吐量，让我们从顺序工作负载开始。当顺序写入磁盘时，每个逻辑写入都必须导致两次物理写入；例如，当我们写入逻辑块 0（在上图中）时，RAID 内部会将其写入磁盘 0 和磁盘 1。因此，我们可以得出结论，在顺序写入镜像阵列期间获得的最大带宽是 ( N / 2 · S)，即峰值带宽的一半。

不幸的是，我们在顺序读取期间获得了完全相同的性能。有人可能会认为顺序读取可以做得更好，因为它只需要读取一份数据，而不是两份。但是，让我们用一个例子来说明为什么这没有多大帮助。假设我们需要读取块 0、1、2、3、4、5、6 和 7。假设我们向磁盘 0 发出读取 0 的命令，向磁盘 2 发出读取 1 的命令，向磁盘 1 发出读取 2 的命令，向磁盘 3 发出读取 3 的命令。我们继续分别向磁盘 0、2、1 和 3 发出读取 4、5、6 和 7 的命令。有人可能会天真地认为，因为我们利用了所有磁盘，所以我们实现了阵列的全带宽。

但是，要了解情况并非如此（必然如此），请考虑单个磁盘（例如磁盘 0）收到的请求。首先，它收到对块 0 的请求；然后，它收到对块 4 的请求（跳过块 2）。实际上，每个磁盘都会收到对其他每个块的请求。当它在跳过的块上旋转时，它不会向客户端提供有用的带宽。因此，每个磁盘只会提供其峰值带宽的一半。因此，顺序读取将仅获得 ( N / 2 · S) MB/s 的带宽。

随机读取是镜像 RAID 的最佳情况。在这种情况下，我们可以将读取分布到所有磁盘上，从而获得全部可能的带宽。因此，对于随机读取，RAID-1 提供 N · R MB/s。

最后，随机写入的性能正如您所期望的那样：N/2 ·R MB/s。每个逻辑写入都必须变成两个物理写入，因此虽然所有磁盘都在使用中，但客户端只会将其视为可用带宽的一半。即使对逻辑块 x 的写入变成了对两个不同物理磁盘的两次并行写入，许多小请求的带宽也只能达到我们在条带化中看到的带宽的一半。我们很快就会看到，获得一半的可用带宽实际上相当不错！


# 38.6 RAID Level 4: Saving Space With Parity
现在，我们介​​绍一种向磁盘阵列添加冗余度的另一种方法，称为**奇偶校验**。基于奇偶校验的方法试图使用较少的容量，从而克服镜像系统付出的巨大空间代价。然而，这样做是有代价的：性能。
![[Pasted image 20241204180930.png]]
以下是一个五磁盘 RAID-4 系统的示例（图 38.4）。对于每个数据条带，我们添加了一个奇偶校验块，用于存储该条带块的冗余信息。例如，奇偶校验块 P1 具有从块 4、5、6 和 7 计算出的冗余信息。

要计算奇偶校验，我们需要使用一个数学函数，使我们能够承受条带中任何一个块的丢失。事实证明，简单的函数 XOR 可以很好地完成这个任务。对于给定的一组位，如果位中有偶数个 1，则所有这些位的 XOR 返回 0，如果位中有奇数个 1，则返回 1。

从上面的例子中，您也许能够猜出如何使用奇偶校验信息来从故障中恢复。假设标记为 C2 的列丢失了。要找出该列中必须包含哪些值，我们只需读取该行中的所有其他值（包括经过 XOR 处理的奇偶校验位）并重建正确答案。具体来说，假设 C2 列中第一行的值丢失（它是 1）；通过读取该行中的其他值（C0 中的 0、C1 中的 0、C3 中的 1 以及奇偶校验列 P 中的 0），我们得到值 0、0、1 和 0。因为我们知道 XOR 在每行中保留偶数个 1，所以我们知道丢失的数据必须是什么：1。这就是基于 XOR 的奇偶校验方案中的重建工作方式！还要注意我们如何计算重建值：我们只是将数据位和奇偶校验位进行异或运算，就像我们首先计算奇偶校验一样。

现在您可能想知道：我们正在讨论对所有这些位进行异或运算，但从上面我们知道 RAID 在每个磁盘上放置 4KB（或更大）的块；我们如何将异或运算应用于一堆块来计算奇偶校验？事实证明这也很容易。只需对数据块的每个位执行按位异或；将每个按位异或的结果放入奇偶校验块中相应的位槽中。例如，如果我们有 4 位大小的块（是的，这仍然比 4KB 块小很多，但您明白了），它们可能看起来像这样：

## RAID-4 Analysis
From a capacity standpoint, RAID-4 uses 1 disk for parity information for every group of disks it is protecting. Thus, our useful capacity for a RAID group is (N-1) * B.

Reliability is also quite easy to understand: RAID-4 tolerates 1 disk failure and no more. If more than one disk is lost, there is simply no way to reconstruct the lost data.

Finally, there is performance. Sequential read performance can utilize all of the disks except for the parity disk, and thus deliver a peak effective bandwidth of (N-1)* S MB/s.

![[Pasted image 20241204181747.png]]

要了解顺序写入的性能，我们必须首先了解它们是如何完成的。在将大量数据写入磁盘时，
RAID-4 可以执行称为**全条带写入**的简单优化。例如，想象一下块 0、1、2 和 3 作为写入请求的一部分发送到 RAID 的情况（图 38.5）。

In this case, the RAID can simply calculate the new value of P0 (by performing an XOR across the blocks 0, 1, 2, and 3) and then write all of the blocks (including the parity block) to the five disks above in parallel. Thus, full-stripe writes are the most efficient way for RAID-4 to write to disk.

一旦我们理解了全条带写入，计算 RAID-4 上顺序写入的性能就很容易了；有效带宽也是
(N −1)·S MB/s。即使奇偶校验磁盘在操作过程中不断使用，客户端也不会从中获得性能优势。

现在让我们分析一下随机读取的性能。从上图还可以看出，一组 1 块随机读取将分布在系统的数据磁盘上，但不分布在奇偶校验磁盘上。因此，有效性能为：(N − 1) · R MB/s。我们最后提到的随机写入是 RAID-4 最有趣的情况。假设我们希望覆盖上面示例中的块 1。我们可以继续覆盖它，但这会给我们带来一个问题：奇偶校验块 P0 将不再准确反映条带的正确奇偶校验值；在此示例中，P0 也必须更新。我们如何才能正确而有效地更新它？事实证明有两种方法。第一种方法称为加性奇偶校验，需要我们执行以下操作。要计算新奇偶校验块的值，请并行读取条带中的所有其他数据块（在示例中为块 0、2 和 3），然后将它们与新块 (1) 进行异或。结果就是您的新奇偶校验块。要完成写入，您可以同时将新数据和新奇偶校验写入各自的磁盘。

这种技术的问题在于它会随着磁盘数量而扩展，因此在较大的 RAID 中需要大量读取才能计算奇偶校验。因此，减法奇偶校验方法。


# 38.7 RAID Level 5: Rotating Parity

# 38.8 RAID Comparison: A Summary
现在，我们在图 38.8 中总结了 RAID 级别的简化比较。请注意，我们省略了一些细节以简化我们的分析。例如，在镜像系统中写入时，平均寻道时间比仅写入单个磁盘时略高，因为寻道时间是两次寻道（每个磁盘一次）的最大值。因此，两个磁盘的随机写入性能通常会比单个磁盘的随机写入性能略低。此外，在 RAID-4/5 中更新奇偶校验磁盘时，第一次读取旧奇偶校验可能会导致完全寻道和旋转，但第二次写入奇偶校验只会导致旋转。最后，与其他方法相比，镜像 RAID 的顺序 I/O 会付出 2 倍的性能损失。

但是，图 38.8 中的比较确实捕捉到了本质差异，并且有助于理解 RAID 级别之间的权衡。
对于延迟分析，我们仅使用 T 来表示对单个磁盘的请求所需的时间。

![[Pasted image 20241204182406.png]]
总之，如果您只想要性能而不关心可靠性，条带化显然是最好的。但是，如果您想要随机 I/O 性能和可靠性，镜像是最好的；您付出的代价是容量损失。如果容量和可靠性是您的主要目标，那么 RAID5 就是赢家；您付出的代价是小写入性能。最后，如果您总是进行顺序 I/O 并希望最大化容量，RAID-5 也是​​最有意义的。


# 38.9 Other Interesting RAID Issues
在考虑 RAID 时，还有许多其他有趣的想法可以（也许应该）讨论。以下是我们最终可能会写的一些内容。

例如，还有许多其他 RAID 设计，包括原始分类法中的级别 2 和 3，以及可容忍多个磁盘故障的级别 6 [C+04]。当磁盘发生故障时，RAID 还会执行其他操作；有时它会有一个热备用磁盘来替代发生故障的磁盘。发生故障时的性能以及重建故障磁盘时的性能会发生什么变化？还有更现实的故障模型，以考虑潜在的扇区错误或块损坏 [B+08]，以及许多处理此类故障的技术（有关详细信息，请参阅数据完整性章节）。最后，您甚至可以将 RAID 构建为软件层：此类软件 RAID 系统更便宜，但存在其他问题，包括一致性更新问题 [DAA05]。

# 38.10 Summary
我们已经讨论了 RAID。RAID 将多个独立磁盘转换为一个更大、容量更大、更可靠的单一实体；重要的是，它以透明的方式进行转换，因此上面的硬件和软件相对来说对这种变化没有感知。

有许多可能的 RAID 级别可供选择，而要使用的确切 RAID 级别在很大程度上取决于最终用户看重什么。例如，镜像 RAID 简单、可靠，并且通常提供良好的性能，但容量成本较高。相比之下，RAID-5 从容量角度来看是可靠的，而且更好，但在工作负载中有少量写入时性能相当差。为特定工作负载选择 RAID 并正确设置其参数（块大小、磁盘数量等）具有挑战性，并且仍然是一门艺术而不是科学。
