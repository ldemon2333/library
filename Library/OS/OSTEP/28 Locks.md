# 28.1 Locks：基本概念
假设临界区长这样：
![[Pasted image 20241022180851.png]]
要使用锁，我们在关键部分周围添加一些代码，如下所示：

![[Pasted image 20241022181019.png]]

锁只是一个变量，因此要使用它，您必须声明某种类型的锁变量（例如上面的互斥锁）。此锁变量（或简称为“锁”）在任何时刻保存锁的状态。我们还可以在数据类型中存储其他信息，例如哪个线程持有锁，或者用于排序锁获取的队列，但这些信息对锁的用户是隐藏的。

锁为程序员提供了对调度的最低限度的控制。一般来说，我们将线程视为由程序员创建但由操作系统以操作系统选择的任何方式调度的实体。锁将部分控制权交还给程序员；通过对一段代码进行锁定，程序员可以保证该代码中只有一个线程处于活动状态。因此，锁有助于将传统操作系统调度的混乱转变为更受控制的活动。

# 28.2 Pthread Locks
POSIX 库对锁使用的名称是互斥锁，因为它用于提供线程之间的互斥，即如果一个线程处于临界区，它会阻止其他线程进入，直到它完成该区为止。因此，当您看到以下 POSIX 线程代码时，您应该明白它正在执行与上述相同的操作（我们再次使用我们的包装器来检查锁定和解锁时的错误）：

![[Pasted image 20241022181527.png]]

您可能还会注意到，POSIX 版本将变量传递给 lock 和 unlock，因为我们可能使用不同的锁来保护不同的变量。这样做可以提高并发性：人们通常会使用不同的锁来保护不同的数据和数据结构，而不是在访问任何关键部分时使用一个大锁（粗粒度锁定策略），从而允许更多线程同时处于锁定代码中（更细粒度的方法）。

# 28.3 创建一个Lock
现在，从程序员的角度来看，您应该对锁的工作原理有所了解。但是我们应该如何构建锁呢？需要什么硬件支持？什么操作系统支持？

要构建一个可用的锁，我们需要硬件这个老朋友以及操作系统这个好伙伴的帮助。

# 28.4 Evaluating Locks
在构建任何锁之前，我们首先应该了解我们的目标是什么，因此我们要问如何评估特定锁实现的有效性。要评估锁是否有效（并且工作良好），我们应该建立一些基本标准。首先是锁是否执行其基本任务，即提供互斥。锁是否有效，防止多个线程进入关键部分？

第二个是公平性。每个争用锁的线程在锁释放后是否都能公平地获得它？另一种看待这个问题的方法是检查更极端的情况：是否有任何争用锁的线程在这样做时处于饥饿状态，从而永远无法获得它？

最后一个标准是性能，特别是使用锁所增加的时间开销。这里有几种不同的情况值得考虑。一种是没有争用的情况；当单个线程正在运行并获取和释放锁时，这样做的开销是多少？另一种是多个线程在单个 CPU 上争用锁的情况；在这种情况下，是否存在性能问题？最后，当涉及多个 CPU 并且每个 CPU 上的线程都在争用锁时，锁的性能如何？通过比较这些不同的场景，我们可以更好地理解使用各种锁定技术对性能的影响，如下所述。

# 28.5 控制中断
最早用于提供互斥的解决方案之一是禁用临界区的中断；此解决方案是为单处理器系统发明的。代码如下所示：
![[Pasted image 20241022182046.png]]
假设我们在这样的单处理器系统上运行。通过在进入临界区之前关闭中断（使用某种特殊的硬件指令），我们确保临界区内的代码不会被中断，因此将像原子一样执行。完成后，我们重新启用中断（再次通过硬件指令），这样程序就可以照常进行。

这种方法的主要优点是简单。没有中断，线程可以确保它执行的代码将执行，并且没有其他线程会干扰它。

不幸的是，这种方法有很多缺点。首先，这种方法要求我们允许任何调用线程执行特权操作（打开和关闭中断）。正如您已经知道的那样，任何时候我们被要求信任一个任意程序，我们可能都会遇到麻烦。在这里，麻烦表现在很多方面：贪婪的程序可以在执行开始时调用 lock()，从而独占处理器；更糟糕的是，错误或恶意的程序可以调用 lock() 并进入无限循环。在后一种情况下，操作系统永远不会重新获得对系统的控制权，并且只有一种补救措施：重新启动系统。使用中断禁用作为通用同步解决方案需要对应用程序有太多的信任。

其次，该方法不适用于多处理器。如果多个线程在不同的 CPU 上运行，并且每个线程都试图进入相同的临界区，则单个处理器中断是否被禁用并不重要；线程将能够在其他处理器上运行，因此可以进入临界区。由于多处理器现在很常见，我们的通用解决方案必须做得比这更好。

第三，长时间关闭中断可能会导致中断丢失，从而导致严重的系统问题。例如，想象一下，如果 CPU 错过了磁盘设备已完成读取请求的事实。操作系统如何知道唤醒等待读取的进程？

出于这些原因，关闭中断仅在有限的环境中用作互斥原语。例如，在某些情况下，操作系统本身将使用中断屏蔽来保证访问其自身数据结构时的原子性，或者至少防止出现某些混乱的中断处理情况。这种用法是有意义的。


# 28.6  失败的尝试：仅使用加载/存储
要超越基于中断的技术，我们必须依赖 CPU 硬件及其提供的指令来构建适当的锁。让我们首先尝试使用单个标志变量构建一个简单的锁。在这次失败的尝试中，我们将看到构建锁所需的一些基本思想，并且了解为什么仅使用单个变量并通过常规加载和存储访问它是不够的。

在第一次尝试中（图 28.1），想法非常简单：使用一个简单的变量来指示某个线程是否拥有锁。进入临界区的第一个线程将调用 lock()，它测试标志是否等于 1（在本例中不是），然后将标志设置为 1，以指示该线程现在拥有锁。完成临界区后，线程将调用 unlock() 并清除标志，从而指示不再持有锁。

![[Pasted image 20241022182440.png]]

如果另一个线程恰好在第一个线程处于临界区时调用 lock()，它将简单地在 while 循环中自旋等待该线程调用 unlock() 并清除标志。一旦第一个线程这样做了，等待的线程将退出 while 循环，将标志设置为 1，然后进入临界区。

不幸的是，代码有两个问题：一个是正确性问题，另一个是性能问题。一旦你习惯了并发编程的思考，正确性问题就很容易看出。想象一下图 28.2 中的代码交错；假设 flag=0 开始。

从这种交错可以看出，如果中断及时（不及时？），我们很容易产生这样一种情况：两个线程都将标志设置为 1，因此两个线程都能够进入临界区。这种行为就是专业人士所说的“不好”——我们显然未能提供最基本的要求：提供互斥。

性能问题（稍后我们会进一步讨论）是线程等待获取已持有的锁的方式：它无休止地检查标志的值，这种技术称为自旋等待。自旋等待浪费时间等待另一个线程释放锁。在单处理器上，浪费特别多，因为等待者的线程甚至无法运行（至少在发生上下文切换之前）！因此，随着我们不断前进并开发更复杂的解决方案，我们还应该考虑避免这种浪费的方法。

# 28.7 Building Working Spin Locks with Test-And-Set
由于禁用中断在多处理器上不起作用，并且使用加载和存储的简单方法（如上所示）不起作用，因此系统设计人员开始发明锁定的硬件支持。最早的多处理器系统（例如 20 世纪 60 年代早期的 Burroughs B5000）具有此类支持；如今，所有系统都提供这种类型的支持，即使是单 CPU 系统也是如此。

最容易理解的硬件支持是test-and-set（或原子交换）指令。我们通过以下 C 代码片段定义测试并设置指令的作用：

![[Pasted image 20241022190307.png]]

![[Pasted image 20241022191643.png]]

test-and-set 指令的作用如下。它返回旧 ptr 指向的旧值，并同时将该值更新为新值。当然，关键在于这一系列操作是原子执行的。之所以称为“测试和设置”，是因为它使您能够“测试”旧值（即返回的值），同时将内存位置“设置”为新值；事实证明，这个稍微强大的指令足以构建一个简单的自旋锁，正如我们现在在图 28.3 中检查的那样。

让我们确保我们理解这个锁为什么有效。首先想象一下一个线程调用 lock() 并且当前没有其他线程持有锁的情况；因此，flag 应该是 0。当线程调用 TestAndSet(flag, 1) 时，例程将返回 flag 的旧值，即 0；因此，正在测试 flag 值的调用线程不会陷入 while 循环中的旋转，并将获取锁。该线程还将自动将值设置为 1，从而表明现在已持有锁。当线程完成其关键部分时，它将调用 unlock() 将标志重新设置为零。

我们可以想象的第二种情况是，当一个线程已经持有锁（即标志为 1）时。在这种情况下，此线程将调用 lock()，然后也调用 TestAndSet(flag, 1)。这次，TestAndSet() 将返回标志处的旧值，即 1，同时将其再次设置为 1。只要锁被另一个线程持有，TestAndSet() 就会反复返回 1，因此该线程将不断旋转，直到锁最终被释放。当标志最终被其他线程设置为 0 时，此线程将再次调用 TestAndSet()，现在它将返回 0，同时自动将值设置为 1，从而获取锁并进入关键部分。

通过将测试（旧锁值）和设置（新值）设为单个原子操作，我们确保只有一个线程获取锁。这就是构建有效互斥原语的方法！

您现在可能也明白了为什么这种类型的锁通常被称为自旋锁。它是最简单的锁类型，只需使用 CPU 周期旋转，直到锁可用。要在单个处理器上正常工作，它需要一个抢占式调度程序（即，它会通过计时器中断线程，以便不时运行不同的线程）。如果没有抢占，自旋锁在单个 CPU 上就没有多大意义，因为在 CPU 上旋转的线程永远不会放弃它。

# 28.8 评价自旋锁
有了基本的自旋锁，我们现在可以沿着我们之前描述的轴来评估它的有效性。锁最重要的方面是正确性：它是否提供互斥？答案是肯定的：自旋锁一次只允许一个线程进入临界区。因此，我们有一个正确的锁。

下一个是公平性。自旋锁对等待线程有多公平？你能保证等待线程会进入临界区吗？不幸的是，这里的答案是坏消息：自旋锁不提供任何公平性保证。事实上，线程旋转可能会永远旋转，在争用下。简单的自旋锁是不公平的，可能会导致饥饿。

最后一个是性能。使用自旋锁的成本是多少？为了更仔细地分析这一点，我们建议考虑几种不同的情况。在第一种情况下，想象线程在单个处理器上争夺锁；在第二种情况下，考虑分布在多个 CPU 上的线程。

对于自旋锁，在单 CPU 情况下，性能开销可能非常大；想象一下持有锁的线程在关键部分内被抢占的情况。然后，调度程序可能会运行其他每个线程（假设有 N - 1 个其他线程），每个线程都试图获取锁。在这种情况下，每个线程都会在放弃 CPU 之前旋转一个时间片，浪费 CPU 周期。

但是，在多 CPU 上，自旋锁的效果相当好（如果线程数大致等于 CPU 数）。思路如下：假设线程 A 在 CPU 1 上，线程 B 在 CPU 2 上，两者都在争夺一个锁。如果线程 A（CPU 1）抢占锁，然后线程 B 尝试抢占，则线程 B 将自旋（在 CPU 2 上）。但是，可能临界区很短，因此锁很快就会可用，并由线程 B 获取。在这种情况下，自旋以等待另一个处理器上持有的锁不会浪费很多周期，因此是有效的。

# 28.9 Compare-And-Swap
某些系统提供的另一个硬件原语称为 compare-and-swap 指令（例如，在 SPARC 上调用）或compare-and-exchange（在 x86 上调用）。此单个指令的 C 伪代码如图 28.4 所示。

![[Pasted image 20241022193203.png]]

compare-and-swap 的基本思想是测试 ptr 指定的地址处的值是否等于预期值；如果是，则用新值更新 ptr 指向的内存位置。如果不是，则不执行任何操作。在任一情况下，返回该内存位置的原始值，从而允许调用比较和交换的代码知道它是否成功。

使用compare-and-swap 指令，我们可以以与test-and-set非常相似的方式构建锁。例如，我们可以用以下内容替换上面的 lock() 例程：
![[Pasted image 20241022193430.png]]

代码的其余部分与上面的test-and-set示例相同。此代码的工作原理非常相似；它只是检查标志是否为 0，如果是，则自动交换为 1，从而获取锁。在锁被持有期间尝试获取锁的线程将卡在旋转状态，直到锁最终被释放。

最后，正如您可能已经感觉到的，compare-and-swap是比test-and-set更强大的指令。我们将在将来简要探讨无锁同步等主题时利用这种能力。但是，如果我们只是用它构建一个简单的自旋锁，它的行为与我们上面分析的自旋锁相同。

# 28.10 链接加载和条件存储
一些平台提供了一对协同工作的指令来帮助构建临界区。例如，在 MIPS 架构上，可以同时使用load-linked指令和store-conditional指令来构建锁和其他并发结构。这些指令的 C 伪代码如图 28.5 所示。Alpha、PowerPC 和 ARM 提供类似的指令。
![[Pasted image 20241022202735.png]]

在多线程或并发编程中，`load-linked` 和 `store-conditional` 是用于实现原子操作的重要指令。它们的工作原理如下：

1. **load-linked（LL）**：这个指令从给定的内存地址读取值，并在后台设置一个监视器，监视该地址是否在之后被其他线程或进程修改。
2. **store-conditional（SC）**：这个指令用于尝试将一个新值写入之前通过 `load-linked` 读取的地址。它的关键在于：
   - 只有在没有其他线程对该地址进行存储操作的情况下，`store-conditional` 才会成功。如果成功，它会返回1，并将新值写入该地址。
   - 如果在调用 `store-conditional` 之前，该地址已经被其他线程修改，那么操作会失败，此时不会更新地址中的值，返回0。

这种机制允许开发者安全地实现锁-free 数据结构和算法，因为它确保了在进行更新操作时，没有其他线程干扰，避免了数据竞争问题。

作为对自己的挑战，尝试思考如何使用加载链接指令和存储条件构建锁。然后，当您完成后，查看下面的代码，它提供了一个简单的解决方案。 解决方案如图 28.6 所示。

![[Pasted image 20241022203014.png]]

lock() 代码是唯一有趣的部分。 首先，一个线程旋转等待标志设置为 0（从而表明锁未被持有）。 一旦这样，线程就会尝试通过 store-conditional 获取锁； 如果成功，则线程已原子地将标志的值更改为 1，因此可以进入临界区。 

注意store-conditional 可能失败的原因。一个线程调用lock() 并执行load-linked，由于未持有锁，因此返回 0。在尝试 store-conditional 之前，它被中断，另一个线程进入锁定代码，也执行load-linked 指令，也获得 0 并继续。此时，两个线程都已执行load-linked，并且每个线程都即将尝试store-conditional。这些指令的关键特性是，只有其中一个线程会成功将标志更新为 1 并因此获取锁；尝试store-conditional 的第二个线程将失败，因此必须再次尝试获取锁。

更短的代码：
![[Pasted image 20241022203719.png]]

# 28.11 Fetch-And-Add
最后一个硬件原语是Fetch-And-Add指令，它以原子方式增加一个值，同时返回特定地址的旧值。取数并加法指令的 C 伪代码如下所示：
![[Pasted image 20241022203925.png]]
在这个例子中，我们将使用fetch-and-add来构建一个更有趣的锁，正如 Mellor-Crummey 和 Scott 所介绍的那样。图 28.7中给出了lock和unlock代码。

此解决方案不使用单个值，而是使用a ticket和turn variable 组合来构建锁。基本操作非常简单：当线程希望获取锁时，它首先对ticket value执行原子fetch-and-add；该值现在被视为此线程的“轮次”(myturn)。然后使用全局共享的 lock->turn 来确定轮到哪个线程；当 (myturn == turn) 对于给定线程时，轮到该线程进入临界区。解锁只需增加轮次即可完成，以便下一个等待线程（如果有）现在可以进入临界区。

请注意，此解决方案与我们之前的尝试相比有一个重要区别：它确保所有线程的进度。一旦为线程分配了其ticket value，它将在未来的某个时间点被调度（一旦它前面的线程通过了关键部分并释放了锁）。在我们之前的尝试中，并不存在这样的保证；例如，在test-and-set上旋转的线程可以永远旋转，即使其他线程获取并释放了锁。

![[Pasted image 20241022204123.png]]

# 28.12 Too Much Spinning: What Now?
我们的基于硬件的锁很简单（只有几行代码）而且它们有效，这是任何系统或代码的两个优秀属性。但是，在某些情况下，这些解决方案可能非常低效。想象一下，您正在单处理器上运行两个线程，一个线程（线程 0）处于临界区，因此持有一个锁，但不幸的是被中断了。第二个线程（线程 1）现在尝试获取锁，但发现它被持有了。因此，它开始旋转，然后继续旋转。最后，计时器中断响起，线程 0 再次运行，释放锁，最后（比如说，下次运行时），线程 1 不必旋转那么多，并且能够获取锁。因此，任何时候线程在这种情况下陷入旋转，它都会浪费整个时间片，除了检查一个不会改变的值之外什么都不做！当 N 个线程争用一个锁时，问题会变得更糟；N - 1 个时间片可能会以类似的方式被浪费，只是旋转并等待单个线程释放锁。因此，我们的下一个问题是：

How to avoid spining?
How can we develop a lock that doesn't needlessly waste time spining on the CPU?

仅靠硬件支持无法解决问题。我们还需要操作系统支持！现在让我们看看它是如何工作的。

# 28.13 A Simple Approach: Just Yield
硬件支持让我们取得了很大进展：工作锁，甚至（与 ticket 锁的情况一样）锁获取的公平性。然而，我们仍然有一个问题：当在临界区发生上下文切换时，并且某线程开始无休止地旋转，等待被中断的（持有锁的）线程再次运行时，该怎么办？

我们第一次尝试的是一种简单而友好的方法：当你要旋转时，将 CPU 让给另一个线程。正如 Al Davis 可能会说的那样，“放弃吧，宝贝！”。
![[Pasted image 20241022205137.png]]

在这种方法中，我们假设一个操作系统原语yield()，当线程想要放弃CPU并让另一个线程运行时，可以调用该原语。线程可以处于三种状态之一（运行、就绪或阻塞）；yield只是一个系统调用，它将调用者从运行状态移到就绪状态，从而将另一个线程提升为运行状态。因此，yielding线程本质上是取消了自身的调度。

考虑一个CPU上有两个线程的示例；在这种情况下，我们基于yield的方法效果很好。如果一个线程恰好调用lock()并发现持有锁，它将简单地让出CPU，因此另一个线程将运行并完成其关键部分。在这个简单的情况下，让步方法效果很好。

现在让我们考虑有许多线程（比如100个）反复争用锁的情况。在这种情况下，如果一个线程获取了锁并在释放之前被抢占，其他99个线程将分别调用lock()，发现锁被占有了，然后就会让出CPU。假设某种循环调度程序，在持有锁的线程再次运行之前，99 个线程中的每一个都将执行此运行和让出模式。虽然比我们的旋转方法（会浪费 99 个时间片旋转）更好，但这种方法仍然成本高昂；上下文切换的成本可能很高，因此会造成大量浪费。

更糟糕的是，这种方法没有解决饥饿问题。当其他线程反复进入和退出临界区时，一个线程可能会陷入无限的让出循环。我们显然需要一种直接解决饥饿问题的方法。

# 28.14 使用队列：休眠而不是旋转
一些先前方法（ticket 锁除外）的真正问题是它们将太多事情留给了机会。调度程序决定接下来运行哪个线程；如果调度程序做出了错误的选择，则运行的线程必须旋转等待锁（我们的第一种方法），或者立即放弃 CPU（我们的第二种方法）。无论哪种方式，都可能造成浪费，并且无法防止饥饿。

因此，我们必须明确控制当前持有者释放锁后哪个线程接下来获得锁。为此，我们需要更多的操作系统支持，以及一个队列来跟踪哪些线程正在等待获取锁。

为简单起见，我们将使用 Solaris 提供的支持，即两个调用：park() 用于将调用线程置于休眠状态，unpark(threadID) 用于唤醒由 threadID 指定的特定线程。这两个例程可以串联使用，以构建一个锁，如果调用者试图获取持有的锁，则将其置于休眠状态，并在锁空闲时将其唤醒。让我们看看图 28.9 中的代码，以了解此类原语的一种可能用途。

![[Pasted image 20241022210031.png]]

在这个例子中，我们做了一些有趣的事情。首先，我们将旧的test-and-set 思想与显式的锁等待队列相结合，以创建更高效​​的锁。其次，我们使用队列来帮助控制谁接下来获得锁，从而避免饥饿。

guard 是互斥访问锁的信号量，确保只有一个线程可以修改锁的状态。
您可能会注意到guard是如何使用的（图 28.9），基本上是作为锁正在使用的标志和队列操作的自旋锁。因此，这种方法不能完全避免自旋等待；线程可能会在获取或释放锁时被中断，从而导致其他线程自旋等待该线程再次运行。但是，自旋所花费的时间非常有限（只有锁定和解锁代码中的几条指令，而不是用户定义的临界区），因此这种方法可能是合理的。

您可能还会注意到，在 lock() 中，当线程无法获取锁（锁已被持有）时，我们会小心地将自己添加到队列中（通过调用 gettid() 函数获取当前线程的线程 ID），将 guard 设置为 0，并让出 CPU。读者可以思考一下：如果 guard 锁的释放发生在 park() 之后，而不是之前，会发生什么？提示：可能会出现一些问题。

您可能进一步发现，当另一个线程被唤醒时，flag不会重新设置为 0。为什么会这样？好吧，这不是错误，而是一种必要！当一个线程被唤醒时，它就像是从 park() 返回一样；但是，它在代码中的那个点没有保持guard，因此甚至无法尝试将标志设置为 1。因此，我们只是将锁直接从释放锁的线程传递给下一个获取锁的线程；在此期间标志不会设置为 0。

最后，您可能会注意到解决方案中在调用 park() 之前出现的竞争条件。如果时机不对，线程将要停驻，假设它应该休眠直到锁不再被占有。此时切换到另一个线程（例如，持有锁的线程）可能会导致问题，例如，如果该线程随后释放了锁。第一个线程随后的停驻将永远休眠（可能），这个问题有时称为唤醒/等待竞争。

Solaris 通过添加第三个系统调用 setpark() 解决了这个问题。通过调用此例程，线程可以指示它即将停放。如果它碰巧被中断，并且另一个线程在实际调用 park 之前调用 unpark，则后续的 park 将立即返回，而不是休眠。lock() 内部的代码修改非常小：

![[Pasted image 20241022213649.png]]

另一种解决方案是将保护传递到内核。在这种情况下，内核可以采取预防措施，自动释放锁并使正在运行的线程出队。

# 28.15 不同的OS，不同支持
到目前为止，我们已经看到了操作系统可以提供的一种支持，以便在线程库中构建更高效的锁。其他操作系统也提供类似的支持；细节各不相同。

Futex（Fast Userspace Mutex）是Linux内核提供的一种高效的用户空间同步机制，主要用于实现线程间的互斥和条件变量。Futex 的设计旨在减少上下文切换和内核调用的开销，从而提高多线程程序的性能。

### Futex 的基本原理

1. **用户空间操作**：Futex 允许线程在用户空间进行大部分操作，例如尝试获得锁或进行条件等待。这些操作不会引起上下文切换，因而非常快速。

2. **内核参与**：只有在需要阻塞线程时（例如，锁被其他线程持有时），Futex 才会与内核交互。这时，内核会将线程状态改变为“睡眠”，并在锁释放时唤醒相应的线程。

3. **原子性**：Futex 提供的操作是原子的，可以防止数据竞争。

### Futex 的使用场景

- **互斥锁**：使用 Futex 实现互斥锁，避免在不必要的情况下进入内核。
- **条件变量**：用于实现线程的等待和通知机制。
- **读写锁**：高效管理对共享资源的读写访问。

### Futex 的优点

- **性能高**：大多数操作在用户空间完成，减少了内核切换的开销。
- **灵活性**：可以支持多种同步机制，如互斥锁和条件变量。

### Futex 的缺点

- **复杂性**：由于 Futex 涉及用户空间和内核空间的交互，编写基于 Futex 的代码可能较复杂。
- **调试困难**：在高并发情况下，可能会出现难以重现的竞态条件和死锁问题。


例如，Linux 提供了一个与 Solaris 接口类似但提供更多内核功能的 futex。具体来说，每个 futex 都与一个特定的物理内存位置以及每个 futex 的内核队列相关联。调用者可以使用 futex 调用（如下所述）根据需要进入休眠和唤醒状态。

具体来说，有两个调用可用。对 futex wait(address,expected) 的调用使调用线程进入睡眠状态，假设地址 address 处的值等于 expected。如果不相等，则调用立即返回。对例程 futex wake(address) 的调用唤醒一个在队列中等待的线程。Linux 互斥锁中这些调用的用法如图 28.10所示。

![[Pasted image 20241022215123.png]]

nptl 库（gnu libc 库的一部分）中的 lowlevellock.h 中的这段代码片段很有趣，原因如下。首先，它使用单个整数来跟踪锁是否被持有（整数的高位）以及锁上的等待者数量（所有其他位）。因此，如果锁为负，则表示锁被持有（因为高位已设置，并且该位决定了整数的符号）。

其次，代码片段展示了如何针对常见情况进行优化，特别是在没有锁争用的情况下；只有一个线程获取和释放锁，几乎不需要做任何工作（原子位测试和设置以锁定以及原子添加以释放锁）。

# 28.16 二阶段锁
最后要说明的是：Linux 方法带有一种旧方法的味道，这种方法已经断断续续使用了好几年，至少可以追溯到 20 世纪 60 年代早期的 Dahm Locks，现在被称为两相锁。两相锁意识到旋转很有用，特别是当锁即将被释放时。因此，在第一阶段，锁会旋转一段时间，希望能够获得锁。

但是，如果在第一个旋转阶段没有获得锁，则进入第二阶段，调用者将进入休眠状态，并且只有在锁稍后空闲时才会被唤醒。上面的 Linux 锁就是这样一种锁，但它只旋转一次；这种锁的一般化可以在循环中旋转一段固定的时间，然后使用 futex 支持进入休眠状态。

两相锁是混合方法的另一个例子，将两个好的想法结合起来确实可以产生一个更好的想法。当然，是否能做到这一点在很大程度上取决于很多因素，包括硬件环境、线程数量和其他工作负载细节。一如既往，制作一个适用于所有可能用例的通用锁是一项相当大的挑战。



## 旁注：避免使用自旋锁的更多原因：优先级反转
避免使用自旋锁的一个很好的理由是性能：如正文所述，如果线程在持有锁时被中断，则使用自旋锁的其他线程将花费大量 CPU 时间等待锁可用。然而，事实证明，在某些系统上避免使用自旋锁还有另一个有趣的原因：正确性。需要警惕的问题称为优先级反转，不幸的是，这是一个星际祸害，发生在地球和火星！

假设系统中有两个线程。线程 2 (T2) 具有高调度优先级，线程 1 (T1) 具有较低的优先级。在这个例子中，假设 CPU 调度程序将始终运行 T2 而不是 T1，如果两者都可运行的话； T1 仅在 T2 无法运行（例如，当T2 在 I/O 上被阻塞时）时运行。

现在，问题来了。假设 T2 由于某种原因被阻塞。因此 T1 运行，获取自旋锁，并进入临界区。T2 现在变为未阻塞状态（可能是因为 I/O 已完成），并且 CPU 调度程序立即对其进行调度（从而取消调度 T1）。T2 现在尝试获取锁，但由于它无法获取锁（T1 持有锁），它只是继续旋转。由于锁是自旋锁，T2 永远旋转，系统挂起。

不幸的是，仅仅避免使用自旋锁并不能避免反转问题。想象三个线程，T1、T2 和 T3，T3 具有最高优先级，而 T1 具有最低优先级。现在想象一下 T1 获取锁。然后 T3 启动，并且由于它的优先级高于 T1，因此立即运行（抢占 T1）。 T3 尝试获取 T1 持有的锁，但却陷入等待状态，因为 T1 仍持有该锁。如果 T2 开始运行，它的优先级将高于 T1，因此它将运行。优先级高于 T2 的 T3却陷入等待 T1 的状态，而 T2 正在运行，T1 可能永远无法运行。强大的 T3 无法运行，而低级的 T2 控制着CPU，这难道不令人难过吗？高优先级已不复当初。

您可以通过多种方式解决优先级反转问题。在自旋锁导致问题的特定情况下，您可以避免使用自旋锁（下面将详细介绍）。更一般地说，等待低优先级线程的高优先级线程可以暂时提高低优先级线程的优先级，从而使其能够运行并克服优先级反转，这种技术称为优先级继承。最后一个解决方案最简单：确保所有线程具有相同的优先级。


# 28.17 总结
上述方法展示了如今真正的锁是如何构建的：一些硬件支持（以更强大的指令的形式）加上一些操作系统支持（例如，以 Solaris 上的 park() 和 unpark() 原语的形式，或 Linux 上的 futex 的形式）。当然，细节有所不同，并且执行此类锁定的确切代码通常经过高度调整。如果您想了解更多详细信息，请查看 Solaris 或 Linux 代码库；

---
![[Pasted image 20241022194602.png]]


1. `char compare_and_swap(int *ptr, int old, int new) {`  
   定义一个函数 `compare_and_swap`，接受一个指针 `ptr` 和两个整数 `old` 和 `new`。

2. `unsigned char ret;`  
   声明一个无符号字符变量 `ret`，用于存储操作结果（成功或失败）。

3. `__asm__ __volatile__ (`  
   开始内联汇编块，`__volatile__` 表示编译器不会优化掉这个代码块。

4. `" lock\n"`  
   添加 `lock` 前缀，确保在多处理器环境中操作的原子性。

5. `" cmpxchgl %2,%1\n"`  
   使用 `cmpxchgl` 指令，比较 `*ptr` 和 `old`，如果相等，则将 `new` 存入 `*ptr`。`%1` 和 `%2` 分别对应后面输入的 `*ptr` 和 `new`。

6. `" sete %0\n"`  
   使用 `sete` 指令，将比较结果转换为布尔值。如果比较成功，`ret` 将被设置为 1；否则为 0。

7. `: "=q" (ret), "=m" (*ptr)`  
   输出部分：`ret` 的值存储在 `q` 寄存器中，`*ptr` 的内容在内存中被修改。

8. `: "r" (new), "m" (*ptr), "a" (old)`  
   输入部分：`new` 在任意寄存器中，`*ptr` 在内存中，`old` 在 `a` 寄存器中。

9. `: "memory");`  
   通知编译器该汇编代码会修改内存中的内容，防止内存重排序。

10. `return ret;`  
    返回操作结果 `ret`，指示比较与交换是否成功。

`__volatile__` 是一个关键字，用于告诉编译器不要优化掉这段代码。这通常用于内联汇编或访问硬件寄存器，确保每次执行时都真实执行，而不是根据编译器的假设进行优化。这样可以避免可能的错误，特别是在多线程或中断环境中，确保代码的正确性和顺序性。

The `cmpxchgl` instruction, particularly when prefixed with `lock`, acts as a memory fence (or memory barrier). 这意味着它不仅确保了涉及被访问的特定内存位置的操作的顺序，而且还对指令之前和之后发生的所有内存访问施加了顺序。这样可以确保内存操作按指定的顺序完成，防止编译器或 CPU 重新排序。

### Cost Comparison

1. **Cost of `cmpxchgl` with `lock`:** 
   - 由于该指令的原子特性以及确保跨多个处理器的原子性的额外开销，它的成本相对于简单的加载或存储来说较高。
   - 它通常会带来性能损失，因为它可能涉及多核系统中的缓存一致性协议，这会增加延迟。

2. **Cost of a Memory Fence:**
   - A memory fence (like `mfence`, `lfence`, or `sfence`) also incurs a cost, as it similarly prevents reordering of memory operations. However, the cost may vary based on the specific implementation and architecture.阻止内存操作重排
   - Memory fences generally provide less functionality than `cmpxchgl` because they don't perform any value comparison or swapping, but they still can be costly.

### Summary
就功能而言，带锁的 cmpxchgl 可以充当更全面的内存围栏，同时还可以执行比较并交换操作。由于其原子特性以及与缓存一致性机制的潜在交互作用，该成本高于标准内存围栏。

---
A memory fence (or memory barrier) is a mechanism used in concurrent programming to enforce ordering constraints on memory operations. 它阻止 CPU 或编译器重新排序读写操作，确保某些内存访问按指定的顺序完成。这在多线程环境中尤其重要，因为在多线程环境中，不同的线程可能会访问共享数据。

### Key Points about Memory Fences:

1. **Types of Fences:**
   - **Load Fence (`lfence`)**: Ensures that all load (read) operations before the fence are completed before any load operations that follow.
   - **Store Fence (`sfence`)**: Ensures that all store (write) operations before the fence are completed before any store operations that follow.
   - **Full Fence (`mfence`)**: Ensures that both load and store operations are completed in order.

2. **Purpose:**
   - To prevent reordering of memory operations by the compiler or CPU, which could lead to unexpected behavior in multi-threaded applications.
   - To ensure visibility of memory changes between threads, allowing one thread to see the updates made by another.

3. **Usage Context:**
   - Commonly used in low-level programming, such as operating systems, embedded systems, and high-performance computing, where fine control over memory access is required.

4. **Performance Impact:**
   - Memory fences can introduce performance overhead because they prevent certain optimizations. Therefore, they should be used judiciously to avoid unnecessary slowdowns.

In summary, memory fences are crucial for maintaining data consistency and correctness in concurrent programming by enforcing a strict order on memory operations.