# Faults and Partial Failures
这是计算机设计中的一个刻意选择：如果发生内部故障，我们宁愿计算机彻底崩溃，也不愿返回错误的结果，因为错误的结果处理起来既困难又令人困惑。因此，计算机隐藏了其实现所基于的模糊的物理现实，并呈现了一个理想化的系统模型，该模型以数学上的完美性运行。CPU 指令总是执行相同的操作；如果您将某些数据写入内存或磁盘，这些数据将保持完整，并且不会随机损坏。这种始终正确的计算的设计目标可以追溯到第一台数字计算机。

当你编写的软件运行在通过网络连接的多台计算机上时，情况就截然不同了。在分布式系统中，我们不再是在理想化的系统模型中运行——我们别无选择，只能面对物理世界的混乱现实。而在物理世界中，各种各样的事情都可能出错，正如这则轶事[4]所说明的那样：

在分布式系统中，即使系统的其他部分运行良好，也可能存在某些部分以某种不可预测的方式出现故障。这被称为部分故障。问题在于部分故障具有不确定性：如果你尝试执行任何涉及多个节点和网络的操作，它有时可能成功，有时也可能意外失败。正如我们将看到的，你甚至可能不知道某些操作是否成功，因为消息在网络中传输所需的时间也是不确定的！

# Cloud Computing and Supercomputing
关于如何构建大规模计算系统存在一系列的理念：
- 高性能计算 (HPC) 领域处于这一领域的一端。拥有数千个 CPU 的超级计算机通常用于计算密集型的科学计算任务，例如天气预报或分子动力学（模拟原子和分子的运动）。
- cloud computing
- Traditional enterprise datacenters 位于两个极端之间

这些理念带来了截然不同的故障处理方法。在超级计算机中，a job typically checkpoints the state of its computation to durable storage from time to time. 如果一个节点发生故障，一种常见的解决方案是简单地停止整个集群工作负载。故障节点修复后，计算将从最后一个检查点重新启动[7, 8]。因此，超级计算机更像是一台单节点计算机，而不是分布式系统：它处理部分故障的方式是让故障升级为全面故障——如果系统的任何部分发生故障，就让所有系统崩溃（就像单台机器上的内核崩溃一样）。

In this book we focus on systems for implementing internet services, which usually
look very different from supercomputers:

- online applications，low latency
- 超级计算机通常由专用硬件构建，每个节点都非常可靠，节点通过共享内存和远程直接内存访问 (RDMA) 进行通信。另一方面，云服务中的节点由商用机器构建，由于规模经济，它们可以以更低的成本提供同等的性能，但故障率也更高。
- 大型数据中心网络通常基于 IP 和以太网，采用 Clos 拓扑结构来提供高 bisection bandwidth [9]。超级计算机通常使用专门的网络拓扑结构，例如多维网格和环面 [10]，这些结构对于已知通信模式的 HPC 工作负载而言，可以提供更佳的性能。
- 系统越大，其组件发生故障的可能性就越大。随着时间的推移，故障会被修复，新的组件也会发生故障，但在一个拥有数千个节点的系统中，可以合理地假设某些组件总是会出故障 [7]。当错误处理策略只是简单地放弃时，大型系统最终可能会花费大量时间从故障中恢复，而不是执行有用的工作 [8]。
- 如果系统能够容忍节点故障，同时仍然保持整体运行，那么这对于运维来说是一个非常有用的特性：例如，您可以执行滚动升级（参见第 4 章），一次重启一个节点，同时服务继续不间断地为用户提供服务。在云环境中，如果某个虚拟机性能不佳，您可以直接终止它并申请一个新的（希望新的虚拟机速度更快）。
- 在地理分布的部署中（将数据保持在地理位置上靠近用户的位置以减少访问延迟），通信很可能通过互联网进行，与本地网络相比，互联网速度慢且不可靠。超级计算机通常假设其所有节点都彼此靠近。

如果我们想要使分布式系统正常运行，就必须接受部分故障的可能性，并在软件中构建容错机制。换句话说，我们需要用不可靠的组件构建一个可靠的系统。（正如第 6 页“可靠性”部分所述，不存在完美的可靠性，因此我们需要了解我们能够实际承诺的极限。）

> Building a Reliable System from Unreliable Components
> 
> 您可能想知道这是否合理——直观地看，一个系统的可靠性似乎只能取决于其最不可靠的组件（最薄弱的环节）。但事实并非如此：事实上，在计算领域，从不太可靠的底层构建更可靠的系统是一个古老的想法[11]。例如：
 - 纠错码允许数字数据在偶尔出现错误（例如由于无线网络中的无线电干扰而导致的）的通信信道上准确传输[12]。
> - IP（互联网协议）不可靠：它可能会丢弃、延迟、重复或重新排序数据包。TCP（传输控制协议）在 IP 之上提供了一个更可靠的传输层：它确保丢失的数据包被重新传输，重复的数据包被消除，并且数据包被重新组装成它们发送的顺序。
>
>尽管系统可以比其底层部分更可靠，但其可靠性始终是有限的。例如，纠错码可以处理少量的单位错误，但如果信号受到干扰，通过通信信道传输的数据量就会受到根本限制[13]。TCP 可以隐藏数据包丢失、重复和乱序，但它无法神奇地消除网络延迟。
>
>虽然更可靠的高层系统并不完美，但它仍然有用，因为它可以处理一些棘手的低层故障，因此其余故障通常更容易推理和处理。我们将在第 519 页的“端到端论证”中进一步探讨这个问题。

# Unreliable Networks
The internet and most internal networks in datacenters (often Ethernet) are asynchronous packet networks. In this kind of network, one node can send a message (a packet) to another node, but the network gives no guarantees as to when it will arrive, or whether it will arrive at all. If you send a request and expect a response, many things could go wrong (some of which are illustrated in Figure 8-1):
1. Your request may have been lost (perhaps someone unplugged a network cable).
2. Your request may be waiting in a queue and will be delivered later (perhaps the network or the recipient is overloaded).
3. The remote node may have failed (perhaps it crashed or it was powered down).
4. The remote node may have temporarily stopped responding (perhaps it is experiencing a long garbage collection pause; see “Process Pauses” on page 295), but it will start responding again later.
5. The remote node may have processed your request, but the response has been lost on the network (perhaps a network switch has been misconfigured).
6. The remote node may have processed your request, but the response has been delayed and will be delivered later (perhaps the network or your own machine is overloaded).
![[Pasted image 20250707112458.png]]

发送方甚至无法判断数据包是否已送达：唯一的选择是接收方发送响应消息，而响应消息可能会丢失或延迟。这些问题在异步网络中难以区分：你唯一掌握的信息是你尚未收到响应。如果你向另一个节点发送请求，而没有收到响应，则无法确定原因。

处理此问题的常用方法是超时：一段时间后，你放弃等待，并假设响应不会到达。然而，当发生超时时，你仍然不知道远程节点是否收到了你的请求（如果请求仍在某个队列中，即使发送方已经放弃，它仍然可能被传递给接收方）。

# Network Faults in Practice
一些系统性研究和大量的轶事证据表明，即使在受控环境中，例如由一家公司运营的数据中心[14]，网络问题也可能异常常见。一项针对中型数据中心的研究发现，每月大约发生12次网络故障，其中一半导致单台机器断开连接，另一半导致整个机架断开连接[15]。另一项研究测量了架顶式交换机、聚合交换机和负载均衡器等组件的故障率[16]。研究发现，添加冗余网络设备并不能像预期的那样减少故障，因为它无法防范人为错误（例如，交换机配置错误），而人为错误是造成中断的主要原因。

EC2 等公有云服务因频繁出现瞬时网络故障而臭名昭著 [14]，而管理良好的私有数据中心网络可以提供更稳定的环境。然而，没有人能够免受网络问题的影响：例如，交换机软件升级过程中出现的问题可能会触发网络拓扑重新配置，在此期间网络数据包可能会延迟超过一分钟 [17]。鲨鱼可能会咬坏海底电缆 [18]。其他令人意外的故障包括网络接口有时会丢弃所有入站数据包，但出站数据包却能成功发送 [19]：网络链路在一个方向上工作正常，并不能保证它在相反方向上也能正常工作。

如果网络故障的错误处理机制未定义且未经过测试，则可能会发生各种糟糕的事情：例如，集群可能会陷入死锁，即使网络恢复正常[20]，也永远无法处理请求，甚至可能删除所有数据[21]。如果软件处于意外情况，它可能会做出各种意想不到的举动。

处理网络故障并不一定意味着容忍它们：如果您的网络通常相当可靠，那么一个有效的方法可能是在网络出现问题时向用户显示一条错误消息。但是，您确实需要了解您的软件如何应对网络问题，并确保系统能够从中恢复。故意触发网络问题并测试系统的响应可能是有意义的（这是 Chaos Monkey 背后的想法；请参阅第 6 页的“可靠性”）。

# Detecting Faults
系统需要自动检测节点失效：

不幸的是，网络的不确定性使得判断一个节点是否正常工作变得困难。在某些特定情况下，你可能会收到一些反馈，明确地告诉你某些节点出了问题：
- 如果您可以访问节点应该运行的机器，但没有进程在目标端口上监听（例如，由于进程崩溃），操作系统将通过发送 RST 或 FIN 数据包作为回复来关闭或拒绝 TCP 连接。但是，如果节点在处理您的请求时崩溃，您就无法知道远程节点实际处理了多少数据 [22]。
- 如果某个节点进程崩溃（或被管理员终止），但该节点的操作系统仍在运行，则脚本可以通知其他节点崩溃的情况，以便另一个节点可以快速接管，而无需等待超时。例如，HBase 就是这样做的 [23]。
- 如果您可以访问数据中心网络交换机的管理接口，则可以查询它们以检测硬件级别的链路故障（例如，如果远程计算机已关闭）。如果您通过互联网连接，或者您位于共享数据中心而无法访问交换机本身，或者由于网络问题而无法访问管理接口，则此选项不适用。
- 如果路由器确定您尝试连接的 IP 地址无法访问，它可能会向您发送 ICMP 目标不可达数据包。然而，路由器也没有神奇的故障检测能力——它与网络的其他参与者一样，受到同样的限制。

关于远程节点宕机的快速反馈很有用，但你不能指望它。即使 TCP 确认数据包已送达，应用程序也可能在处理它之前就崩溃了。如果你想确保请求成功，你需要应用程序本身的肯定响应 [24]。

相反，如果出现问题，你可能会在堆栈的某个级别收到错误响应，但通常你必须假设你根本不会收到任何响应。你可以重试几次（TCP 重试是透明的，但你也可以在应用程序级别重试），等待超时，如果在超时时间内没有收到回复，最终宣布该节点已宕机。

# Timeouts and Unbounded Delays
多久设置 timeout 时间？

过早地宣布一个节点死亡是有问题的：如果该节点实际上处于活动状态，并且正在执行某项操作（例如，发送电子邮件），而另一个节点接管了该操作，则该操作最终可能会被执行两次。我们将在第300页的“知识、真相与谎言”以及第9章和第11章中更详细地讨论这个问题。

当一个节点被宣布死亡时，其职责需要转移到其他节点，这会给其他节点和网络带来额外的负载。如果系统已经承受着高负载，过早地宣布节点死亡可能会使问题更加严重。具体来说，节点可能实际上并没有死亡，只是由于过载而响应缓慢；将其负载转移到其他节点可能会导致级联故障（在极端情况下，所有节点都会宣布彼此死亡，然后一切都停止工作）。

设想一个虚拟系统，其网络保证了数据包的最大延迟——每个数据包要么在时间 d 内送达，要么丢失，但送达时间绝不会超过 d。此外，假设您可以保证一个非故障节点始终在时间 r 内处理请求。在这种情况下，您可以保证每个成功的请求都会在 2d + r 的时间内收到响应——如果您在该时间内没有收到响应，则说明网络或远程节点存在故障。如果情况属实，那么 2d + r 就是一个合理的超时时间。

不幸的是，我们使用的大多数系统都无法提供上述任何一种保证：异步网络的延迟是无限的（也就是说，它们会尝试尽快地传送数据包，但数据包到达所需的时间没有上限），并且大多数服务器实现无法保证它们能够在某个最大时间内处理请求（请参阅第 298 页的“响应时间保证”）。对于故障检测而言，系统在大多数情况下保持快速运行是不够的：如果超时时间很短，那么只需往返时间出现短暂的峰值，系统就会失去平衡。

## Network congestion and queueing
类似地，计算机网络上数据包延迟的变化通常是由于排队[25]造成的：
- 如果多个不同的节点同时尝试向同一目的地发送数据包，网络交换机必须将它们排队，并逐个将它们送入目标网络链路（如图 8-2 所示）。在繁忙的网络链路上，数据包可能需要等待一段时间才能获得一个插槽（这称为网络拥塞）。如果传入数据过多，交换机队列已满，则该数据包将被丢弃，因此需要重新发送——即使网络运行正常。
![[Pasted image 20250707142419.png]]

- 当数据包到达目标机器时，如果所有 CPU 核心当前都处于繁忙状态，则来自网络的传入请求将被操作系统排队，直到应用程序准备好处理它。根据机器的负载，这可能需要任意长的时间。
- 在虚拟化环境中，正在运行的操作系统通常会暂停数十毫秒，而另一个虚拟机则会使用一个 CPU 核心。在此期间，虚拟机无法使用来自网络的任何数据，因此传入的数据会被虚拟机监视器排队（缓冲）[26]，这进一步增加了网络延迟的变化。
- TCP performs *flow control* (congestion avoidance or backpressure), in which a node limits its own rate of sending in order to avoid overloading a network link or the receiving node. This means additional queueing at the sender before the data even enters the network.

此外，如果数据包在某个超时时间（根据观察到的往返时间计算）内未得到确认，TCP 会将其视为丢失，并且丢失的数据包会自动重传。虽然应用程序看不到数据包丢失和重传，但它确实能看到由此产生的延迟（等待超时到期，然后等待重传的数据包得到确认）。

在这样的环境中，您只能通过实验来选择超时：测量在较长时间内、在多台机器上网络往返时间的分布，以确定延迟的预期变化。然后，结合应用程序的特性，您可以在故障检测延迟和过早超时的风险之间找到一个合适的平衡点。

更妙的是，系统无需使用已配置的恒定超时，而是可以持续测量响应时间及其变化（抖动），并根据观察到的响应时间分布自动调整超时。这可以通过 Phi Accrual 故障检测器 [30] 来实现，例如 Akka 和 Cassandra [31] 就使用了该检测器。TCP 重传超时也采用类似的原理 [27]。

# Synchronous Versus Asynchronous Networks
如果我们可以依赖网络以固定的最大延迟传递数据包，并且不丢弃数据包，那么分布式系统就会简单得多。为什么我们不能在硬件层面解决这个问题，让网络变得可靠，这样软件就无需担心了呢？

为了回答这个问题，将数据中心网络与传统的固定电话网络（非蜂窝、非 VoIP）进行比较会很有意思。传统的固定电话网络极其可靠：音频帧延迟和掉线的情况非常罕见。电话通话需要持续较低的端到端延迟和足够的带宽来传输语音样本。如果计算机网络也能拥有类似的可靠性和可预测性，那岂不是很好？

当你通过电话网络拨打电话时，它会建立一条线路：在通话双方之间的整个路径上，会为通话分配固定且有保证的带宽。该线路会一直保持到通话结束 [32]。例如，ISDN 网络以每秒 4,000 帧的固定速率运行。通话建立后，会在每帧内（每个方向）分配 16 位的空间。
因此，在通话期间，每一方都能保证每 250 微秒发送恰好 16 位的音频数据 [33, 34]。

这种网络是同步的：即使数据经过多个路由器，也不会受到排队的影响，因为用于呼叫的16位空间已经在网络的下一跳中预留。而且由于没有排队，网络的最大端到端延迟是固定的。我们称之为有界延迟。

## Can we not simply make network delays predictable?
请注意，电话网络中的电路与 TCP 连接截然不同：电路是固定数量的预留带宽，在建立电路期间，其他任何人都无法使用；而 TCP 连接的数据包则会随机使用所有可用的网络带宽。您可以向 TCP 发送一个大小可变的数据块（例如，一封电子邮件或一个网页），它会尝试在最短的时间内传输这些数据。TCP 连接空闲时，不会占用任何带宽。

如果数据中心网络和互联网是电路交换网络，那么在建立电路时，就可以保证最大往返时间。然而，它们并非如此：以太网和 IP 是分组交换协议，它们受排队机制的影响，因此网络延迟不受限制。这些协议没有电路的概念。

为什么数据中心网络和互联网使用分组交换？答案是，它们针对突发流量进行了优化。电路适用于音频或视频通话，因为通话期间每秒需要传输相当恒定的比特数。另一方面，请求网页、发送电子邮件或传输文件对带宽没有任何特定要求——我们只是希望它尽快完成。

如果要通过电路传输文件，则必须猜测带宽分配。如果猜测得太低，传输速度会不必要地慢，导致网络容量被闲置。如果猜测得太高，则无法建立电路（因为如果无法保证带宽分配，网络就无法允许创建电路）。因此，使用电路进行突发数据传输会浪费网络容量，并使传输速度不必要地慢。相比之下，TCP 会根据可用的网络容量动态调整数据传输速率。

已经有一些尝试构建同时支持电路交换和分组交换的混合网络，例如 ATM.iii。InfiniBand 与之有一些相似之处 [35]：它在链路层实现端到端流量控制，这减少了网络中排队的需求，尽管它仍然可能因链路拥塞而受到延迟 [36]。通过谨慎使用服务质量（QoS、数据包的优先级和调度）和准入控制（限制发送方的速率），可以在分组网络上模拟电路交换，或提供统计上有界的延迟 [25, 32]。

>Latency and Resource Utilization
更一般地，你可以将可变延迟视为动态资源分配的结果。
>假设两个电话交换机之间有一条线路，最多可同时承载 10,000 个呼叫。通过这条线路交换的每个电路都占用其中一个呼叫时隙。因此，你可以将这条线路视为一种资源，最多可供 10,000 个并发用户共享。该资源以静态方式分配：即使你现在是线路上唯一的呼叫，并且所有其他 9,999 个时隙都未使用，你的线路仍然会分配到与线路满负荷时相同的固定带宽。
相比之下，互联网是动态共享网络带宽的。发送方相互推挤，以便尽快通过线路发送数据包，而网络交换机会根据每个时刻决定发送哪个数据包（即带宽分配）。这种方法存在排队的缺点，但其优点是可以最大限度地利用线路。线路成本是固定的，因此，如果更好地利用线路，通过线路发送的每个字节都会更便宜。
CPU 也存在类似的情况：如果在多个线程之间动态共享每个 CPU 核心，则有时一个线程必须在操作系统的运行队列中等待另一个线程的运行，因此线程可能会暂停不同的时间长度。然而，这比为每个线程分配静态数量的 CPU 周期（参见第 298 页的“响应时间保证”）更能利用硬件。更好的硬件利用率也是使用虚拟机的一个重要动机。
如果资源是静态划分的（例如，专用硬件和独占带宽分配），则可以在某些环境中实现延迟保证。然而，这是以降低利用率为代价的——换句话说，它的成本更高。另一方面，具有动态资源分区的多租户模式能够提供更高的利用率，因此成本更低，但它也存在延迟变化的缺点。网络中的延迟变化并非自然规律，而仅仅是成本/收益权衡的结果。

然而，目前在多租户数据中心、公有云或通过互联网通信时，尚无法实现这种服务质量。iv 当前部署的技术无法保证网络的延迟或可靠性：我们必须假设网络拥塞、排队和无限延迟会发生。因此，超时没有“正确”的值——它们需要通过实验来确定。

# Unreliable Clocks
在分布式系统中，时间是一个棘手的问题，因为通信并非瞬时完成：消息通过网络从一台机器传输到另一台机器需要时间。消息的接收时间总是晚于发送时间，但由于网络延迟的可变性，我们无法知道具体晚了多少。当涉及多台机器时，这一事实有时会使确定事件发生的顺序变得困难。

这些设备并非完全精确，因此每台机器都有自己的时间概念，可能比其他机器略快或略慢。可以在一定程度上同步时钟：最常用的机制是网络时间协议 (NTP)，它允许根据一组服务器报告的时间调整计算机时钟[37]。服务器则从更精确的时间源（例如 GPS 接收器）获取时间。

## 分布式系统中不可靠时间问题

在分布式系统中，时间是一个看似简单却极其复杂的问题。与单机系统不同，分布式系统中的各个节点都有自己的本地时钟，这些时钟之间**无法完全同步**，导致了各种各样的“不可靠时间”问题。这些问题对系统的正确性、一致性和性能都可能产生严重影响。

### 1. 时钟漂移 (Clock Drift)

**时钟漂移**是指不同节点上的本地时钟以不同的速率运行，导致它们之间的时间差不断增大。即使初始时同步了所有时钟，由于硬件（例如晶体振荡器）的微小差异以及环境因素（如温度变化），时钟也会逐渐偏离。

- **影响：**
    
    - **事件顺序错乱：** 如果系统依赖于时间戳来确定事件的顺序，时钟漂移可能导致一个在物理上先发生的事件被标记为后发生。
        
    - **数据不一致：** 在需要协调操作（如分布式事务）的场景中，不一致的时间可能导致数据在不同节点上出现不一致的状态。
        
    - **过期判断错误：** 依赖时间戳进行缓存失效、租约过期等判断时，不准确的时间可能导致数据被错误地保留或过早地删除。
        

### 2. 时钟同步问题

即使使用网络时间协议（NTP）等机制进行时钟同步，也无法实现**完全精确的同步**。网络延迟、数据包丢失以及NTP服务器本身的准确性都限制了同步的精度。

- **影响：**
    
    - **同步误差：** 即使是微小的同步误差，在对时间精度要求极高的场景（例如金融交易、科学计算）中也可能造成重大问题。
        
    - **复杂性：** 实现和维护高精度的时钟同步机制本身就增加了系统的复杂性。
        

### 3. 时间戳的局限性

在分布式系统中，仅仅依靠本地时间戳来排序事件是不可靠的。

- **无法保证因果关系：** 如果事件A发生在节点1，事件B发生在节点2，并且事件B是由于事件A引起的（因果关系），但由于时钟漂移或同步延迟，节点2的本地时间可能比节点1慢，导致B的时间戳早于A。
    
- **并发事件排序：** 对于同时发生的事件（在物理上无法确定先后），单纯依赖时间戳也无法提供明确的排序。
    

### 4. 闰秒问题 (Leap Second)

闰秒是为了使协调世界时（UTC）与地球自转保持一致而偶尔插入或删除的一秒。虽然不经常发生，但闰秒的处理在分布式系统中是一个臭名昭著的问题。

- **影响：**
    
    - **时间跳跃：** 插入或删除一秒可能导致系统时间出现“跳跃”，这会扰乱依赖时间连续性的应用程序。
        
    - **服务中断：** 许多系统在处理闰秒时曾出现故障，导致服务中断或数据错误。
        

### 5. 单调时钟与墙上时钟

分布式系统通常区分两种时钟：

- **墙上时钟 (Wall-clock time/System time)：** 这是我们日常生活中使用的时钟，可以被调整（例如通过NTP），因此可能不连续或回跳。
    
- **单调时钟 (Monotonic clock)：** 这种时钟只保证时间**向前推进**，不会回跳。它通常用于测量时间间隔，而不是绝对时间。
    

在分布式系统中，**仅仅依赖墙上时钟**来测量时间间隔或进行事件排序是危险的，因为墙上时钟可能被调整。

### 解决方案和应对策略

为了解决这些不可靠时间问题，分布式系统通常会采用以下策略：

- **逻辑时钟：** 例如 **Lamport 逻辑时钟** 和 **Vector Clock (向量时钟)**，它们不依赖于物理时间，而是通过事件之间的因果关系来维护事件的顺序。
    
- **同步协议：** 使用 **NTP** 或 **PTP (精确时间协议)** 来尽可能地同步物理时钟，但要认识到其局限性。
    
- **全局唯一ID：** 使用不依赖于时间戳的全局唯一标识符（如UUID或Snowflake ID）来避免时间戳冲突。
    
- **租约 (Leases)：** 使用带有过期时间的租约机制，结合心跳机制，来处理分布式协调中的资源锁定和释放。
    
- **容忍时间不确定性：** 设计系统时要考虑到时间的不确定性，例如在判断事件顺序时留有容错区间。
    
- **时钟同步服务：** 部署专门的时钟同步服务（如Google的TrueTime），提供带误差边界的时间戳，从而使系统能够做出更可靠的决策。
    
## Monotonic clocks
In particular, it makes no sense to compare monotomic clock values from two different computers, because they don't mean the same thing.

分布式系统中的时间同步是一个复杂的问题，而 **NTP (Network Time Protocol)** 正是为了解决这一挑战而设计的。NTP 是互联网上最古老、最广泛使用的协议之一，旨在将计算机系统的时间同步到 **Coordinated Universal Time (UTC)**，通常可以达到毫秒级的精度。

---

## NTP 算法的核心原理

NTP 的核心在于通过计算客户端与服务器之间的时间差和网络延迟，来逐步调整客户端的本地时钟，使其与服务器的时钟保持一致。它主要基于以下几个关键概念和步骤：

### 1. 客户端-服务器通信模型

NTP 通常采用客户端-服务器模型。客户端定期向一个或多个 NTP 服务器发送时间请求，然后根据服务器的响应来调整自己的时钟。

### 2. 四个时间戳

这是 NTP 算法计算时间差和延迟的关键：

当客户端向服务器请求时间时，会记录四个时间戳：

- **T1 (客户端发送时间):** 客户端发送请求包时，客户端的本地时间。
    
- **T2 (服务器接收时间):** 服务器收到客户端请求包时，服务器的本地时间。
    
- **T3 (服务器发送时间):** 服务器发送响应包时，服务器的本地时间。
    
- **T4 (客户端接收时间):** 客户端收到服务器响应包时，客户端的本地时间。
    

### 3. 计算时间偏移量 (Offset) 和往返延迟 (Delay)

NTP 客户端收到服务器的响应后，会利用这四个时间戳计算出：

- **往返延迟 (Round-trip Delay / `delay`):** `delay = (T4 - T1) - (T3 - T2)`
    
    - 这个公式表示了数据包从客户端到服务器再返回客户端的总时间，减去服务器处理请求的时间。理想情况下，`T2 - T1` 是客户端到服务器的单向延迟，`T4 - T3` 是服务器到客户端的单向延迟。
        
    - NTP 假定上行和下行路径的延迟大致相等，因此 **单向延迟近似为 `delay / 2`**。
        
- **时间偏移量 (Clock Offset / `offset`):** `offset = ((T2 - T1) + (T3 - T4)) / 2`
    
    - 这个公式计算出客户端时钟相对于服务器时钟的偏差。如果 `offset` 为正，说明客户端时钟比服务器快；如果为负，则说明客户端时钟比服务器慢。
        

### 4. 时钟调整策略 (Clock Discipline)

NTP 客户端不会简单地将自己的时钟直接跳到计算出的 `offset` 值。为了避免时钟的突然跳变（这可能对某些应用程序造成问题），NTP 通常采用**平滑调整 (slewing)** 的方式：

- **小幅度调整：** 如果计算出的时间偏移量很小（通常在几十到几百毫秒内），NTP 会以一个较慢的速率逐步调整本地时钟的频率，使其慢慢“追赶”或“放慢”到正确的时间，直到消除偏差。这就像调整一个走快或走慢的手表，而不是直接把它拨到正确时间。
    
- **大幅度调整：** 如果时间偏移量非常大（例如几秒甚至更长），NTP 可能会选择直接将时钟跳变到正确的时间。这种情况通常发生在系统启动时，或者长时间没有同步导致时钟严重偏离时。
    

### 5. 分层结构 (Stratum)

NTP 使用分层 (Stratum) 结构来表示时间源的精度和距离：

- **Stratum 0：** 这是最高精度的时间源，通常是原子钟、GPS 接收器或其他无线电时钟。它们不直接连接到网络，而是作为参考时钟。
    
- **Stratum 1：** 直接连接到 Stratum 0 参考时钟的服务器。它们是主要的、高精度的时间服务器。
    
- **Stratum 2：** 从 Stratum 1 服务器获取时间同步的服务器。
    
- **Stratum N：** 从 Stratum N-1 服务器获取时间同步的服务器。
    

数字越小，表示时间源越接近高精度参考时钟，其时间精度也越高。客户端通常会连接到多个不同 Stratum 级别的服务器，以提高鲁棒性和选择最佳时间源。

### 6. 服务器选择与过滤算法

为了应对网络不稳定、服务器故障或恶意服务器等问题，NTP 客户端通常会从多个服务器获取时间样本，并使用复杂的算法（如 **Intersection Algorithm**，一种改进的 Marzullo 算法）来：

- **筛选 (Filtering)：** 识别并排除那些延迟过高或时间明显错误的服务器。
    
- **选择 (Selection)：** 从剩下的“合格”服务器中，根据它们的精度、稳定性和到参考时钟的距离等因素，选择一个或几个最佳的时间源来同步。
    

### 7. 闰秒处理 (Leap Second)

NTP 还能够处理闰秒。当国际地球自转服务（IERS）宣布将插入或删除一秒时，NTP 服务器会在特定时间点向客户端发出警告，以便客户端能够平滑地处理这一秒的调整，避免时间跳变引发的问题。

---

**总结来说，NTP 算法通过精确测量网络延迟和时间偏移，并结合多源选择、分层结构和智能的时钟调整策略，实现了在不稳定的网络环境下高精度、高鲁棒性的时间同步。**

## Timestamps for ordering events
If two clients write to a distributed database, who got there first? Which write is the more recent one?

![[Pasted image 20250712131943.png]]
Illustrates a dangerous use of time-of-day clocks in a database with multi-leader replication


last write wins

## “最后写入者获胜”（Last Write Wins - LWW）解释

**“最后写入者获胜”（Last Write Wins - LWW）**是一种在**分布式系统**中解决**数据冲突**的常用策略。当多个客户端或节点同时尝试修改同一个数据项时，不可避免地会出现冲突。LWW 策略的核心思想是：**系统会接受并保留所有写入操作中，时间戳（或版本号）“最新”的那一个。** 换句话说，谁最后写，谁的数据就有效。

### LWW 的工作原理

要实现 LWW，系统需要为每个数据项的每次写入操作附加一个**时间戳**或**版本号**。当发生冲突时，系统会比较这些时间戳或版本号：

1. **写入请求到达：** 客户端向分布式系统发送一个写入请求，尝试修改某个数据。
    
2. **附加时间戳/版本号：** 系统通常会在接受写入时，给这个操作打上一个时间戳（例如，写入操作发生的系统时间）或者递增一个版本号。
    
3. **冲突检测：** 如果有多个对同一数据项的写入操作同时进行，或者在网络延迟导致消息乱序的情况下，它们可能会在不同的节点上被处理，导致冲突。
    
4. **解决冲突：** 当系统发现存在多个对同一数据项的写入时，它会比较这些写入操作所带的时间戳或版本号。拥有**最大（最新）时间戳或版本号**的写入操作将被视为“获胜者”，其数据将被保存下来，而其他较旧的写入操作则会被丢弃。
    

### 优点

- **简单易实现：** LWW 策略的逻辑非常直观和简单，容易在分布式系统中实现。
    
- **性能较好：** 由于冲突解决的逻辑不复杂，LWW 不会引入大量的协调开销，因此在写入密集型应用中性能表现通常较好。
    
- **高可用性：** 系统不需要等待所有副本都达成一致，只要能决定哪个是“最新”写入，就可以继续服务。
    

### 缺点和挑战

尽管 LWW 简单有效，但它存在一些显著的缺点，需要在使用时格外注意：

1. **依赖时钟同步：** 如果 LWW 依赖于**物理时间戳**（如系统时间），那么它就极度依赖于分布式系统中所有节点**时钟的同步程度**。如果节点间的时钟存在漂移或不同步，一个物理上先发生的写入，可能因为其所在节点的时钟快而被打上一个“更晚”的时间戳，从而错误地覆盖掉物理上后发生的写入。这被称为“时钟跳跃”**问题，可能导致数据不一致甚至数据丢失。
    
2. **不保证因果顺序：** LWW 无法保证操作的**因果顺序**。如果操作 A 导致了操作 B（即 A 是 B 的前置条件），但由于网络延迟或时钟同步问题，B 的写入被 LWW 算法判断为更早，那么 B 的结果可能会被 A 的结果覆盖，导致逻辑错误。
    
3. **潜在的数据丢失：** 并非所有有效的写入都一定会被保留。如果两个同时发生的写入操作都修改了数据的不同部分，但在 LWW 策略下，只有一个会“赢”，另一个则会被完全丢弃，即使它们修改的是数据中不冲突的字段。这被称为**“丢失更新”**或**“丢失修改”**问题。
    
4. **不适用于所有场景：** 对于那些对数据一致性要求极高，或者需要保留所有修改历史的场景，LWW 并不是一个合适的选择。例如，在银行交易、库存管理等场景中，任何数据丢失都是不可接受的。
    

### 适用场景

LWW 策略通常适用于以下场景：

- **对最终一致性要求高，对强一致性要求不高。**
    
- **数据更新频率高，但对历史版本或所有更新的精确保留不那么敏感。**
    
- **需要简单快速的冲突解决机制。**
    
- **系统能够容忍少量的数据丢失或不一致性。**
    
- **能够确保较好的时钟同步。**
    

**示例：**

- **用户个人资料更新：** 多个设备同时修改用户的昵称或头像，通常最后一次修改会生效。
    
- **计数器：** 如果只是简单地增加或减少一个计数器的值，并且可以容忍偶尔的计数不准（例如，在一个非常庞大的 PV 统计系统中）。
    
- **会话状态：** 用户的会话信息更新，最后一次写入的状态通常是最新的。
    

### 替代方案

为了解决 LWW 的缺点，分布式系统还采用了其他更复杂的冲突解决机制：

- **版本向量（Vector Clocks）：** 能够捕获事件的因果关系，从而更准确地识别和解决冲突，但实现更复杂。
    
- **CRDTs (Conflict-Free Replicated Data Types)：** 允许在并发修改后自动合并数据，保证最终一致性且不丢失更新，适用于协作编辑等场景。
    
- **显式合并：** 要求应用程序层介入，对冲突的数据进行自定义的合并逻辑。
    
- **读-修改-写原子操作：** 通过锁或分布式事务来确保对同一数据项的修改是串行化的。
    

---

总之，LWW 是一种简单高效的冲突解决策略，适用于许多场景，但在使用时务必清楚其对时钟同步的依赖以及可能导致数据丢失的风险。