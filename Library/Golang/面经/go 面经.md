17.如何提高MySQL的查询速度？

18.索引具体是如何提高查询速度的？

19.构建索引有什么注意事项？

20.MySQL中的事务是怎样的？

1


## 🔐 一、互斥锁 `sync.Mutex`

### ✅ 特点：

- 只能有**一个协程**访问临界区
    
- 没有读/写之分
    
- 上锁（`Lock()`）和解锁（`Unlock()`）都要配对
    

### 📌 使用场景：

- 写操作较多，或者读写都很频繁且不区分开
    
- 资源不能被同时读写（任何时刻都只能有一个协程访问）
    


## 📚 二、读写锁 `sync.RWMutex`

### ✅ 特点：

- 区分 **读锁（RLock）** 和 **写锁（Lock）**
    
- 多个协程可以**同时持有读锁**（只要没有写锁）
    
- 读写互斥、写写互斥
    

### 📌 使用场景：

- **读多写少** 的情况非常适合
    
- 比如缓存读取、配置读取、状态查询等
    



## 🆚 三、Mutex vs RWMutex

|比较维度|Mutex|RWMutex|
|---|---|---|
|并发读|❌ 不支持|✅ 支持多个并发读|
|并发写|❌ 不支持|❌ 不支持|
|读写同时|❌ 不支持|❌ 不支持（写优先）|
|适用场景|读写都频繁 / 简单控制同步|读多写少，读不需要阻塞其他读|
|性能|写多时性能更好|读多写少时更高效|

---

## ⚠️ 注意点：

- `RWMutex` 写锁会**阻塞所有读锁**，所以如果写很多，反而效率更低。
    
- 所有锁都必须 `Unlock()`，否则会造成死锁。
    
- 避免把锁暴露给外部使用。
    


# 能说说uintptr和unsafe.Pointer的区别吗？
- unsafe.Pointer只是单纯的通用指针类型，用于转换不同类型指针，它不可以参与指针运算；
    
- 而uintptr是用于指针运算的，GC 不把 uintptr 当指针，也就是说 uintptr 无法持有对象， uintptr 类型的目标会被回收；
    
- unsafe.Pointer 可以和 普通指针 进行相互转换；
    
- unsafe.Pointer 可以和 uintptr 进行相互转换。

![[Pasted image 20250426145941.png]]
- `uintptr(unsafe.Pointer(w))` 获取了 `w` 的指针`起始值`
    
- `unsafe.Offsetof(w.b)` 获取 `b` 变量的`偏移量`
    
- 两个`相加`就得到了 `b` 的`地址值`，将通用指针 `Pointer` 转换成具体指针 `((*int)(b))`，通过 `*` 符号取值，然后赋值。`*((*int)(b))` 相当于把 `(*int)(b)` 转换成 `int` 了，最后对变量重新赋值成 `10`，这样指针运算就完成了。




# HTTP  与 HTTPS 区别
**HTTPS**（Hypertext Transfer Protocol Secure：超文本传输安全协议）是一种透过计算机网络进行安全通信的传输协议。HTTPS 经由 HTTP 进行通信，但利用 SSL/TLS 来加密数据包。HTTPS 开发的主要目的，是提供对网站服务器的身份认证，保护交换数据的隐私与完整性。

HTTPS 默认工作在 TCP 协议443端口，它的工作流程一般如以下方式：

- 1、TCP 三次同步握手
- 2、客户端验证服务器数字证书
- 3、DH 算法协商对称加密算法的密钥、hash 算法的密钥
- 4、SSL 安全加密隧道协商完成
- 5、网页以加密的方式传输，用协商的对称加密算法和密钥加密，保证数据机密性；用协商的hash算法进行数据完整性保护，保证数据不被篡改。

- HTTP 明文传输，数据都是未加密的，安全性较差，HTTPS（SSL+HTTP） 数据传输过程是加密的，安全性较好。
- 使用 HTTPS 协议需要到 CA（Certificate Authority，数字证书认证机构） 申请证书，一般免费证书较少，因而需要一定费用。证书颁发机构如：Symantec、Comodo、GoDaddy 和 GlobalSign 等。
- HTTP 页面响应速度比 HTTPS 快，主要是因为 HTTP 使用 TCP 三次握手建立连接，客户端和服务器需要交换 3 个包，而 HTTPS除了 TCP 的三个包，还要加上 ssl 握手需要的 9 个包，所以一共是 12 个包。
- http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是 80，后者是 443。
- HTTPS 其实就是建构在 SSL/TLS 之上的 HTTP 协议，所以，要比较 HTTPS 比 HTTP 要更耗费服务器资源。
## HTTPS 的工作原理
![[Pasted image 20250414140133.png]]
**1、客户端发起 HTTPS 请求**
这个没什么好说的，就是用户在浏览器里输入一个 https 网址，然后连接到 server 的 443 端口。

**2、服务端的配置**
采用 HTTPS 协议的服务器必须要有一套数字证书，可以自己制作，也可以向组织申请，区别就是自己颁发的证书需要客户端验证通过，才可以继续访问，而使用受信任的公司申请的证书则不会弹出提示页面(startssl 就是个不错的选择，有 1 年的免费服务)。

这套证书其实就是一对公钥和私钥，如果对公钥和私钥不太理解，可以想象成一把钥匙和一个锁头，只是全世界只有你一个人有这把钥匙，你可以把锁头给别人，别人可以用这个锁把重要的东西锁起来，然后发给你，因为只有你一个人有这把钥匙，所以只有你才能看到被这把锁锁起来的东西。

**3、传送证书**
这个证书其实就是公钥，只是包含了很多信息，如证书的颁发机构，过期时间等等。

**4、客户端解析证书**
这部分工作是有客户端的TLS来完成的，首先会验证公钥是否有效，比如颁发机构，过期时间等等，如果发现异常，则会弹出一个警告框，提示证书存在问题。

如果证书没有问题，那么就生成一个随机值，然后用证书对该随机值进行加密，就好像上面说的，把随机值用锁头锁起来，这样除非有钥匙，不然看不到被锁住的内容。

**5、传送加密信息**
这部分传送的是用证书加密后的随机值，目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密了。

**6、服务端解密信息**

服务端用私钥解密后，得到了客户端传过来的随机值(对称秘钥)，然后把内容通过该值进行对称加密，所谓对称加密就是，将信息和私钥通过某种算法混合在一起，这样除非知道私钥，不然无法获取内容，而正好客户端和服务端都知道这个私钥，所以只要加密算法够彪悍，私钥够复杂，数据就够安全。

**7、传输加密后的信息**
这部分信息是服务段用私钥加密后的信息，可以在客户端被还原。

**8、客户端解密信息**
客户端用之前生成的私钥解密服务段传过来的信息，于是获取了解密后的内容，整个过程第三方即使监听到了数据，也束手无策。


# **golang 中 make 和 new 的区别？（基本必问）**

共同点：给变量分配内存  
**不同点：**  
1）作用变量类型不同，new给string,int和数组分配内存，make给切片，map，channel分配内存；  
2）返回类型不一样，new返回指向变量的指针，make返回变量本身；  
3）new 分配的空间被清零。make 分配空间后，会进行初始化；  
1) 字节的面试官还说了另外一个区别，就是分配的位置，在堆上还是在栈上？这块我比较模糊，大家可以自己探究下，我搜索出来的答案是golang会弱化分配的位置的概念，因为编译的时候会自动内存逃逸处理，懂的大佬帮忙补充下：make、new内存分配是在堆上还是在栈上？

在 Go 中，`make` 和 `new` 都是用来分配内存的，但它们的用途和行为有显著不同。下面是它们的主要区别：

### 1. **`new`**：用于分配内存并初始化为零值

`new` 是一个内存分配函数，它分配一个类型的零值内存并返回指向该类型的指针。`new` 只负责分配内存，不会初始化值，只会将内存设置为类型的零值。

#### 使用场景：

- `new` 适用于需要分配内存但并不需要初始化数据的情况。

#### 例子：

```go
var ptr *int
ptr = new(int)  // 分配一个 int 类型的零值内存，即 0
fmt.Println(*ptr) // 输出 0
```

- 这里 `ptr` 是一个 `*int` 指针，指向一个 `int` 类型的零值内存（即 `0`）。

### 2. **`make`**：用于初始化内建数据类型（`slice`, `map`, `chan`）

`make` 用于为切片（`slice`）、映射（`map`）和通道（`chan`）分配和初始化内存。与 `new` 不同，`make` 返回的是已初始化的对象，而不是指向它们的指针。

#### 使用场景：

- `make` 用于初始化 Go 的三种内建数据类型（`slice`、`map` 和 `chan`）的实例。它不仅分配内存，还进行初始化，以确保它们可以正常使用。

#### 例子：

```go
// 使用 make 创建一个切片
slice := make([]int, 5)  // 创建一个长度为 5 的 int 类型切片
fmt.Println(slice)        // 输出: [0 0 0 0 0]

// 使用 make 创建一个 map
m := make(map[string]int)
m["age"] = 30
fmt.Println(m)  // 输出: map[age:30]

// 使用 make 创建一个 channel
ch := make(chan int)
go func() {
    ch <- 42
}()
fmt.Println(<-ch)  // 输出: 42
```

- 在这些例子中，`make` 创建并初始化了 `slice`、`map` 和 `chan`，使它们能够被直接使用。

### 总结：

- **`new`**：分配类型的零值内存，返回指向该类型的指针。
    - 适用于一般类型（如 `int`、`struct` 等）的内存分配。
    - 返回类型是指针。
- **`make`**：用于初始化内建类型（`slice`、`map`、`chan`）并返回这些类型的实例。
    - 适用于 `slice`、`map`、`chan` 的内存分配和初始化。
    - 返回的是初始化好的对象，而不是指针。

### 关键区别：

- `new` 返回的是指针（即 `*T` 类型），而 `make` 返回的是初始化好的对象本身（即 `[]T`、`map[T]T`、`chan T` 类型）。
- `new` 可以用于任何类型，而 `make` 仅限于内建的三种类型：切片、映射和通道。

所以，简而言之，`new` 用于普通类型的内存分配，`make` 用于内建类型的初始化和分配。

在 Go 中，`new` 和 `make` 分配内存的**位置**也是不同的。这与它们的内存管理机制和用途密切相关。

### 1. **`new` 分配内存的位置：**

`new` 分配的内存通常是分配在 **堆** 上。具体来说，`new` 会返回一个指向内存块的指针，这个内存块是从堆上分配的。Go 使用垃圾回收（GC）来管理这些堆内存的生命周期。

- **堆分配**：`new` 会分配一个类型的零值内存，并返回指向该内存的指针，这块内存会存储在堆上。
- **堆的原因**：当你使用 `new` 分配内存时，Go 认为你可能会在不同的函数或 goroutine 中使用这个内存，因此它将其放在堆上，便于跨函数或 goroutine 的共享。

#### 例子：

```go
var ptr *int
ptr = new(int)  // 使用 new 分配内存，返回指向 int 的指针
fmt.Println(ptr) // ptr 的地址
```

- 在这个例子中，`new(int)` 返回的是指向堆上分配的内存的指针。

### 2. **`make` 分配内存的位置：**

`make` 用于创建和初始化切片（`slice`）、映射（`map`）和通道（`chan`）。这些数据结构本身是引用类型，所以当你使用 `make` 时，它会在堆或栈上分配内存，具体取决于变量的作用域和 Go 的逃逸分析（escape analysis）机制。

- **切片（slice）**：切片本身是一个引用类型，它指向底层数组。底层数组的内存通常分配在 **堆** 上，特别是当切片的大小或生命周期不能确定时，Go 会把底层数组放在堆上。否则，它可能会分配在栈上。
    
- **映射（map）和通道（chan）**：它们是引用类型，`make` 会在堆上分配内存，因为这些数据结构通常具有动态大小，需要在堆上分配内存，以便 Go 的垃圾回收系统能够管理它们。
    

#### 例子：

```go
// 创建切片
slice := make([]int, 5)  // 底层数组分配在堆或栈上，取决于逃逸分析

// 创建映射
m := make(map[string]int)  // 分配内存在堆上

// 创建通道
ch := make(chan int)  // 通道的内存也分配在堆上
```

### 3. **堆与栈的区别**

- **栈（Stack）**：栈上的内存是局部的，生命周期仅限于函数调用的作用域。当函数返回时，栈上的内存会被自动释放。栈的内存分配速度较快，但它不能用于存储动态大小的数据。
    
- **堆（Heap）**：堆上的内存可以在多个函数或 goroutine 之间共享，且它的生命周期由垃圾回收器控制。堆内存分配较慢，但能够存储大小动态的数据。
    

### 4. **逃逸分析（Escape Analysis）**

Go 的编译器会执行逃逸分析来确定哪些变量需要分配到堆上。具体来说，逃逸分析决定一个变量是否**逃逸**到函数外（即是否需要长期存在）。如果一个变量的生命周期不在当前函数范围内，或者需要跨多个 goroutine 使用，那么它的内存就会分配到堆上。否则，它会分配到栈上。

例如，如果你把一个切片传递给其他函数或 goroutine，Go 会通过逃逸分析将它分配到堆上。

```go
func createSlice() []int {
    slice := make([]int, 10)
    return slice  // slice 会逃逸到堆上
}
```

在上面的例子中，`slice` 变量会逃逸到堆上，因为它在函数返回后仍然有效。

### 5. **总结**

- **`new`**：分配内存通常发生在 **堆** 上，并返回一个指向该内存的指针。它仅仅分配内存并将内存初始化为零值，适用于任何类型。
    
- **`make`**：主要用于初始化切片（`slice`）、映射（`map`）和通道（`chan`）等引用类型，它会在堆或栈上分配内存，具体取决于 Go 的逃逸分析。在大多数情况下，它会在堆上分配内存，特别是当数据结构的大小无法确定时。
    

# for range 的时候它的地址会发生变化么？
答：在 for a,b := range c 遍历中， a 和 b 在内存中只会存在一份，即之后每次循环时遍历到的数据都是以值覆盖的方式赋给 a 和 b，a，b 的内存地址始终不变。由于有这个特性，for 循环里面如果开协程，不要直接把 a 或者 b 的地址传给协程。解决办法：在每次循环时，创建一个临时变量。


# 解析 tag 是怎么实现的？反射原理是什么？


# select 底层数据结构和一些特性？
go 的 select 为 golang 提供了多路 IO 复用机制，和其他 IO 复用一样，用于检测是否有读写事件是否 ready。linux 的系统 IO 模型有 select，poll，epoll，go 的 select 和 linux 系统 select 非常相似。  

select 结构组成主要是由 case 语句和执行的函数组成 select 实现的多路复用是：每个线程或者进程都先到注册和接受的 channel（装置）注册，然后阻塞，然后只有一个线程在运输，当注册的线程和进程准备好数据后，装置会根据注册的信息得到相应的数据。  
**select 的特性**  
1）select 操作至少要有一个 case 语句，出现读写 nil 的 channel 该分支会忽略，在 nil 的 channel 上操作则会报错。  
2）select 仅支持管道，而且是单协程操作。  
3）每个 case 语句仅能处理一个管道，要么读要么写。  
4）多个 case 语句的执行顺序是随机的。  
5）存在 default 语句，select 将不会阻塞，但是存在 default 会影响性能。


# defer 底层数据结构和一些特性?
每个 defer 语句都对应一个_defer 实例，多个实例使用指针连接起来形成一个单连表，保存在 gotoutine 数据结构中，每次插入_defer 实例，均插入到链表的头部，函数结束再一次从头部取出，从而形成后进先出的效果。  
**defer 的规则总结**：  
延迟函数的参数是 defer 语句出现的时候就已经确定了的。  
延迟函数执行按照后进先出的顺序执行，即先出现的 defer 最后执行。  
延迟函数可能操作主函数的返回值。  
申请资源后立即使用 defer 关闭资源是个好习惯。


# 单引号，双引号，反引号的区别？
单引号，表示byte类型或rune类型，对应 uint8和int32类型，默认是 rune 类型。byte用来强调数据是raw data，而不是数字；而rune用来表示Unicode的code point。  
双引号，才是字符串，实际上是字符数组。可以用索引号访问某字节，也可以用len()函数来获取字符串所占的字节长度。  
反引号，表示字符串字面量，但不支持任何转义序列。字面量 raw literal string 的意思是，你定义时写的啥样，它就啥样，你有换行，它就换行。你写转义字符，它也就展示转义字符。


# 如何实现 set 
Go中是不提供Set类型的，Set是一个集合，其本质就是一个List，只是List里的元素不能重复。  
Go提供了map类型，但是我们知道，map类型的key是不能重复的，因此，我们可以利用这一点，来实现一个set。那value呢？value我们可以用一个常量来代替，比如一个空结构体，实际上空结构体不占任何内存，使用空结构体，能够帮我们节省内存空间，提高性能


# 从数组中取一个相同大小的 slice 有成本吗？
在Go语言中，从数组中取一个相同大小的slice（切片）实际上是一个非常低成本的操作。这是因为slice在Go中是一个引用类型，它内部包含了指向数组的指针、切片的长度以及切片的容量。当你从一个数组创建一个相同大小的slice时，你实际上只是创建了一个新的slice结构体，它包含了**指向原数组的指针**、**原数组的长度作为切片的长度**，以及**原数组的长度作为切片的容量**。

这个操作的成本主要在于内存的分配（为新的slice结构体分配内存），但这个成本是非常小的，因为它只是分配了一个很小的结构体，而不是复制数组的内容。数组的内容仍然是共享的，即新的slice和原数组指向相同的内存区域。

因此，从数组中取一个相同大小的slice是一个低成本的操作，它允许你高效地操作数组的部分或全部元素，而不需要复制这些元素。



# map 相关
## 什么类型可以作为 map 的 key
在Go语言中，map的key可以是任何可以**比较**的类型。这包括所有的基本类型，如**整数、浮点数、字符串和布尔值，以及结构体和数组**，只要它们没有被定义为包含不可比较的类型（如切片、映射或函数）。

注意，切片、映射和函数类型是不可比较的，因此不能作为map的key。如果你需要一个包含这些类型的key，你可以考虑使用一个指向这些类型的指针，或者将它们封装在一个可比较的结构体中，并确保结构体不包含任何不可比较的类型。

## map 循环是有序的还是无序的？
在Go语言中，map的循环（遍历）是无序的。这意味着当你遍历map时，每次遍历的顺序可能都不同。Go语言的map是基于哈希表的，因此元素的存储顺序是不确定的，并且可能会随着元素的添加、删除等操作而改变。

如果你需要按照特定的顺序处理map中的元素，你应该先将key提取到一个切片中，对切片进行排序，然后按照排序后的顺序遍历切片，并从map中取出对应的值。这样，你就可以按照特定的顺序处理map中的元素了。

## map 中删除一个 key，它的内存会释放么？
在Go语言中，从map中删除一个key时，其内存释放的行为并非直观且立即的，这涉及到Go语言的内存管理机制。具体来说，删除map中的key后，其内存释放情况如下：


## 对 map 进行并发访问
使用并发安全的 map （sync.Map)

# mysql,redis,mongoDB,ES 说说如何根据使用场景,选择对应的存储组件?
MySQL、Redis、MongoDB 和 Elasticsearch（ES）各自有其独特的优势和适用场景，根据不同的需求和业务场景可以选择合适的存储组件。下面是对它们的简要分析以及相应的使用场景建议：

1. **MySQL**：
    
    - MySQL 是一种关系型数据库管理系统（RDBMS），支持ACID特性（原子性、一致性、隔离性和持久性），适合需要强一致性和复杂事务处理的场景。
    - 使用场景：
        - 结构化数据且数据模式相对固定的应用，如电商订单系统、财务系统等，其中数据之间的关系紧密，需要执行复杂的JOIN查询。
        - 对数据准确性要求极高，不允许丢失事务性的场景。
2. **Redis**：
    
    - Redis 是一个基于内存、支持持久化的键值存储系统，同时也支持多种数据结构（如字符串、哈希、列表、集合、有序集合等）。
    - 使用场景：
        - 需要高性能读写操作的场合，如缓存、会话存储、实时排行榜、计数器、消息队列等。
        - 实时计算和数据分析，作为数据中转站或快速存储。
        - 适合处理大量小规模的数据并行操作。
3. **MongoDB**：
    
    - MongoDB 是一种NoSQL数据库，属于文档型数据库，存储结构灵活，支持JSON-like文档格式，适合于处理非结构化和半结构化数据。
    - 使用场景：
        - 数据模型经常变化或需要灵活性高的应用，比如社交网络、内容管理系统、物联网设备数据存储等。
        - 需要全文检索能力较弱但数据结构复杂多变的场景。
        - 高并发写入和大数据量存储，尤其在集群环境下能够水平扩展以应对大规模数据。
4. **Elasticsearch**：
    
    - Elasticsearch 是一个分布式的搜索引擎和分析引擎，基于Lucene构建，主要用于实时全文搜索和分析大量数据。
    - 使用场景：
        - 实时搜索和分析，如电商商品搜索、日志分析平台、监控系统等。
        - 对大量数据进行近实时分析，提供聚合查询与可视化报表。
        - 需要复杂查询能力和高效索引机制的场景。

总结来说，当选择存储组件时，应该考虑以下几个关键因素：

- 数据结构和查询需求：关系紧密、结构固定的选用MySQL；结构灵活、文档化的选用MongoDB；注重全文搜索和分析的选用Elasticsearch。
- 性能需求：高速读写的短期数据存储可选Redis；长期存储和复杂查询需求则考虑MySQL和MongoDB。
- 扩展性需求：大规模数据和高并发环境，MongoDB和Elasticsearch支持分布式部署，具有更好的水平扩展性。
- 功能需求：对于需要高级数据结构、事务处理、复杂分析、实时搜索等功能，不同数据库有不同的侧重点。


# 乐观锁和悲观锁的区别? 写多读少的情况, 应该使用乐观锁还是悲观锁?
乐观锁和悲观锁是两种并发控制机制，它们在处理并发场景时采取不同的策略来防止数据竞争和保持数据一致性。

**悲观锁(Pessimistic Lock)：**

- 悲观锁假定会发生并发冲突，所以在访问数据时，会立即获取并锁定资源（例如数据库记录），直到事务结束才释放锁。在此期间，其他事务试图访问相同的资源时会被阻塞，必须等到锁被释放才能进行操作。

**乐观锁(Optimistic Lock)：**

- 乐观锁假设并发冲突不太可能发生，因此在读取数据时不加锁，但在更新数据时，会先验证数据自上次读取以来是否被其他事务修改过。常见的乐观锁实现方式是使用版本号或时间戳，更新数据时检查版本号是否变化，如果变化则说明数据已被修改，此时更新失败，需要重新读取并尝试更新。

**写多读少的情况应该使用哪种锁：**

- 在写多读少的情况下，如果并发写入非常频繁且冲突可能性较大，使用悲观锁可能是更好的选择，因为它在一开始就阻止了并发写入，减少了因并发带来的冲突和重试次数。
- 如果虽然写入较多，但实际冲突概率不大，或者系统对并发性能要求较高，可以考虑使用乐观锁。乐观锁在大多数情况下不阻塞其他事务，只有在更新时才会检查并发冲突，从而提升并发性能。然而，如果并发冲突确实很多，乐观锁会导致大量更新失败和重试，反而可能降低性能。
选择何种锁机制需要依据具体的并发程度、冲突概率、性能要求等因素综合决定。在写多读少且并发冲突严重的场景下，悲观锁可能更具优势，因为它在源头上避免了冲突的发生。然而在实践中，应当通过压测和性能分析来决定最适合的并发控制策略。

# 3分布式锁? 分布式死锁如何解决? 看门狗机制? 如何避免当前线程加的锁, 被其它线程解锁?
**分布式锁**：  
分布式锁是一种在分布式环境下协调多个节点共享资源访问的机制。它的目的是在分布式系统中实现对共享资源的互斥访问，确保在任何时候只有一个节点能够获得锁并对资源进行操作。常见的分布式锁实现方案有基于数据库（如MySQL的排他锁、Redis的SETNX命令）、基于Zookeeper、基于etcd等。

**分布式死锁的解决**：  
分布式死锁类似于单机环境中的死锁，但由于涉及到多个节点和网络通信，问题变得更加复杂。解决分布式死锁的方法主要有：

1. **避免死锁**：
    
    - **资源排序和一致的锁获取顺序**：所有线程在获取多个锁时，按照固定的顺序获取资源，这样可以避免循环等待，从而消除死锁的可能性。
    - **超时设置**：为获取锁的操作设置一个合理的超时时间，超时后主动释放已经持有的锁，再尝试重新获取。
2. **死锁检测和解除**：
    
    - **周期性检测**：系统定期检测是否存在死锁，并尝试解开死锁，例如通过打破循环等待链或者强制回滚部分事务来释放锁。
    - **智能锁**：一些分布式锁服务提供者可能会内置死锁检测和解决机制，例如通过跟踪锁的持有者和依赖关系。

**看门狗(Watchdog)机制**：  
在分布式系统中，看门狗机制通常用于检测和恢复系统的异常状态。对于分布式锁而言，它可以用于监控持有锁的线程或进程是否正常工作。例如，如果持有锁的线程在一段时间内没有响应或未能释放锁，看门狗会认为该线程可能已经失效，这时会强制释放锁以避免死锁。

**如何避免当前线程加的锁被其他线程解锁**：  
在单机环境下，可以通过Java的`synchronized`关键字或ReentrantLock等可重入锁机制，确保只有锁的持有者才能解锁。而在分布式环境下，为了避免非锁持有者解锁，需要锁服务提供正确的锁释放逻辑和锁的所有权跟踪机制，例如：

- **唯一标识符**：每个请求锁的线程或进程都有一个唯一的标识符，只有拥有正确标识符的请求者才能解锁。
- **锁绑定**：将锁与特定的会话或事务关联，只有关联的会话或事务有权释放锁。
- **租约机制**：锁的有效期是有限的（租约），过了租约时间后，除非持有者续租，否则锁将自动失效，从而避免其他线程误操作。

# GMP 调度模型
**面试官：** 请你详细介绍一下 Go 语言的 GMP 调度模型，并谈谈它有哪些亮点？

**应聘者：** 好的，Go 的调度模型基于 GMP，其中：

- **G** 代表 goroutine，是 Go 中轻量级的执行单元，拥有很小的栈内存，可以动态增长；
    
- **M** 代表 OS 线程，实际执行代码的载体；
    
- **P** 代表逻辑处理器，它是调度器的核心，用来绑定 M 和 G，同时维护本地运行队列。
    

**面试官：** 请你具体说明一下各个组件之间是如何协同工作的？

**应聘者：** 调度器的工作流程大致如下：

1. **G 的调度**  
    每个 P 内部都有一个本地的运行队列，G 会被插入到这个队列中。当一个 M（OS 线程）获得了一个 P 后，就会从该 P 的队列中取出 G 并执行。
    
2. **P 与 M 的绑定**  
    一个 P 只能由一个 M 持有并执行队列中的 G，这样保证了同一时刻的调度安全。当一个 G 阻塞（例如执行了系统调用或等待 IO）时，M 会被释放，P 可以被其他 M 绑定，以保证其他 G 能继续执行。
    
3. **工作窃取机制**  
    当一个 P 的队列为空时，它可以尝试从其他 P 的队列中窃取任务，从而达到负载均衡。这种工作窃取机制大大提升了多核并发下的调度效率。
    
4. **抢占式调度**  
    在 Go 1.14 之前，goroutine 的调度主要依赖协作式，让出执行权；但在 1.14 之后，引入了异步抢占机制。当一个 goroutine 长时间运行时，运行时系统会发出抢占信号，使其在安全点中断，从而避免某个 goroutine 独占 CPU 时间。这对防止长时间运行的 goroutine 造成调度延迟非常关键。
    
5. **轻量级与高效性**
    
    - **轻量级：** goroutine 的栈空间从几 KB 开始，可以根据需要扩展，远比操作系统线程轻量。
        
    - **高效性：** 调度器采用无锁设计和分布式队列，加上工作窃取机制，能有效利用多核资源，降低上下文切换的开销。
        

**面试官：** 很好。那你能再谈谈在实际面试中，有哪些细节是很多候选人容易忽略，但能体现你对 Go 调度器深入理解的？

**应聘者：** 当然。除了上面讲的基本原理，还有以下几个亮点：

- **局部运行队列与全局队列：**  
    每个 P 有自己的本地队列，用于快速分发任务。但当本地队列耗尽时，调度器会从全局队列中获取 G。这种设计在兼顾低延迟和公平性方面做了很好的平衡。
    
- **M 与阻塞调用的脱钩：**  
    当 goroutine 发生阻塞（如等待 IO 或系统调用）时，当前 M 不会闲置，而是可以被调度器回收去执行其他 G，从而提高了整体的 CPU 利用率。
    
- **抢占点的设计与实现：**  
    Go 的抢占机制依赖于编译器和运行时的协同，在编译阶段就嵌入了抢占检查点，这种设计既保证了性能，又能在必要时中断长时间运行的 goroutine。
    
- **避免全局锁竞争：**  
    通过分散到各个 P 的局部队列和工作窃取机制，Go 调度器很大程度上避免了全局锁竞争的问题，这对于高并发场景下的性能至关重要。
    
- **调度器的调优与演进：**  
    Go 语言在不断演进中对调度器也做了大量的优化，例如在 Go 1.6 引入了 P 的概念，Go 1.14 改进了抢占式调度，这些改进都反映出调度器设计者对并发调度效率和实时响应性的深刻理解。
    

**面试官：** 你的回答非常全面。能看出你对 Go 调度器底层实现有深入的理解。还有没有什么你觉得特别有趣或者容易被忽视的点？

**应聘者：** 还有一点值得一提：

- **垃圾回收与调度器的协同：**  
    Go 的垃圾回收器（GC）与调度器之间有很紧密的协同。GC 运行时会暂停 goroutine 的执行，但这种暂停是尽可能短暂和分布式的，不会造成整个系统的卡顿。这种设计进一步保证了高并发场景下的系统响应能力。

# Context 包
Go 语言中的 context 包主要用于在多个 goroutine 之间传递取消信号、截止日期以及请求级别的数据。它解决了在复杂并发场景下如何协调 goroutine 退出、超时控制以及跨 API 边界传递元数据的问题。常见用途包括：

- **取消操作：** 当外部请求取消时，可以传递取消信号给相关 goroutine。
    WithCancel
- **超时控制：** 通过设置截止日期或超时，自动取消超时的操作。
    WithTimeout和 WithDeadline
- **传递请求信息：** 如用户认证信息、请求 ID 等，可以通过 context 在整个调用链中传递。
WithValue


# select 和 epoll
下面给出一个模拟面试场景，帮助你理解并解释 select 和 epoll 的差异及其各自的优缺点：

---

**面试官：** 请谈谈 Linux 下的 I/O 多路复用机制，特别是 select 和 epoll，它们各自有什么特点？

**应聘者：**  
好的。select 和 epoll 都是 Linux 下常见的 I/O 多路复用机制，主要用于同时监控多个文件描述符的 I/O 状态，但它们在设计和性能上有明显区别：

- **select：**
    
    - **基本原理：** select 通过传入一个文件描述符集合，轮询所有文件描述符的状态，来检查是否有就绪事件。
        
    - **限制：** 每次调用需要将文件描述符集合从用户态复制到内核态，而且文件描述符数量有固定上限（通常为 1024），这限制了它在大规模并发场景下的应用。
        
    - **性能问题：** 当监控的文件描述符数量较多时，每次轮询都需要遍历整个集合，导致 CPU 开销较大。
        
- **epoll：**
    
    - **基本原理：** epoll 采用事件驱动的方式，通过内核维护的红黑树和就绪链表来管理事件，只有就绪的事件才会被返回。
        
    - **优势：**
        
        - 能够支持大量的文件描述符，因为不受固定上限限制；
            
        - 不需要每次轮询时复制所有文件描述符，大大减少了内核与用户态间的数据传输；
            
        - 性能更好，特别是在高并发场景下，时间复杂度更低。
            
    - **触发模式：** epoll 同时支持水平触发（Level-Triggered）和边缘触发（Edge-Triggered）两种模式，边缘触发模式可以减少事件通知的次数，但要求程序更细致地处理状态变化。
        

**面试官：** 很好。那么你认为在实际应用中，为什么很多高并发场景下会优先选择 epoll 而不是 select？

**应聘者：**  
主要原因有以下几点：

1. **扩展性：** epoll 没有固定的文件描述符上限，适用于大量并发连接的场景；
    
2. **效率：** epoll 通过事件通知的方式，只关注就绪的文件描述符，避免了遍历所有 fd 的开销；
    
3. **灵活性：** 支持边缘触发模式，能够进一步降低系统调用次数，提高响应效率；
    
4. **内存和 CPU 开销更低：** 在连接数量很大时，select 每次都要复制整个 fd 集合，而 epoll 的工作方式使得内存和 CPU 的消耗都大幅降低。
    

**面试官：** 非常好。你能简单说明一下 epoll 的边缘触发和水平触发有什么区别吗？

**应聘者：**  
当然。

- **水平触发（Level-Triggered）：** 这是默认模式，当文件描述符处于就绪状态时，每次调用 epoll_wait() 都会返回这个事件，类似于 select 的轮询机制。
    
- **边缘触发（Edge-Triggered）：** 只在状态变化时触发一次事件通知，如果没有读取完数据，则不会再次通知，因此需要一次性读完所有数据，否则可能会遗漏事件。边缘触发模式在处理大量数据时效率更高，但实现起来要求更高，需要程序员仔细处理 I/O 操作，确保不会遗漏事件。
    
![[Pasted image 20250227131846.png]]
![[Pasted image 20250227133304.png]]

# kafka 和 rabbitmq 中间件的工作原理


# HTTP 和 HTTPS 的区别

# B 树 和 B+ 树的区别，为什么 mysql 要用 B+ 树，mongodb 要用 B 树
下面给出一个模拟面试场景，帮助你阐述 B 树和 B+ 树的区别，以及为什么 MySQL 使用 B+ 树，而 MongoDB 使用 B 树。

---

**面试官：** 请你说明一下 B 树和 B+ 树的主要区别，并解释为什么 MySQL 采用 B+ 树，而 MongoDB 选择 B 树？

**应聘者：**  
好的，我们先来看两种数据结构的主要区别：

### B 树与 B+ 树的主要区别

- **数据存储位置：**
    
    - **B 树：**  
        数据记录可以存储在所有节点中，包括内部节点和叶子节点。内部节点除了作为索引外，也直接存储部分数据。
        
    - **B+ 树：**  
        所有的实际数据都存储在叶子节点上，内部节点仅存储用于索引的键。这使得内部节点更“轻”，能够容纳更多的索引项，从而降低树的高度。
        
- **叶子节点链表：**
    
    - **B 树：**  
        叶子节点之间通常没有显式的链表结构，范围查询需要在各个节点之间跳转。
        
    - **B+ 树：**  
        叶子节点通常通过指针相互连接，形成链表，便于范围查询和顺序扫描。
        
- **查询效率：**
    
    - **B 树：**  
        对于点查询可能更快，因为在内部节点就能直接获取数据，不必总是访问叶子节点。
        
    - **B+ 树：**  
        虽然点查询需要到叶子节点，但由于树的高度通常较低，同时内部节点存储更多索引项，可以减少磁盘 I/O，特别适合大量数据的存储和范围查询。
        
- **磁盘 I/O 和存储密度：**
    
    - **B 树：**  
        由于内部节点存储数据记录，存储密度相对较低，每个节点能存放的关键字数量较少。
        
    - **B+ 树：**  
        内部节点只存储键值和指针，因而能够装载更多索引项，降低了树的高度，减少了磁盘访问次数。
        

### 为什么 MySQL 采用 B+ 树

- **高效的范围查询与顺序扫描：**  
    MySQL 的 InnoDB 存储引擎主要使用 B+ 树来实现索引。由于叶子节点构成了一个有序链表，范围查询和顺序扫描非常高效，对于查询范围内的数据只需要顺序扫描叶子链表即可。
    
- **降低树高度和磁盘 I/O：**  
    B+ 树内部节点只存储键值，能容纳更多索引项，从而树的高度更低。这对于磁盘存储来说，可以减少访问磁盘的次数，提高查询性能。
    
- **聚集索引设计：**  
    在 InnoDB 中，数据记录与主键索引存储在同一 B+ 树上，利用 B+ 树的结构可以实现聚集索引，数据存储与索引有机结合，便于范围查询和分页查询。
    

### 为什么 MongoDB 采用 B 树

- **直接数据访问：**  
    MongoDB 选择 B 树作为索引结构，允许数据在内部节点中直接存储。这种设计在某些场景下可以减少一次查找的开销，因为如果数据恰好存储在内部节点，就无需再访问叶子节点。
    
- **灵活性和适应性：**  
    MongoDB 的存储场景和数据模型与传统关系型数据库有所不同，使用 B 树在设计上更灵活，能够快速定位和返回结果，适应其文档存储和动态查询需求。
    
- **历史和实现因素：**  
    在 MongoDB 的设计演进过程中，选择 B 树结构可能更符合其系统架构和性能优化的需求，特别是在多种查询类型和动态索引管理方面，B 树的实现方式能更好地满足业务要求。
    

---

你的问题涵盖了服务治理、运维排查、系统资源优化、数据库、高并发、操作系统、编程语言底层实现、算法等多个领域，我会逐一回答。

---

### 1. Consul 介绍

Consul 是 HashiCorp 开源的分布式服务治理解决方案，主要提供**服务发现**、**健康检查**、**KV 存储**、**多数据中心支持**和**服务网格**等功能。

- **服务发现**：服务可以向 Consul 注册，并通过 DNS 或 HTTP 查询找到其他服务。
    
- **健康检查**：Consul 通过 HTTP、TCP、gRPC、脚本等方式进行服务健康检查，自动剔除不可用服务。
    
- **KV 存储**：类似于 etcd 和 Zookeeper，可以用于存储配置数据，如数据库连接信息。
    
- **多数据中心**：支持多个数据中心之间的同步。
    
- **服务网格**：通过 Consul Connect 实现安全的服务间通信（类似 Istio）。
    

---

### 2. 多个服务实例运行，某个实例出现问题如何排查

1. **日志分析**：检查 `systemctl status` 或 `journalctl -u 服务名`，或应用自身日志。
    
2. **健康检查**：Consul/Zookeeper/etcd 等注册中心是否检测到异常。
    
3. **进程状态**：`ps aux | grep 服务名`，检查进程是否存活，资源占用情况。
    
4. **端口监听**：`netstat -tulnp | grep 端口`，检查端口是否正常监听。
    
5. **依赖项**：数据库、Redis、MQ 等依赖服务是否正常。
    
6. **CPU/内存**：`top` 或 `htop` 观察进程资源占用。
    
7. **网络**：`ping`、`telnet`、`tcpdump` 等检查网络问题。
    
8. **重启服务**：若无头绪，可尝试 `systemctl restart` 或 `docker restart`。
    

---

### 3. 资源占用从哪几部分考虑

1. **CPU**：进程占用的 CPU，是否有计算瓶颈（`top`、`htop`）。
    
2. **内存**：应用是否有内存泄漏、缓存占用大（`free -h`、`ps aux --sort=-%mem`）。
    
3. **I/O**：磁盘或网络 I/O 是否过高（`iostat`、`iotop`、`sar -d`）。
    
4. **网络**：流量是否过大、丢包率高（`iftop`、`netstat -s`、`tcpdump`）。
    

---

### 4. Redis 常见的部署架构

- **单机模式**：适用于小型应用，但没有高可用。
    
- **主从模式**：一个主节点，多从节点，读写分离，但主节点挂掉时手动切换。
    
- **Sentinel（哨兵）模式**：在主从基础上增加监控和自动故障转移。
    
- **Cluster（集群模式）**：数据分片，多个主节点，每个主节点带多个从节点，适用于高并发和大数据存储。
    

---

### 5. Redis 为什么快

1. **基于内存存储**，避免了磁盘 I/O 瓶颈。
    
2. **单线程处理**，避免了多线程上下文切换开销。
    
3. **使用高效的数据结构**（跳表、哈希表、压缩列表）。
    
4. **采用 epoll/kqueue 事件机制**，高效处理并发请求。
    

---

### 6. Redis 的 QPS 能达到多少？

- 单机可达 **10 万 QPS**，具体取决于 CPU、网络等条件。
    
- Cluster 模式下可通过分片扩展到 **百万级 QPS**。
    

---

### 7. Redis 数据迁移

- **`bgsave` + `scp`**：先 RDB 冷备，再拷贝到新机器。
    
- **主从同步**：搭建一个新 Redis 作为主节点，从原来的 Redis 进行数据同步，完成后切换主节点。
    
- **`redis-cli --rdb`**：导出 RDB 文件后再导入。
    
- **在线迁移**：使用 `redis-shake` 进行数据同步。
    

---

### 8. RDB 为什么比 AOF 快

- RDB 采用 **快照存储**，批量写入，减少磁盘 I/O。
    
- AOF 采用 **追加写**，每条操作都会写入日志，I/O 开销大。
    

---

### 9. MySQL 主键索引 vs 普通索引

- **主键索引（Clustered Index）**：数据按主键顺序存储，叶子节点存储的是完整行数据。
    
- **普通索引（Secondary Index）**：索引存储的是主键值，而不是行数据，查询时需要回表。
    

---

### 10. 如何优化 name = 'abc' 查询（上百亿行）

1. **创建索引 `ALTER TABLE t ADD INDEX idx_name (name)`**。
    
2. **使用覆盖索引 `SELECT name FROM t WHERE name='abc'`** 避免回表。
    
3. **分库分表**，减少单表数据量。
    

---

### 11. OFFSET 和 LIMIT 的问题

- **大 OFFSET 慢**，因为 MySQL 需要扫描并丢弃前 N 条数据。
    
- **优化方法**：使用 `WHERE id > (SELECT id FROM t LIMIT N, 1)` 代替 `OFFSET`。
    

---

### 12. TCP vs UDP

- **TCP**：面向连接，可靠传输，有拥塞控制（如 HTTP、SSH）。
    
- **UDP**：无连接，不可靠，低延迟（如 DNS、视频流）。
    

---

### 13. 死锁的情况

1. **互斥**：资源只能被一个线程占有。
    
2. **持有并等待**：持有资源的同时等待新资源。
    
3. **不可剥夺**：资源不能被抢占。
    
4. **循环等待**：多个线程形成环形等待。
    

---

### 14. 进程调度算法

1. **FIFO**：先到先服务。
    
2. **SJF**：短作业优先。
    
3. **RR**：时间片轮转。
    
4. **MLFQ**：多级反馈队列。
    

---

### 15. Go 的 slice 底层

- **结构**：`ptr`（指向数组的指针）、`len`（长度）、`cap`（容量）。
    
- **扩容机制**：不足时 `cap*2`。
    

---

### 16. Go 和 C++ 遍历 map 时删除 key

- **Go**：不能边遍历边删除。
    
- **C++**：使用 `erase(it++)`。
    

---

### 17. 线程安全删除 map key

- **先收集要删除的 key**，再创建新 map 过滤保留的 key。
    

---

### 18. 三树之和（算法题）

- **排序 + 双指针**，类似三数之和问题。
    

---

### 19. C++ `vector` 实现

- **动态数组**，底层是 `malloc` 分配内存，扩容时 `2x` 扩展。
    

---

### 20. `sort` 底层实现

- C++ `std::sort` 使用 **IntroSort**（快速排序 + 堆排序 + 插入排序）。
    

---

### 21. 选择排序 vs 快排

- **几十个元素**：选择排序较快，避免递归开销。
    
- **更多元素**：快排更快，$O(n \log n)$ 复杂度更优。
    

---

### 22. 低资源情况下的优化

1. **减少内存占用**：用 `uint8_t` 代替 `int`，压缩数据结构。
    
2. **减少 CPU 开销**：使用 SIMD 指令优化计算。
    
3. **减少 I/O**：批量处理数据。
    

---

这些问题涵盖了面试核心知识点，欢迎交流！


### **1. MySQL 索引有哪些？**

MySQL 的索引主要包括以下几种：

- **主键索引（PRIMARY KEY）**：唯一标识表中的一行，默认是 **聚簇索引（InnoDB）**，数据按主键顺序存储。
    
- **唯一索引（UNIQUE）**：保证某列的值唯一，但不同于主键，允许 `NULL` 值。
    
- **普通索引（INDEX）**：对查询加速，但不强制唯一性。
    
- **全文索引（FULLTEXT）**：用于全文搜索（如 `MATCH() AGAINST()`）。
    
- **前缀索引（Prefix Index）**：针对长字符串字段，索引部分前缀（适用于 `VARCHAR` / `TEXT`）。
    
- **哈希索引（Hash Index）**：Memory 存储引擎支持，基于哈希算法，查询快但不支持范围查询。
    
- **空间索引（Spatial Index, SPATIAL）**：适用于 GIS（地理信息）数据类型，如 `POINT`、`LINESTRING`。
    

---

### **2. 什么是联合索引？适用于哪些场景？**

**联合索引（Composite Index）** 是指 **多个列组合** 在一起的索引，例如：

```sql
CREATE INDEX idx_name_age ON users(name, age);
```

适用于：

1. **多个查询条件**，如：
    
    ```sql
    SELECT * FROM users WHERE name = 'Tom' AND age = 25;
    ```
    
    **联合索引会比单列索引更高效。**
    
2. **索引最左匹配原则（Leftmost Prefix Matching）**：
    
    - `WHERE name = 'Tom'` ✅ **能用索引**
        
    - `WHERE age = 25` ❌ **不能单独用该索引**
        
    - `WHERE name = 'Tom' AND age > 20` ✅ **能用索引**
        
    - `WHERE age > 20 AND name = 'Tom'` ✅ **优化器可调整顺序**
        
    - `WHERE age > 20` ❌ **不能用索引**
        

**索引失效情况**

- `WHERE name LIKE '%Tom%'`（前缀通配符）
    
- `WHERE name = 'Tom' OR age = 25`（`OR` 可能导致索引失效）
    

---

### **3. MySQL 查询优化方法**

**（1）使用索引优化**

- **覆盖索引（Covering Index）**：避免回表查询
    
    ```sql
    SELECT name FROM users WHERE name = 'Tom';
    ```
    
    若 `name` 在索引 `idx_name_age(name, age)` 中，**可直接查索引**，不需要回表查询。
    
- **索引下推（Index Condition Pushdown, ICP）** MySQL 5.6+ **减少回表次数**，如：
    
    ```sql
    SELECT * FROM users WHERE name LIKE 'Tom%' AND age > 20;
    ```
    
    **在索引中先筛选 name，然后再过滤 age，减少回表次数。**
    

**（2）SQL 查询优化**

- **避免 `SELECT *`**，只查询必要的列。
    
- **尽量减少 `JOIN` 和子查询**，用 `EXPLAIN` 分析索引使用情况。
    
- **优化 `ORDER BY`**，如：
    
    ```sql
    SELECT * FROM users ORDER BY age LIMIT 10;
    ```
    
    若 `age` 有索引，可直接 **索引排序**，否则可能导致 **Using filesort**。
    

**（3）表结构优化**

- **拆分大表**（**分库分表、分区表**）
    
- **使用合适的数据类型**，如：
    
    - `VARCHAR(255)` → `VARCHAR(50)`（避免过长）
        
    - `BIGINT` → `INT`（节省存储）
        

**（4）缓存优化**

- **使用 Redis 缓存热点数据**，减少 MySQL 访问压力。
    
- **使用 `Query Cache`**（MySQL 8.0 已移除）。
    
- **避免慢查询**，设置 `slow_query_log` 并优化 `EXPLAIN` 结果。
    

---

### **4. MySQL 事务隔离级别**

MySQL **事务隔离级别** 有 4 种：

1. **读未提交（Read Uncommitted）**
    
    - 事务可读取未提交的数据（脏读）。
        
    - 可能有**脏读、不可重复读、幻读**问题。
        
2. **读已提交（Read Committed，Oracle 默认）**
    
    - 事务只能读取已提交数据（无脏读）。
        
    - 可能有**不可重复读、幻读**问题。
        
3. **可重复读（Repeatable Read，InnoDB 默认）**
    
    - 事务中多次读取相同数据，保证一致（无脏读、不可重复读）。
        
    - **可能有幻读（但 MySQL 通过 MVCC 解决）**。
        
4. **串行化（Serializable）**
    
    - **最高级别**，事务完全串行执行（加锁）。
        
    - **性能最差**，通常不推荐使用。
        

---

### **5. MySQL 的 MVCC（多版本并发控制）**

**MVCC（Multi-Version Concurrency Control）** 主要通过 **快照读（Snapshot Read）** 来实现：

- **可重复读** 通过 MVCC 解决**不可重复读**问题。
    
- **MVCC 通过 undo log 存储历史版本**，使得不同事务可以读取不同的版本数据。
    

**MVCC 机制**

1. **Read View**：每个事务开启时，创建一个 **Read View**，用于确定可以看到哪些数据版本。
    
2. **Undo Log**：存储数据的历史版本，实现多版本读。
    
3. **事务 ID（trx_id）**：
    
    - **每个事务都有一个 ID**，数据更新时，新数据会分配新的 **事务 ID**。
        

**快照读 vs 当前读**

- **快照读（Snapshot Read）**（使用 MVCC）
    
    ```sql
    SELECT * FROM users WHERE id = 1; -- 读历史版本（无锁）
    ```
    
- **当前读（Current Read）**（加锁）
    
    ```sql
    SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE; -- 共享锁
    SELECT * FROM users WHERE id = 1 FOR UPDATE; -- 排他锁
    ```
    

**MVCC 优势**

- 读不加锁，写不阻塞读，提高并发性能。
    
- **默认的 `REPEATABLE READ` 级别可避免幻读问题**。
    

---

### **总结**

| 主题       | 说明                                       |
| -------- | ---------------------------------------- |
| **索引**   | 主键索引、唯一索引、普通索引、联合索引等                     |
| **联合索引** | 遵循**最左前缀匹配**，适用于多条件查询                    |
| **查询优化** | `EXPLAIN` 分析索引、避免 `SELECT *`、缓存优化        |
| **事务隔离** | **可重复读（MySQL 默认）**，防止不可重复读，MVCC 解决幻读     |
| **MVCC** | **通过 Read View + Undo Log 实现多版本控制，提高并发** |
|          |                                          |


### **1. URL 输入到浏览器响应经历了什么？**

1. **DNS 解析**：将域名解析为 IP 地址。
    
2. **TCP 连接**：三次握手建立连接（HTTP/3 使用 QUIC）。
    
3. **发送 HTTP 请求**：浏览器构造 HTTP 请求并发送给服务器。
    
4. **服务器处理请求**：后端解析请求、查询数据库、执行业务逻辑等。
    
5. **服务器返回 HTTP 响应**：返回 HTML、JSON、图片等数据。
    
6. **浏览器渲染**：解析 HTML、CSS，执行 JS，最终渲染页面。
    

---

### **2. HTTP 怎么解析的？**

- **请求行**（Request Line）：包含 `GET /index.html HTTP/1.1`
    
- **请求头**（Request Headers）：包含 `Host、User-Agent、Accept-Encoding` 等
    
- **请求体**（Request Body）：POST 请求的数据（JSON、表单等）
    
- **服务器解析 HTTP 响应**：
    
    - 状态行：`HTTP/1.1 200 OK`
        
    - 响应头：`Content-Type: text/html`
        
    - 响应体：HTML 页面数据或 JSON 数据
        

---

### **3. TCP 怎么保证可靠性？**

1. **校验和（Checksum）**：防止数据损坏。
    
2. **序列号（Sequence Number）**：保证数据按顺序到达。
    
3. **确认应答（ACK）**：确保数据被正确接收。
    
4. **超时重传（Retransmission Timeout, RTO）**：丢包时自动重传。
    
5. **滑动窗口（Sliding Window）**：控制数据流，提高传输效率。
    
6. **流量控制（Flow Control）**：防止发送端发送过快导致接收端缓存溢出。
    
7. **拥塞控制（Congestion Control）**：避免网络拥塞。
    

---

### **4. TCP 的快速重传解释**

当接收方**连续收到 3 个相同的 ACK**（ACK 号未变），说明某个数据包丢失，发送方**立即重传丢失的包**，而不必等待超时。

---

### **5. TCP 拥塞控制是为了解决什么问题？**

防止网络因数据过多而拥塞（丢包、延迟增加），保证整体吞吐量。

四种控制机制：

1. **慢启动（Slow Start）**：指数增长，初始时控制发送速率。
    
2. **拥塞避免（Congestion Avoidance）**：线性增长，避免网络拥塞。
    
3. **快速重传（Fast Retransmit）**：3 次 ACK 触发重传。
    
4. **快速恢复（Fast Recovery）**：避免慢启动，快速回到拥塞避免阶段。
    

---

### **6. TCP 接收缓存接不住了怎么办？**

1. **通知发送方减少发送速率**（滑动窗口）。
    
2. **丢弃新来的数据包**（导致超时重传）。
    
3. **调整内核参数**，增大 `net.core.rmem_max`。
    

---

### **7. MySQL InnoDB 的索引结构**

InnoDB 索引采用 **B+ 树** 结构：

- **主键索引（聚簇索引，Clustered Index）**：
    
    - 叶子节点存储**整行数据**。
        
- **二级索引（辅助索引，Secondary Index）**：
    
    - 叶子节点存储**主键 ID**，需要回表查询。
        

---

### **8. 二级索引存放的是什么数据？**

- **存放主键 ID**，不存整行数据。
    
- 查询时先查二级索引，再回表查数据（索引回表）。
    

---

### **9. 联合索引 `A=10 AND B>100 AND C>50` 这种怎么查？**

- **最左前缀匹配原则**：
    
    - 若索引 `idx(A, B, C)`：
        
        1. **先匹配 `A=10`**。
            
        2. **再匹配 `B>100`（范围查询）**。
            
        3. **`C>50` 无法使用索引**（范围查询后续字段不能用索引）。
            

优化方案：

- 只筛选 `A=10 AND B>100`，再在结果中过滤 `C>50`。
    

---

### **10. IO 多路复用：select 和 epoll**

|**机制**|**特点**|
|---|---|
|`select`|轮询所有 fd，最多支持 1024/2048 个连接（Linux 限制），**O(n)**|
|`epoll`|事件驱动，不轮询所有 fd，**O(1)**，适用于高并发|

---

### **11. 内核态和用户态的区别**

|**对比项**|**用户态**|**内核态**|
|---|---|---|
|运行权限|低（Ring 3）|高（Ring 0）|
|访问资源|不能直接访问硬件|可以访问硬件|
|运行位置|应用程序|操作系统内核|

---

### **12. 什么时候会进入内核态？**

1. **系统调用（syscall）**
    
2. **中断（硬件中断、异常）**
    
3. **进程调度**
    
4. **IO 操作（读写文件、网络通信）**
    

---

### **13. 除了系统调用和硬件中断，还有其他方式吗？**

- **软件中断（Soft Interrupt）**
    
- **信号（Signal）**
    

---

### **14. 高峰期在线人数**

表 `(userid, login_time, logout_time)`，求高峰期人数：

```sql
SELECT time, SUM(active_users) AS online_users
FROM (
    SELECT login_time AS time, 1 AS active_users FROM user_logs
    UNION ALL
    SELECT logout_time, -1 FROM user_logs
) AS events
GROUP BY time
ORDER BY time;
```

**思路**：

- **登录 +1，登出 -1**。
    
- **按照时间排序，计算最大值**。
    



### **1. HTTP1.0 和 HTTP1.1 的区别**

|**对比项**|**HTTP1.0**|**HTTP1.1**|
|---|---|---|
|**连接方式**|**短连接**，每次请求都要重新建立 TCP 连接|**长连接**（默认 `Connection: keep-alive`）|
|**请求管道化**|不支持，必须等待前一个请求完成|支持**流水线请求**（Pipelining，但默认关闭）|
|**Host 头**|可选，不支持虚拟主机|**必须**，支持多个虚拟主机共享 IP|
|**缓存机制**|依赖 `Expires` 头|新增 `Cache-Control`（`max-age`、`no-cache`）|
|**分块传输**|不支持|**支持 `Transfer-Encoding: chunked`**|
|**额外请求方法**|仅支持 `GET`、`POST`|新增 `PUT`、`DELETE`、`OPTIONS` 等|
|**状态管理**|依赖 `Cookie`|新增 `ETag`、`If-Modified-Since` 等优化|

---

### **2. UDP 为什么是不安全的？**

1. **无连接**：UDP 不需要建立连接，数据包可能丢失或乱序。
    
2. **不可靠传输**：
    
    - **无确认机制**：UDP 发送后不管数据是否到达。
        
    - **无重传机制**：数据丢失不会自动重发。
        
    - **无流量控制**：不会根据网络情况调整发送速率。
        
    - **无拥塞控制**：发送端可能会导致网络拥塞。
        
3. **容易被伪造**：UDP 头部较简单，容易被欺骗（如 UDP 放大攻击）。
    

---

### **3. 视频通话基于 UDP，卡顿严重，如何减少 UDP 丢包？**

1. **前向纠错（FEC, Forward Error Correction）**
    
    - 通过冗余数据恢复丢失的包，例如 `n` 个数据包中插入额外的 `m` 个校验包。
        
2. **自适应比特率（ABR, Adaptive Bitrate）**
    
    - 根据网络状况动态调整视频质量（降低码率）。
        
3. **ARQ（Automatic Repeat reQuest，自动重传请求）**
    
    - 在 UDP 之上实现类似 TCP 的重传机制，但只重传关键数据。
        
4. **降低丢包率**
    
    - **QoS（Quality of Service）**：运营商优先处理视频流量。
        
    - **FEC 码**：RTP+FEC 降低丢包带来的影响。
        
    - **带宽冗余**：使用更大的带宽来缓解网络抖动。
        
5. **减少延迟**
    
    - **减少缓冲时间**：实时视频比流媒体需要更低的缓冲。
        
    - **减少 Jitter Buffer**：动态调整抖动缓冲区，避免过大的网络延迟。
        
6. **使用 QUIC 代替 UDP**
    
    - QUIC 在 UDP 之上增加了可靠性（支持丢包重传、流量控制）。
        

---

### **4. DNS 解析过程**

1. **浏览器缓存**：先查找本地缓存是否有 IP 地址。
    
2. **操作系统缓存**：查找 `/etc/hosts` 或系统 DNS 缓存。
    
3. **本地 DNS 服务器**（ISP 提供）：
    
    - 若缓存命中，直接返回 IP 地址。
        
    - 若无缓存，向 **根域名服务器** 递归查询。
        
4. **根域名服务器**：
    
    - 共 **13 台**，负责全球 DNS 查询的顶级分发。
        
    - 返回 **顶级域名服务器（TLD，.com、.cn）** 的地址。
        
5. **TLD 服务器**：
    
    - 例如 `.com` 服务器，返回该域名的 **权威 DNS 服务器**。
        
6. **权威 DNS 服务器**：
    
    - 例如 `baidu.com` 的权威服务器，返回最终的 IP 地址。
        
7. **返回给用户**：本地 DNS 服务器缓存并返回 IP，浏览器连接目标服务器。
    

---

### **总结**

1. **HTTP1.1** 相比 HTTP1.0 有 **长连接、分块传输、Host 头、缓存优化**。
    
2. **UDP 不可靠**，无连接、无确认、无流控、无拥塞控制。
    
3. **减少 UDP 丢包**：
    
    - **FEC 纠错、ARQ 重传、QoS 保障、自适应码率、带宽冗余**。
        
    - **可以用 QUIC 代替 UDP**。
        
4. **DNS 解析**：
    
    - **浏览器/系统缓存 → 本地 DNS → 根 DNS（13 台） → TLD 服务器 → 权威 DNS → 返回 IP**。
        

希望对你有帮助！🚀