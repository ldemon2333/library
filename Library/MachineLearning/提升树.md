提升树是以分类树或回归树为基本分类器的提升方法。

#  提升树模型
boosting方法实际采用加法模型（即基函数的线性组合）与前向分布算法。以决策树为基函数的boosting方法称为提升树（boosting tree）。对分类问题决策树是二叉分类树，对回归问题决策树是二叉回归树。提升树模型可以表决为决策树的加法模型：
![[Pasted image 20240921120941.png]]

# 提升树算法
![[Pasted image 20240921121136.png]]
下面讨论针对不同问题的提升树学习算法，其主要区别在于使用的损失函数不同。包括用平方误差损失函数的回归问题，用指数损失函数的分类问题，以及用一般损失函数的一般决策问题。

对于二类分类问题，提升树算法只需将AdaBoost算法中的基本分类器限制为二类分类树即可。下面叙述回归问题的提升树。
![[Pasted image 20240921121623.png]]
![[Pasted image 20240921121650.png]]
![[Pasted image 20240921121946.png]]
是当前模型拟合数据的残差（residual）。所以，对回归问题的提升树算法来说，只需简单地拟合当前模型的残差。
![[Pasted image 20240921122117.png]]
![[Pasted image 20240921122220.png]]

# 梯度提升
提升树利用加法模型与前向分布算法实现学习的优化过程。当损失函数是平方损失和指数损失函数时，每一步优化是很简单的。但对一般损失函数而言，往往每一步优化并不那么容易。针对这一问题，Freidman提出了梯度提升算法。这是利用最速下降法的近似方法，其关键是利用损失函数的负梯度在当前模型的值
![[Pasted image 20240921123734.png]]
![[Pasted image 20240921123818.png]]
![[Pasted image 20240921123904.png]]

