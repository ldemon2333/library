谱聚类（spectral clustering）是广泛使用的聚类算法，比起传统的K-Means算法，谱聚类对数据分布的适应性更强，聚类效果也很优秀，同时聚类的计算量也小很多，更加难能可贵的是实现起来也不复杂。在处理实际的聚类问题时，个人认为谱聚类是应该首先考虑的几种算法之一。下面我们就对谱聚类的算法原理做一个总结。

# 1.谱聚类概述
谱聚类是从图论中演化出来的算法，后来在聚类中得到了广泛的应用。它的主要思想是把所有的数据看做空间中的点，这些点之间可以用边连接起来。距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重值较高，通过对所有数据点组成的图进行切图，让切图后不同的子图间边权重和尽可能的低，而子图内的边权重和尽可能的高，从而达到聚类的目的。

乍一看，这个算法原理的确简单，但是要完全理解这个算法的话，需要对图论中的无向图，线性代数和矩阵分析都有一定的了解。下面我们就从这些需要的基础知识开始，一步步学习谱聚类。

# 2.一：无向权重图
对于一个图$G$，我们一般用点的集合$V$和边的集合$E$来描述。即为$G(V,E)$。其中$V$即为我们数据集里面所有的点$(v_1,v_2,...,v_n)$。对于$V$中的任意两个点，可以有边连接，也可以没有边连接。我们定义权重$w_{ij}$为点$v_i$和点$v_j$之间的权重。由于是无向图，所以$w_{ij} = w_{ji}$。

对于有边连接的两个点$v_i$和$v_j$，$w_{ij}>0$,对于没有边连接的两个点$v_i$和$v_j$，$w_{ij}=0$。对于图中的任意一个点$v_i$，它的度$d_i$定义为和它相连的所有边的权重之和，即
$$
d_i = \sum\limits_{j=1}^{n}w_{ij}
$$
利用每个点度的定义，我们可以得到一个nxn的度矩阵$D$，它是一个对角矩阵，只有主对角线，对应第$i$行的第$i$个点的度数，定义如下：
$$
\mathbf{D} = \left( \begin{array}{ccc} d_1 & \ldots & \ldots \\ \ldots & d_2 & \ldots \\   \vdots & \vdots & \ddots \\   \ldots & \ldots &  d_n \end{array} \right)
$$
除此之外，对于点集$V$的一个子集$A \subset V$，我们定义：
$$
|A|: = 子集A中点的个数
$$
$$
vol(A): = \sum\limits_{i \in A}d_i
$$
# 3.二：相似矩阵
在上一节我们讲到了邻接矩阵$W$，它是由任意两点之间的权重值$w_{ij}$组成的矩阵。通常我们可以自己输入权重，但是在谱聚类中，我们只有数据点的定义，并没有直接给出这个邻接矩阵，那么怎么得到这个邻接矩阵呢？

基本思想是，距离较远的两个点之间的边权重值较低，而距离较近的两个点之间的边权重值较高，不过这仅仅是定性，我们需要定量的权重值。一般来说，我们可以通过样本点距离度量的相似矩阵$S$来获得邻接矩阵$W$。

构建邻接矩阵$W$的方法有三类。$\epsilon$-邻近法，K邻近法和全连接法。

对于$\epsilon$-邻近法，它设置了一个距离阈值$\epsilon$，然后用欧式距离$s_{ij}$度量任意两点$x_i$和$x_j$的距离。即相似矩阵的$s_{ij} = \|x_i-x_j\|_2^2$，然后根据$s_{ij}$和$\epsilon$的大小关系，来定义邻接矩阵$W$如下：
$$
w_{ij}= \begin{cases} 0& {s_{ij} > \epsilon}\\ \epsilon& {{s_{ij} \leq \epsilon}} \end{cases}
$$
从上式可见，两点间的权重要不就是$\epsilon$,要不就是0，没有其他的信息了。距离远近度量很不精确，因此在实际应用中，我们很少使用$\epsilon$-邻近法。

第二种定义邻接矩阵$W$的方法是K邻近法，利用KNN算法遍历所有的样本点，取每个样本最近的k个点作为近邻，只有和样本距离最近的k个点之间的$w_{ij}>0$。但是这种方法会造成重构之后的邻接矩阵$W$非对称，我们后面的算法需要对称邻接矩阵。为了解决这种问题，一般采取下面两种方法之一：
第一种K邻近法是只要一个点在另一个点的K近邻中，则保留$s_{ij}$
$$
w_{ij}=w_{ji}= \begin{cases} 0& {x_i \notin KNN(x_j) \;and \;x_j \notin KNN(x_i)}\\ exp(-\frac{\|x_i-x_j\|_2^2}{2\sigma^2})& {x_i \in KNN(x_j)\; or\; x_j \in KNN(x_i}) \end{cases}
$$
第二种k邻近法是必须两个点互为k近邻中，才能保留$s_{ij}$
$$
w_{ij}=w_{ji}= \begin{cases} 0& {x_i \notin KNN(x_j) \;or\;x_j \notin KNN(x_i)}\\ exp(-\frac{\|x_i-x_j\|_2^2}{2\sigma^2})& {x_i \in KNN(x_j)\; and \; x_j \in KNN(x_i}) \end{cases}
$$
第三种定义邻接矩阵$W$的方法是全连接法，相比前两种方法，第三种方法所有的点之间的权重值都大于0，因此称之为全连接法。可以选择不同的核函数来定义边权重，常用的有多项式核函数，高斯核函数和Sigmoid核函数。最常用的是高斯核函数RBF，此时相似矩阵和邻接矩阵相同：
$$
w_{ij}=s_{ij}=exp(-\frac{\|x_i-x_j\|_2^2}{2\sigma^2})
$$
在实际的应用中，使用第三种全连接法来建立邻接矩阵是最普遍的，而在全连接法中使用高斯径向核RBF是最普遍的。

# 4.谱聚类基础三：拉普拉斯矩阵
单独把拉普拉斯矩阵(Graph Laplacians)拿出来介绍是因为后面的算法和这个矩阵的性质息息相关。它的定义很简单，拉普拉斯矩阵$L=D−W$。$D$即为我们第二节讲的度矩阵，它是一个对角矩阵。而$W$即为我们第二节讲的邻接矩阵，它可以由我们第三节的方法构建出。

拉普拉斯矩阵有一些很好的性质如下：

1）拉普拉斯矩阵是对称矩阵
2）由于拉普拉斯矩阵是对称矩阵，则它的所有特征值都是实数
3）对于任意的向量$f$，我们有
$$
f^TLf = \frac{1}{2}\sum\limits_{i,j=1}^{n}w_{ij}(f_i-f_j)^2
$$
这个利用拉普拉斯矩阵的定义很容易得到如下：
$$
f^TLf = f^TDf - f^TWf = \sum\limits_{i=1}^{n}d_if_i^2 - \sum\limits_{i,j=1}^{n}w_{ij}f_if_j
$$
$$
=\frac{1}{2}( \sum\limits_{i=1}^{n}d_if_i^2 - 2 \sum\limits_{i,j=1}^{n}w_{ij}f_if_j + \sum\limits_{j=1}^{n}d_jf_j^2) = \frac{1}{2}\sum\limits_{i,j=1}^{n}w_{ij}(f_i-f_j)^2
$$

4）拉普拉斯矩阵是半正定的，且对应的n个实数特征值都大于等于0。

# 5.谱聚类基础四：无向图切图
对于无向图$G$的切图，我们的目标是将图$G(V,E)$切成相互没有连接的k个子图，每个子图点的集合为：

每个子图点的集合为：$A_1,A_2,...,A_k$，它们满足$A_i \cap A_j = \emptyset$，且$A_1 \cup A_2 \cup ... \cup A_k = V$.

对于任意两个子图点的集合$A,B \subset V$,$A\cap B=\emptyset$，我们定义$A$和$B$之间的切图权重为：
$$
W(A, B) = \sum\limits_{i \in A, j \in B}w_{ij}
$$
那么对于我们k个子图点的集合：$A_1,A_2,...,A_k$，我们定义切图cut为：
$$
cut(A_1,A_2,...A_k) = \frac{1}{2}\sum\limits_{i=1}^{k}W(A_i, \overline{A}_i )
$$
其中$\overline{A}_i$为$A_i$的补集。

那么如何切图可以让子图内的点权重和高，子图间的点权重和低呢？一个自然的想法就是最小化$cut(A_1,A_2,...A_k)$，但是可以发现，这种极小化的切图存在问题，如下图：
![[Pasted image 20241008135243.png]]

# 6.谱聚类之切图聚类
为了避免最小切图导致的切图效果不佳，我们需要对每个子图的规模做出限定，一般来说，有两种切图方式，第一种是RatioCut，第二种是Ncut。下面我们分别加以介绍

## 6.1 RatioCut切图
![[Pasted image 20241008135603.png]]
![[Pasted image 20241008135621.png]]

## 6.2Ncut切图
![[Pasted image 20241008135726.png]]![[Pasted image 20241008135739.png]]
# 7.谱聚类算法流程
![[Pasted image 20241008135851.png]]

# 8.总结
谱聚类算法是一个使用起来简单，但是讲清楚却不是那么容易的算法，它需要你有一定的数学基础。如果你掌握了谱聚类，相信你会对矩阵分析，图论有更深入的理解。同时对降维里的主成分分析也会加深理解。

下面总结下谱聚类算法的优缺点。

谱聚类算法的主要优点有：

1）谱聚类只需要数据之间的相似度矩阵，因此对于处理稀疏数据的聚类很有效。这点传统聚类算法比如K-Means很难做到

2）由于使用了降维，因此在处理高维数据聚类时的复杂度比传统聚类算法好。

谱聚类算法的主要缺点有：

1）如果最终聚类的维度非常高，则由于降维的幅度不够，谱聚类的运行速度和最后的聚类效果均不好。

2） 聚类效果依赖于相似矩阵，不同的相似矩阵得到的最终聚类效果可能很不同。