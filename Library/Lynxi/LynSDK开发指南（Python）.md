# 1. 使用约束
- 一个设备代表单芯片，当前不支持多设备级联

# 2. 简介
## 2.1 什么是 LynSDK
LynSDK 是 KA200 类脑芯片处理器（简称 KA200）的软件栈，面向用户提供了设备（Device）管 理、上下文（Context）管理、流（Stream）管理、Event（Event）管理、内存（Memory）管理、媒体 数据（视频、图像）处理、模型（Neural Network Model）加载与执行、ARM plugin 加载和执行、错误处理（Error Handling or Callback）等 Python 语言 API 库，供用户开发深度学习神经网络应用，用于实现目标检测与跟踪、图像分类、高速物体检测等功能。

## 2.2 系统架构
LynSDK 的软件架构
![[Pasted image 20241118115506.png]]

用户可以通过第三方框架调用灵汐异构编程语言（Lynxi Heterogeneous Programming Language, LXHPL）提供的接口，以便使用 KA200 的运行管理、资源管理能力。

用户应用运行期间，用户可以调用运行管理器（Runtime Manager）的接口实现 Device 管理、 Context 管理、Stream 管理、Event 管理和 Memory 管理。

计算平台层（Computing Platform）主要指计算加速单元（APU）以及用于完成 AI 运算的 CPU， 主要完成神经网络相关的标量、向量以及矩阵计算，完成各神经网络层之间的数据传输和控制，为完 成高效的神经网络推理提供了保障。

## 2.3 基本概念

| 概念            | 描述                                                                                                                                             |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------- |
| KA200 类脑芯片处理器 | 简称 KA200，指由北京灵汐科技有限公司自主研发，应用众核类脑计算架构的 SoC 边 缘计算芯片，用于实现人工智能推理和类脑计算。                                                                             |
| Lyngor        | 是由北京灵汐科技有限公司基于自研 KA200 提供的计算图编程框架，提供了丰富的基 本算子，支持常用的机器学习、深度学习、类脑计算算法及模型。                                                                        |
| Client/Server | 本文中，Client（又称 Host）代表与 KA200 相连的 x86 服务器或 ARM 服务器，会利用 Server（又称 Device）提供的硬件处理能力完成相关业务；Server（又称 Device）代表 KA200 衍生产品（计算加速卡/模组），是指提供计算资源的硬件平台。 |
| Device        | 软件栈以设备（Device）为调度单元，一个设备特指一个 KA200，当一块 PCIe 卡有多块 KA200 时，称一个板卡上有多个设备（Device）。                                                                  |
| 同步/异步         | 若用户在 Client 端调用 LXHPL 提供的 API 不等待 Server 执行完成再返回，则表示 Client 端的调度是异步的；若在调用相关 API 后需要等待 Server 端执行完成再返回，则 表示 Client 端的调度是同步的。                    |
| 进程/线程         | 本文中提及的进程和线程，如无特殊说明，均代表 Client 端的进程和线程。                                                                                                         |
| Context       |                                                                                                                                                |
| Stream        | Stream 代表一组异步执行的指令流，Stream 内的异步指令执行顺序严格按照应用程序的 调用顺序。基于 Stream 的 API 执行能够实现 Client 端操作、Client 与 Server 间的数据传输、Server 端的运算并行。                    |
| APU           | 即加速处理单元（Accelerated Procssing Units），指 KA200 提供的用于神经网络推理的 硬件加速模块。                                                                              |
| Event         |                                                                                                                                                |

## 2.4 进程、线程、设备、上下文、流之间的关系
### 2.4.1 设备/上下文/流之间的关系
![[Pasted image 20241118123407.png]]




