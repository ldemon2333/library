# 1. 从网卡接收数据说起
下图是一个典型的计算机结构图，计算机由CPU、存储器（内存）、网络接口等部件组成。了解epoll本质的**第一步**，要从**硬件**的角度看计算机怎样接收网络数据。
![[Pasted image 20250107231315.png]]

下图展示了网卡接收数据的过程。在①阶段，网卡收到网线传来的数据；经过②阶段的硬件电路的传输；最终将数据写入到内存中的某个地址上（③阶段）。这个过程涉及到DMA传输、IO通路选择等硬件有关的知识，但我们只需知道：**网卡会把接收到的数据写入内存。**
![[Pasted image 20250107231351.png]]
网卡收到数据通过DMA写入内存，然后发送中断信号，系统执行中断程序，将网卡写入的内存内容转移到具体的socket对应的缓存区。同时该中断信号激活SELECT运行,SELECT在每个被它管理的 socket 的睡眠队列里都塞入一个与它相关的 entry。SELECT函数扫描自己监控的fd有没有状态发生变化的，如果有就返回值，没有就继续阻塞。

# 2. 如何知道接受了数据
了解epoll本质的**第二步**，要从**CPU**的角度来看数据接收。要理解这个问题，要先了解一个概念——中断。

一般而言，由硬件产生的信号需要cpu立马做出回应（不然数据可能就丢失），所以它的优先级很高。cpu理应中断掉正在执行的程序，去做出响应；当cpu完成对硬件的响应后，再重新执行用户程序。

当网卡把数据写入到内存后，网卡向CPU发出一个中断信号，OS再通过网卡中断服务程序去处理数据。

# 3. 进程阻塞为什么不占有 CPU 资源
recv, select 和 epoll 都是阻塞方法。

为简单起见，我们从普通的recv接收开始分析，先看看下面代码：
```text
//创建socket
int s = socket(AF_INET, SOCK_STREAM, 0);   
//绑定
bind(s, ...)
//监听
listen(s, ...)
//接受客户端连接
int c = accept(s, ...)
//接收客户端数据
recv(c, ...);
//将数据打印出来
printf(...)
```

recv 是个阻塞方法，当程序运行到 recv 时，它会一直等待，直到接收到数据才往下执行。

## 工作队列
![[Pasted image 20250107232154.png]]

## 等待队列
当进程A执行到创建socket的语句时，操作系统会创建一个由文件系统管理的 socket 对象。这个 socket 对象包含了发送缓冲区、接收缓冲区、等待队列等成员。等待队列是个非常重要的结构，它指向所有需要等待该socket事件的进程。
![[Pasted image 20250107232138.png]]
当程序执行到recv时，操作系统会将进程A从工作队列移动到该socket的等待队列中（如下图）。由于工作队列只剩下了进程B和C，依据进程调度，cpu会轮流执行这两个进程的程序，不会执行进程A的程序。**所以进程A被阻塞，不会往下执行代码，也不会占用cpu资源**。

## 唤醒进程
当socket接收到数据后，操作系统将该socket等待队列上的进程重新放回到工作队列，该进程变成运行状态，继续执行代码。也由于socket的接收缓冲区已经有了数据，recv可以返回接收到的数据。

# 4. 内核接收网络数据全过程
如下图所示，进程在recv阻塞期间，计算机收到了对端传送的数据（步骤①）。数据经由网卡传送到内存（步骤②），然后网卡通过中断信号通知cpu有数据到达，cpu执行中断程序（步骤③）。此处的中断程序主要有两项功能，先将网络数据写入到对应socket的接收缓冲区里面（步骤④），再唤醒进程A（步骤⑤），重新将进程A放入工作队列中。
![[Pasted image 20250107232449.png]]
唤醒进程的过程如下图所示。
![[Pasted image 20250107232520.png]]
**以上是内核接收数据全过程**

这里留有两个思考题，大家先想一想。

其一，操作系统如何知道网络数据对应于哪个socket？

其二，如何同时监视多个socket的数据？

第一个问题：因为一个socket对应着一个端口号，而网络数据包中包含了ip和端口的信息，内核可以通过端口号找到对应的socket。当然，为了提高处理速度，操作系统会维护端口号到socket的索引结构，以快速读取。

第二个问题是**多路复用的重中之重，是本文后半部分的重点！**

# 5. 同时监视多个 socket 的简单方法
服务端需要管理多个客户端连接，而recv只能监视单个socket，这种矛盾下，人们开始寻找监视多个socket的方法。epoll的要义是**高效**的监视多个socket。从历史发展角度看，必然先出现一种不太高效的方法，人们再加以改进。只有先理解了不太高效的方法，才能够理解epoll的本质。

描述不够准确，其实是一个socket进程只能处理一个客户端连接，当多个连接到来时会拥塞，而select和epoll解决了拥塞问题，使得一个socket进程可以处理多个，理论上无限个连接，从而提高了qps

`select` 是一种多路复用技术，用于在单个线程中处理多个 I/O 操作，它运行程序同时监听多个文件描述符的状态变化（如可读，可写）。在网络编程中，`select` 可以用于实现单个线程同时处理多个客户端连接，从而避免了为每个连接创建独立线程的问题。

假如能够预先传入一个socket列表，**如果列表中的socket都没有数据，挂起进程，直到有一个socket收到数据，唤醒进程**。这种方法很直接，也是select的设计思想。

为方便理解，我们先复习`select`的用法。在如下的代码中，先准备一个数组（下面代码中的fds），让fds存放着所有需要监视的socket。然后调用select，如果fds中的所有socket都没有数据，select会阻塞，直到有一个socket接收到数据，select返回，唤醒进程。用户可以遍历fds，通过`FD_ISSET`判断具体哪个socket收到数据，然后做出处理。
```text
int s = socket(AF_INET, SOCK_STREAM, 0);  
bind(s, ...)
listen(s, ...)

int fds[] =  存放需要监听的socket

while(1){
    int n = select(..., fds, ...)
    for(int i=0; i < fds.count; i++){
        if(FD_ISSET(fds[i], ...)){
            //fds[i]的数据处理
        }
    }
}
```
`select` 在某种程度上可以被认为是一种 **轮询操作**，但它具有一些优化的特性，使其不同于传统的逐一检查每个文件描述符的简单轮询。

### `select` 的工作原理：

1. **初始化**： 在每次调用 `select` 之前，程序需要通过 `FD_ZERO` 清空文件描述符集合，并通过 `FD_SET` 把要监视的文件描述符添加到集合中。
    
2. **阻塞等待**： 一旦文件描述符集合设置完成，调用 `select` 函数时会阻塞并等待这些文件描述符中的一个或多个准备就绪（例如：变得可读、可写或发生异常）。
    
3. **返回状态**： `select` 返回后，可以通过 `FD_ISSET` 来检查哪些文件描述符已经准备就绪，准备就绪的文件描述符就是你需要进一步操作的目标。
    

### 是否是轮询？

虽然 `select` 在一定程度上依赖于轮询，但它的工作方式不完全是传统的轮询。传统的轮询会一直检查每个文件描述符的状态，直到发现某些文件描述符已准备好。而 `select` 在进行文件描述符状态检查时，**会阻塞**直到某些文件描述符变得可读或可写。`select` 在每次调用时会使用操作系统的内核进行优化，它并不会每次都完全遍历所有的文件描述符，而是会根据操作系统的内部实现去高效地查找有事件发生的文件描述符。

### 与传统轮询的区别：

1. **阻塞等待**：
    
    - 传统的轮询方式（如你手动实现的 `while` 循环）通常会不断检查所有文件描述符的状态（例如 `recv` 或 `read` 是否可以进行），这是一个忙等待（busy-wait）的过程，直到某些条件满足。
    - 而 `select` 在文件描述符准备好之前会阻塞在内核层面，减少了不必要的 CPU 使用率，因此更加高效。
2. **事件驱动**： `select` 只是简单地告诉程序：**哪个文件描述符有事件发生（可读、可写等）**。当某个事件发生时，`select` 返回，程序可以继续处理准备好的文件描述符。它并不会主动去轮询每个文件描述符，而是会在内核中做一些事件的检查。
    

### `select` 的不足：

1. **性能问题**：
    
    - 在文件描述符数量非常多的时候，`select` 的性能会下降。每次调用 `select` 都需要将所有要监听的文件描述符遍历一遍，并且有一个最大文件描述符的限制（通常是 1024，受 `FD_SETSIZE` 限制）。
    - 每次调用 `select` 时都需要修改文件描述符集合，并且可能会多次遍历这些文件描述符，这导致了性能瓶颈。
2. **不支持边缘触发**：
    
    - `select` 是基于 **水平触发**（level-triggered）模式的，这意味着即使文件描述符已经准备好进行 I/O 操作，它也可能会在下次调用时再次触发。如果你使用 `select` 监听某个文件描述符的可读事件，它会在每次调用时报告该文件描述符可读，直到你真正读完数据。

### 总结：

- `select` 的确有轮询的性质，因为它会检查多个文件描述符的状态，但它是通过操作系统内核的机制来高效地管理这个过程的。它会阻塞直到有事件发生，而不是通过不断检查每个文件描述符来浪费 CPU 时间。
- `select` 是基于 **事件驱动** 的，而不是传统的轮询方式，因此它相比直接的忙等待来说更加高效。
- 如果需要处理大量并发连接，可能需要考虑 `poll` 或 `epoll`，因为它们在大规模连接时具有更好的性能。

## select 流程
最low的就是在用户代码中自旋实现所有阻塞socket的监听。但是每次判断socket是否产生数据，都涉及到用户态到内核态的切换。  
于是select改进：将fd_set传入内核态，由内核判断是否有数据返回；
然后最low的只能使用自旋来时刻的去判断socket列表中是否有数据达到。  
于是select改进：使用等待队列，让线程在没有资源时park（阻塞），当有数据到达时唤醒select线程，去处理socket。

select的实现思路很直接。假如程序同时监视如下图的sock1、sock2和sock3三个socket，那么在调用select之后，操作系统把进程A分别加入这三个socket的等待队列中。

当任何一个socket收到数据后，中断程序将唤起进程。下图展示了sock2接收到了数据的处理流程。

![[Pasted image 20250107233050.png]]
sock2接收到了数据，中断程序唤起进程A

所谓唤起进程，就是将进程从所有的等待队列中移除，加入到工作队列里面。如下图所示。
![[Pasted image 20250107233106.png]]
经由这些步骤，当进程A被唤醒后，它知道至少有一个socket接收了数据。程序只需遍历一遍socket列表，就可以得到就绪的socket。

这种简单方式**行之有效**，在几乎所有操作系统都有对应的实现。

**但是简单的方法往往有缺点，主要是：**

其一，每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。

其二，进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。

那么，有没有减少遍历的方法？有没有保存就绪socket的方法？这两个问题便是epoll技术要解决的。

>补充说明： 本节只解释了select的一种情形。当程序调用select时，内核会先遍历一遍socket，如果有一个以上的socket接收缓冲区有数据，那么select直接返回，不会阻塞。这也是为什么select的返回值有可能大于1的原因之一。如果没有socket有数据，进程才会阻塞。

# 6. epoll 的设计思路
epoll是在select出现N多年后才被发明的，是select和poll的增强版本。epoll通过以下一些措施来改进效率。

## 措施一： 功能分离
将维护等待队列与阻塞进程分离。

select低效的原因之一是将“维护等待队列”和“阻塞进程”两个步骤合二为一。如下图所示，每次调用select都需要这两步操作，然而大多数应用场景中，需要监视的socket相对固定，并不需要每次都修改。epoll将这两个操作分开，先用`epoll_ctl`维护等待队列，再调用`epoll_wait`阻塞进程。显而易见的，效率就能得到提升。
![[Pasted image 20250107233547.png]]
为方便理解后续的内容，我们先复习下epoll的用法。如下的代码中，先用epoll_create创建一个epoll对象epfd，再通过epoll_ctl将需要监视的socket添加到epfd中，最后调用epoll_wait等待数据。
```text
int s = socket(AF_INET, SOCK_STREAM, 0);   
bind(s, ...)
listen(s, ...)

int epfd = epoll_create(...);
epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中

while(1){
    int n = epoll_wait(...)
    for(接收到数据的socket){
        //处理
    }
}
```

功能分离，使得epoll有了优化的可能。

## 措施二：就绪列表
引入就绪列表 rdlist

select低效的另一个原因在于程序不知道哪些socket收到数据，只能一个个遍历。如果内核维护一个“就绪列表”，引用收到数据的socket，就能避免遍历。如下图所示，计算机共有三个socket，收到数据的sock2和sock3被rdlist（就绪列表）所引用。当进程被唤醒后，只要获取rdlist的内容，就能够知道哪些socket收到数据。
![[Pasted image 20250107233832.png]]

对于epoll:  
大学女生宿舍，你想找你对象，于是你找到舍管大妈，把你女朋友的名字和宿舍房号报给舍管大妈，大妈直接就可以帮你找到你女朋友。  
  
对于select:  
还是女生宿舍，你告诉舍管大妈你女朋友的名字，但是舍管大妈，是带着你从一楼101开始一件一件宿舍去找你女朋友…

select/poll模型。  
情况1. 为了能够让一个进程，监控多个socket.
把一个 socket 列表，传入到selector选择器上。这样selector，循环遍历socket列表。把就绪状态的 socket 选择出来，然后进行处理。什么是就绪状态：假设socket的读缓冲区有可读的数据，那么此socket就处于就绪状态。就绪状态的socket，可以这样处理，当读缓冲区有数据时，就读数据。当写缓冲区有空间可以写时，就写数据。当ServerSocket有新建了连接时，就接收 clinetSocket ，并且把clinetSocket添加到seletor选择器中。完成以上处理后，再次遍历socket列表，按照以上逻辑反复处理。

情况2. 遍历一次socket列表，没有一个socket处于就绪状态，那么进程A将阻塞。  
具体流程：遍历socket列表，发现socket处于未就绪状态。那么就在该socket的等待队列中，添加进程A的引用。当遍历完整个socket列表，却没有任何一个socket处于就绪状态。那么就把进程A从工作队列移除，让进程处于阻塞状态。由于CPU每次执行完指令，都会检查是否有中断信号。假设10S以后，socket列表中，有一个socket处于就绪状态。那么网卡对应的硬件，会向CPU发一个中断信号。CPU收到一个中断信号，从而调用对应的中断程序。此中断程序，会把进程A唤醒，加入到工作队列。并且遍历socket列表，将进程A的引用，从所有的等待队列中移除。  
selector再次遍历socket列表，把就绪的 socket选出来，然后进行读或者写的操作。再来看等待队列的作用：就是当socket就绪时，能够通过等待队列的进程引用，找到对应的进程。

讲得有些复杂。简单来说，就是epoll维护了一个红黑树和一个链表，需要监听的socket添加到红黑树上，哪个socket有事件过来，就把它加到链表上，然后发给用户通知。用户直接遍历这个链表，挨个处理即可。 而poll和select只返回有数据的fd的数量，并没有说是哪个fd，所以还需要挨个遍历所有fd去检查

# 7. epoll 的原理和流程
## 创建 epoll 对象
如下图所示，当某个进程调用epoll_create方法时，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll 对象也是文件系统中的一员，和 socket 一样，它也会有等待队列。
![[Pasted image 20250108000443.png]]
内核创建eventpoll对象

创建一个代表该epoll的eventpoll对象是必须的，因为内核要维护“就绪列表”等数据，“就绪列表”可以作为eventpoll的成员。

## 维护监视列表
创建epoll对象后，可以用epoll_ctl添加或删除所要监听的socket。以添加socket为例，如下图，如果通过epoll_ctl添加sock1、sock2和sock3的监视，内核会将eventpoll添加到这三个socket的等待队列中。
![[Pasted image 20250108000607.png]]

当socket收到数据后，中断程序会操作eventpoll对象，而不是直接操作进程。

## 接收数据
当socket收到数据后，中断程序会给eventpoll的“就绪列表”添加socket引用。如下图展示的是sock2和sock3收到数据后，中断程序让rdlist引用这两个socket。
![[Pasted image 20250108000638.png]]

eventpoll对象相当于是socket和进程之间的中介，socket的数据接收并不直接影响进程，而是通过改变eventpoll的就绪列表来改变进程状态。

当程序执行到epoll_wait时，如果rdlist已经引用了socket，那么epoll_wait直接返回，如果rdlist为空，阻塞进程。

## 阻塞和唤醒进程
假设计算机中正在运行进程A和进程B，在某时刻进程A运行到了epoll_wait语句。如下图所示，内核会将进程A放入eventpoll的等待队列中，阻塞进程。
![[Pasted image 20250108000732.png]]
epoll_wait阻塞进程

当socket接收到数据，中断程序一方面修改rdlist，另一方面唤醒eventpoll等待队列中的进程，进程A再次进入运行状态（如下图）。也因为rdlist的存在，进程A可以知道哪些socket发生了变化。
![[Pasted image 20250108000841.png]]
epoll唤醒进程

# 8. epoll 实现细节
eventpoll 的数据结构是什么样子？

就绪队列应该使用什么数据结构？eventpoll应使用什么数据结构来管理通过epoll_ctl添加或删除的socket？

如下图所示，eventpoll包含了lock、mtx、wq（等待队列）、rdlist等成员。rdlist和rbr是我们所关心的。
![[Pasted image 20250108001216.png]]
**就绪列表的数据结构**

就绪列表引用着就绪的socket，所以它应能够快速的插入数据。

程序可能随时调用 epoll_ctl 添加监视socket，也可能随时删除。当删除时，若该socket已经存放在就绪列表中，它也应该被移除。

所以就绪列表应是一种能够快速插入和删除的数据结构。双向链表就是这样一种数据结构，epoll 使用双向链表来是实现就绪队列（对应上图的rdllist）。

**索引结构**
既然epoll将“维护监视队列”和“进程阻塞”分离，也意味着需要有个数据结构来保存监视的socket。至少要方便的添加和移除，还要便于搜索，以避免重复添加。epoll使用了红黑树作为索引结构（对应上图的rbr）。

# 9. 结论
epoll在select和poll（poll和select基本一样，有少量改进）的基础引入了eventpoll作为中间层，使用了先进的数据结构，是一种高效的多路复用技术。

下表是个很常见的表，描述了select、poll和epoll的区别。读完本文，读者能否解释select和epoll的时间复杂度为什么是O(n)和O(1)？
![[Pasted image 20250108001509.png]]
再来看看epoll：  
epoll不会让每个 socket的等待队列都添加进程A引用，而是在等待队列，添加 eventPoll对象的引用。  
当socket就绪时，中断程序会操作eventPoll，在eventPoll中的就绪列表(rdlist)，添加scoket引用。  
这样的话，进程A只需要不断循环遍历rdlist，从而获取就绪的socket。  
从代码来看每次执行到epoll_wait，其实都是去遍历 rdlist。

如果rdlist为空，那么就阻塞进程。  
当有socket处于就绪状态，也是发中断信号，再调用对应的中断程序。  
此时中断程序，会把socket加到rdlist，然后唤醒进程。进程再去遍历rdlist，获取到就绪socket。

总之： poll是翻译轮询的意思，我们可以看到poll和epoll都有轮询的过程。  
不同点在于：  
poll轮询的是所有的socket。  
而epoll只轮询就绪的socket。

首先 epoll 初始化用 `epoll_create` 创建一个 `event_poll` 对象，这个对象有就绪列表，红黑树，等待队列。就绪列表存放就绪的 socket，红黑树存放所有正在监听的 socket 引用，等待列表存放正在等待的进程。

# select poll epoll 总结区别
**select  poll 归为一类说：**
1. select和poll区别是文件描述符数量多少差别，select 用数组记录套接字，poll用的链表。本质没啥区别的。找几个代码例子就能看出来。
2. select和poll相同点，都是轮循，比如有1000个需要监控的TCP连接，同一时间活跃的有10个，那么他们会把1000个套接字标志传到内核，内核遍历1000遍，发现有10个活跃的，修改这10个套接字中状态为可读。然后再传到用户进程遍历1000遍，看看哪个套接字对的状态为可读的。

可以看出，效率低的2点： （1）每次循环3000次，（2）每次拷贝2000个

3.关于这一点：s触发方式是水平触发，应用程序如果没有完成对一个已经就绪的文件描述符进行IO操作，那么之后每次调用还是会将这些文件描述符通知进程。

做游戏服务器的一般不存在这点。

**epoll 归为一类，是如何解决select和poll 效率低的问题呢？**

1.epoll监控tcp连接用的红黑树，添加到内核后，不需要再次添加重复连接。如果继续用上边的数据例子，那么（1）一共循环1000 Log1000 ，加上 每次活跃的 10个  （2）每次拷贝10个

2.每帧检测活跃的套接字会放到双列表里，送到用户进程也就10个


https://my.oschina.net/alchemystar/blog/3008840

