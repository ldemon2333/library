# 1.作用
**为什么会有线程池，到底解决了什么问题**

1. 减少线程的创建与销毁（线程的角度）
2. 异步解耦的作用（设计的角度）

# 2. 线程池的异步处理使用场景
以日志为例，在写日志loginfo(“xxx”)，与日志落盘，是两码事，它们两之间应该是异步的。那么异步解耦就是将日志当作一个任务task，将这个任务抛给线程池去处理，由线程池去负责日志落盘。对于应用程序而言，就可以提升落盘的效率。

以nginx为例，一秒几万的请求，速度很快。如果在其中加一个日志，那么qps一下子就掉下来了，因为每请求一次就需要落盘一次，那么整个服务器的性能就下降。我们可以引入一个线程池，把日志这个任务抛给线程池，对于主循环来说，就只抛任务即可，这样就可以大大提升主线程的效率。这就是线程池异步解耦的作用

不仅仅是日志落盘，还有很多地方都可以用线程池，比较耗时的操作如数据库操作，io处理等，都可以用线程池。

线程池有必要将线程与cpu做亲和性吗？ 在注重cpu处理能力的时候，可以做黏合；如果注重的是异步解耦，那么这里更加注重的是任务，没必要将线程和cpu做绑定。

# 3. 线程池工作原理
## 3.1 线程池应该提供哪些 api
![[Pasted image 20250107125045.png]]
我们在使用线程池的时候，是当作一个组件去使用。所以在使用组件的时候，我们首先想到的是线程池应该提供哪些api。

1. 线程池的初始化(创建) init/create
2. 往池里面抛任务push_task
3. 线程池的销毁 deinit/destroy

这三个api是最核心的api，其他可扩展的api都是可有可无的，而这三个api是一定要有的。

## 3.2 线程池的三个组件
想象去银行营业厅的场景。柜员：为客户提供服务；客户：是来办业务的，对于柜员来说，这些人就是任务。那么这两个形象就构建出了pthread和task。

那么这个公示牌(xxx号来几号柜台办理业务)，是谁的属性呢？告示牌的作用是管理客户和柜员有秩序工作，它不隶属于柜员，也不隶属于客户，它是一个管理工具。

1. 柜员 ---->pthread
2. 客户 ---->task
3. 告示牌–>管理柜员和客户有秩序的工作（不会出现一个任务同时被多个线程处理的情况）

这么这就自然而然的形成了3个组件，那么它们都应该有什么属性呢：

- 对于柜员来说：工号id，停止工作标识符flag
- 对于客户来说：如果办理取款需要带银行卡，如果办贷款需要带凭证等等，所以需要一个任务func()，以及对应任务的参数arg
- 对于告示牌来说：如果没有客户，那么柜员就需要在工作中等待客户的到来，所以第一个需要条件等待cond，既然要管理有秩序的工作，肯定需要mutex来保证临界资源

下面将柜员称为执行队列，客户称为任务队列，告示牌称为池管理组件。

错误理解：要使用线程就从线程池里面拿一个线程出来使用，用完再返回给线程池。这种理解是连接池的概念。而线程池是多个线程去任务队列取任务，竞争任务。

所以线程的核心就是下面的伪代码：

```
while(1){
	get_task();
	task->func();
}
```

# 4. 代码实现
## 4.1 线程池的任务队列、执行队列、池管理组件的定义与添加删除
![[Pasted image 20250107125746.png]]

## 4.2 三个api
创建其实就是创建thread_poll_t结构体，然后按照给定的宏创建线程和worker。

push就是给task队列增加一个任务，然后用signal通知cond。

销毁将所有线程的termination置1，然后广播cond即可。

## 4.3 线程的回调函数
线程要做的就是取任务，执行任务。取任务从任务队列里面取。


# Thread Pool in C++
## Need of Thread Pool in C++
In C++, a thread pool is needed in the following cases:
- When several activities must be completed simulataneously, like in server applications , parallel processing, and parallelizing loops, thread pools are frequently utilized.
- Thread Pools enhance overall performance by lowering the overhead of thread generation and destruction through thread use.

## Example 
The implementation mangages a pool of worker threads and a queue of tasks using thread, queue, mutex, and condition_variable. Every worker thread does tasks once it has continually waited for them to be enqueued.

## Explanation
1. A vector of worker threads, a task queue, a mutex for synchronization, a condition variable for signaling, and a boolean flag to indicate whether the pool should stop are all managed by the ThreadPool class.  
    
2. The worker threads are initialized by the constructor, who then puts them in an endless loop while they wait for jobs to be enqueued. We use a wrapper class std::function over the given tasks.  
    
3. A job is added to the queue and one of the worker threads is notified to begin executing it using the enqueue method.  
    
4. To guarantee a clean shutdown, the destructor joins the worker threads, sets the stop flag, and informs all threads.  
    
5. A ThreadPool with four threads is formed in the main function. Ten jobs are queued up, each of which prints a message including the task number and the thread ID that is currently carrying it out.  
    
6. It should be noted that in a real-world situation, you would usually connect the threads or use some other kind of synchronization to make sure that all jobs are finished before the program ends.


