I/O 复用（I/O Multiplexing）是指在一个进程中同时处理多个 I/O 操作的技术。通过这种方式，单个进程可以同时监视多个文件描述符（例如网络套接字、文件等），当其中某个文件描述符准备好进行 I/O 操作时，程序会被通知并可以处理相应的操作。

I/O 复用的关键在于，它允许进程在等待某些 I/O 操作（如读取、写入）时不需要阻塞其他操作，进而提高程序的并发性和效率。这种技术广泛用于服务器应用程序，尤其是网络编程中，如 HTTP 服务器、数据库连接池等。

在 Linux 中，常见的 I/O 复用机制有：

1. **select**：这是最早的一种 I/O 复用机制，允许你监视多个文件描述符的状态（可读、可写、异常）。但是它有一些限制，例如文件描述符的数量有限。
    
2. **poll**：类似于 `select`，但相比之下，它可以处理更多的文件描述符，而且没有 `select` 的文件描述符数量限制。它使用轮询的方式来检查每个文件描述符的状态。
    
3. **epoll**：这是 Linux 提供的一种更高效的 I/O 复用机制，适用于大量文件描述符的场景。与 `select` 和 `poll` 不同，`epoll` 是基于事件驱动的，只有在某个文件描述符准备好时，内核才会通知应用程序，大大减少了不必要的系统调用。

I/O 复用的优势主要体现在以下几个方面：

- **高效的资源利用**：避免了每个连接都创建一个线程或进程，从而减少了系统资源消耗。
- **非阻塞性**：通过事件驱动机制，进程可以在 I/O 操作完成之前执行其他任务。
- **提高并发性**：使得单个进程可以同时处理大量并发连接，而不需要创建多个线程或进程。

这种技术在构建高性能的服务器应用（如 Web 服务器、数据库服务等）时非常重要，尤其是在处理大量并发请求的场景中。

通常，网络程序在下列情况下需要使用 I/O 复用技术：
- 客户端程序要同时处理多个 socket。
- 客户端程序要同时处理用户输入和网络连接。
- TCP 服务器要同时处理监听 socket 和连接 socket。
- 服务器要同时处理 TCP 请求和 UDP 请求。
- 服务器要同时监听多个端口，或者处理多种服务。
I/O 复用虽然能同时监听多个文件描述符，但它本身是阻塞的。并且当多个文件描述符同时就绪时，如果不采取额外的措施，程序只能按顺序依次处理其中的每一个文件描述符，这使得服务器程序看起来像是串行工作的。如果要实现并发，只能使用多进程或多线程等编程手段。

# 9.1 select 系统调用
select 系统调用的用途是：在一段时间内，监听用户感兴趣的文件描述符上的可读、可写和异常等事件。

## 9.1.1 select API
select 系统调用的原型如下：
![[Pasted image 20250224153423.png]]
1) nfds 指定被监听的文件描述符的总数。通常被设置为 select 监听的所有文件描述符中的最大值加 1.
2) readfds、writefds 和 execptfds 参数分别指向可读、可写和异常等事件对应的文件描述符集合。应用程序调用 select 函数时，通过这三个参数传入自己感兴趣的文件描述符。select 调用返回时，内核将修改它们来通知应用程序哪些文件描述符已经就绪。
![[Pasted image 20250224153821.png]]
fd_set 结构体仅包含一个整型数组，该数组的每个元素的每一位（bit）标记了一个文件描述符。fd_set 能容纳的文件描述符数量由 FD_SETSIZE 指定。
![[Pasted image 20250224153942.png]]
1) timeout 参数用来设置 select 函数的超时时间。它是一个 timeval 结构体的指针。
![[Pasted image 20250224154040.png]]
如果给 timeout 变量的 tv_sec 成员和 tv_usec 成员都传递 0，则 select 将立即返回。如果给 timeout 传递 NULL，则select 将一直阻塞，直到某个文件描述符就绪。


select 成功时返回就绪（可读、可写和异常）文件描述符的总数。

## 9.1.2 文件描述符就绪条件
哪些情况下文件描述符可以被认为是可读、可写或者出现异常。下列情况下 socket 可读：
- socket 内核接收缓存区中的字节数大于或等于其低水位标记 SO_RCVLOWAT。此时可以无阻塞地读该 socket，并且读操作返回的字节数大于 0.
- socket 通信的对方关闭连接。此时对该 socket 的读操作将返回 0。
- 监听 socket 上有新的连接请求。
- socket 上有未处理的错误。此时可以使用 getsockopt 来读取和清除该错误。

下列 socket 可写：
![[Pasted image 20250224154610.png]]

## 9.1.3 处理带外数据
socket 上接收到普通数据和带外数据都将使 select 返回，但 socket 处于不同的就绪状态：前者处于可读状态，后者处于异常状态。

每次调用 select 前都要重新在 read_fds 和 exception_fds 中设置文件描述符 connfd，因为事件发生之后，文件描述符集合将被内核修改。

# 9.2 poll 系统调用
poll 在指定时间内轮询一定数量的文件描述符，以测试其中是否有就绪者。
![[Pasted image 20250224155422.png]]
![[Pasted image 20250224155543.png]]

# 9.3 epoll 系列系统调用
## 9.3.1 内核事件表
epoll 是 Linux 特有的 I/O 复用函数。首先，epoll 使用一组函数来完成任务，而不是单个函数。其次，epoll 把用户关心的文件描述符上的事件放在内核里的一个事件表中，从而无须像 select 和 poll 那样每次调用都要重复传入文件描述符集或事件集。但 epoll 需要使用一个额外的文件描述符，来唯一标识内核中的这个事件表。
![[Pasted image 20250224155853.png]]
siza 给内核一个提示，告诉它事件表需要多大。该函数返回的文件描述符将用作其他所有 epoll 系统调用的第一个参数，以指定要访问的内核事件表。

下面 epoll_ctl 用来操作 epoll 的内核事件表：
![[Pasted image 20250224160115.png]]

## 9.3.2 epoll_wait 函数
![[Pasted image 20250224160245.png]]
![[Pasted image 20250224160453.png]]

## 9.3.3 LT 和 ET 模式
epoll 对文件描述符的操作有两种模式：LT 和 ET。LT 模式是默认的工作模式

![[Pasted image 20250224160627.png]]

将文件描述符设置为非阻塞模式意味着对文件描述符的I/O操作将不会阻塞当前线程。具体来说：

1. **读取操作**：当尝试从文件描述符读取数据时，如果数据不可用，系统不会让线程等待，而是立即返回一个错误（如EAGAIN或EWOULDBLOCK），表示无法立即完成读取。
    
2. **写入操作**：当尝试向文件描述符写入数据时，如果缓冲区已满或无法立即写入，系统同样返回错误，而不是等待空间可用。
    
3. **轮询机制**：为了高效处理多个非阻塞文件描述符，通常会结合轮询机制（如select、poll、epoll等），定期检查哪些文件描述符已准备好进行I/O操作。
    
4. **性能优化**：非阻塞模式特别适合需要处理高并发I/O操作的场景，如Web服务器或实时通信系统，因为它允许程序在同一时间处理多个连接而不被单个连接阻塞。
    
5. **实现方法**：在Linux系统中，可以通过fcntl函数设置文件描述符的O_NONBLOCK标志来启用非阻塞模式。

每个使用 ET 模式的文件描述符都应该是非阻塞的。如果文件描述符是阻塞的，那么读或写操作将会因为没有后续的事件而一直处于阻塞状态。

## 9.3.4 EPOLLONESHOT 事件
即使使用 ET 模式，一个 socket 上的某个事件还是可能被触发多次。这在并发程序中会出现问题。期望的是一个 socket 连接在任一时刻都只被一个线程处理。这一点使用 epoll 的 EPOLLONESHOT 事件实现。
![[Pasted image 20250224161638.png]]

从工作线程函数 worker 来看，如果一个工作线程处理完某个 socket 上的一次请求（休眠 5 秒）之后，又接收到该 socket 上新的客户请求，则该线程将继续为这个 socket 服务。并且因为该 socket 上注册了 EPOLLONESHOT 事件，其他线程没有机会接触这个 socket，如果工作线程等待 5 秒后仍然没收到 socket 上的下一批客户数据，则它将放弃为该 socket 服务。同时，它调用 reset_oneshot 函数来重置该 socket 上的注册事件，这将使 epoll 有机会再次检测到该 socket 上的 EPOLLIN 事件，进而使得其他线程有机会为该 socket 服务。

尽管一个 socket 在不同时间可能被不同的线程处理，但同一时刻肯定只有一个线程为它服务。

# 9.4 三组 I/O 复用函数的比较
这三组系统调用都能同时监听多个 fd。它们将等待由 timeout 参数指定的超时时间，直到一个或者多个 fd 上有事件发生时返回，返回值是就绪的 fd 的数量。返回 0 表示没有事件发生。从事件集、最大支持文件描述符数、工作模式和具体实现等四个方面进一步比较它们的异同。
![[Pasted image 20250227131846.png]]

poll 和 epoll_wait 分别用 nfds 和 maxevents 参数指定最多监听多少个 fd 和事件。这两个数值都能达到系统允许打开的最大 fd 数目，即 65535。而 select 允许监听的最大 fd 数量通常有限制。

select 和 poll 都只能工作在相对低效的 LT 模式，而 epoll 则可以工作在 ET 高效模式。并且 epoll 还支持 EPOLLONESHOT 事件。该事件能进一步减少可读、可写和异常等事件被触发的次数。

1. **回调（Callback）**  
    是一种编程模式，其核心是**被动调用机制**。当某个事件发生或条件满足时，系统（或另一模块）会触发预先定义的操作。这种机制将控制权从调用者转移到被调用者，形成双向交互
    
2. **回调函数（Callback Function）**  
    是实现回调的具体手段，指通过函数指针（或函数对象）传递给其他函数的函数。其特点在于：
    - **被动执行**：由接收方在特定时机调用，而非由实现方直接调用
    - **参数传递**：可接收调用方传递的数据或状态

从实现原理上来说，select 和 epoll 采用的都是轮询的方式，即每次调用都要扫描整个注册 fd 集合，并将其中就绪的 fd 返回给用户程序，因此它们检测就绪事件的算法的时间复杂度是 O(n)。epoll_wait 则不同，它采用的是回调的方式。内核检测到就绪的 fd 时，将触发回调函数，回调函数就将该 fd 上对应的事件插入内核就绪事件队列。内核最后在适当的时机将该就绪事件队列中的内容拷贝到用户空间。因此 epoll_wait 无须轮询整个 fd 集合来检测哪些事件已经就绪，其算法时间复杂度是O(1)。但是，当活动连接比较多的时候，epoll_wait 的效率未必比 select 和 poll 高，因为此时回调函数被触发得过于频繁。所有 epoll_wait 适用于连接数量多，但活动连接较少的情况。
![[Pasted image 20250227133304.png]]

# 9.5 I/O 复用的高级应用一：非阻塞 connect
![[Pasted image 20250227133553.png]]
这段话描述了 connect 出错时的一种 errno 值：EINPROGRESS。这种错误发生在对非阻塞的 socket 调用 connect，而连接又没有立即建立时。在这种情况下，可以调用 select、poll 等函数来监听这个连接失败的 socket 上的可写事件。当 select、poll 等函数返回后，再利用 getsockopt 来读取错误码并清除 socket 上的错误。如果错误码是 0，表示连接成功建立，否则连接失败。

通过上面描述的非阻塞 connect 方式，就能同时发起多个连接并一起等待。

这种方法存在几处移植性问题。首先，非阻塞的 socket 可能导致 connect 始终失败。其次，select 对处于 EINPROGRESS 状态下的 socket 可能不起作用。最后，对于出错的 socket，getsockopt 在有些系统（Linux）上返回 -1，而在有些系统（UNIX）上则返回 0。这些问题没有一个统一的解决方法。

# 9.6 I/O 复用的高级应用二：聊天室程序
以 poll 为例实现一个简单的聊天室程序，以阐述如何使用 I/O 复用技术来同时处理网络连接和用户输入。分为客户端和服务器两个部分。其中客户端有两个功能：一是从标准输入终端读入用户数据，并将用户数据发送至服务器；二是往标准输出终端打印服务器发送给它的数据。服务器的功能是接收客户数据，并把客户数据发送给每一个登录到该服务器上的客户端（数据发送者除外）。

## 9.6.1 客户端
客户端使用 poll 同时监听用户输入和网络连接，并利用 splice 函数将用户输入内容直接定向到网络连接上以发送之，从而实现数据零拷贝，提高了程序执行效率。

## 9.6.2 服务器
服务器程序使用 poll 同时管理监听 socket 和连接 socket，并且使用牺牲空间换取时间的策略来提高服务器性能。

# 9.7 I/O 复用三：同时处理 TCP 和 UDP 服务
至此，我们讨论过的服务器程序都只监听一个端口。在实际应用中，有不少服务器程序能同时监听多个端口。

从 bind 系统调用的参数来看，一个 socket 只能与一个 socket 地址绑定，即一个 socket 只能用来监听一个端口。因此，服务器如果要同时监听多个端口，就必须创建多个 socket，并将它们分别绑定到各个端口上。这一一来，服务器程序就需要同时管理多个 socket，I/O 复用技术就有了用武之地。另外，即使是同一个端口，如果服务器要同时处理该端口上的 TCP 和 UDP 请求，则也需要创建两个不同的 socket：一个是流 socket，另一个是数据报 socket，并将它们都绑定到该端口上。

同时处理 TCP 请求和 UDP 请求的回射服务器

# 9.8 超级服务 xinetd
Linux 因特网服务 inetd 是超级服务。它同时管理着多个子服务，即监听多个端口。现在 Linux 系统上使用的 inetd 服务程序通常是其升级版本 xinetd。xinetd 程序的原理与 inetd 相同，但增加了一些控制选项，并提高了安全性。下面从配置文件和工作流程两个方面对 xinetd 进行介绍。

## 9.8.1 xinetd 配置文件
xinetd 采用 /etc/xinetd.conf 主配置文件和 /etc/xinetd.d 目录下的子配置文件来管理所有服务。主配置文件包含的是通用选项，这些选项将被所有子配置文件继承。不过子配置文件可以覆盖这些选项。每一个子配置文件用于设置一个子服务的参数。比如，telnet 子服务的配置文件 /etc/xinetd.d/telnet 的典型内容如下：
![[Pasted image 20250227145533.png]]

## 9.8.2 xinetd 工作流程
xinetd 管理的子服务中有的是标准服务，比如时间日期服务 daytime、回射服务 echo 和丢弃服务 discard。xinetd 服务器在内部直接处理这些服务。还有的子服务则需要调用外部的服务器程序来处理。xinetd 通过调用 fork 和 exec 函数来加载运行这些服务器程序。比如 telnet、ftp 服务都是这种类型的子服务。以 telnet 服务为例来探讨 xinetd 的工作流程。
![[Pasted image 20250227150124.png]]
![[Pasted image 20250227150239.png]]
![[Pasted image 20250227150355.png]]
