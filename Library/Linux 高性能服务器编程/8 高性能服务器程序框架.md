按照服务器程序的一般原理，将服务器解构为如下三个主要模块：
- I/O 处理单元。介绍 I/O 处理单元的四种 I/O 模型和两种高效事件处理模式
- 逻辑单元。介绍逻辑单元的两种高效并发模式，以及高效的逻辑处理方式——有限状态机
- 存储单元

# 8.1 服务器模型
## 8.1.1 C/S 模型
TCP/IP 协议在设计和实现上并没有客户端和服务器的概念，在通信过程中所有机器都是对等的。
![[Pasted image 20250214141915.png]]
服务器启动后，首先创建一个（或多个）监听 socket，并调用 bind 函数将其绑定到服务器端口上，然后调用 listen 函数等待客户连接。客户端可以调用 connect 函数向服务器发起连接。由于客户连接请求是随机到达的异步事件，服务器需要使用某种 I/O 模型来监听这一事件。I/O 模型有多种，图中采用的 I/O 复用技术是 select 系统调用。当监听到连接请求后，服务器就调用 accept 函数接收它，并分配一个逻辑单元为新的连接服务。逻辑单元可以是新创建的子进程、子线程或者其他。图中是子进程。图中，服务器同时监听多个客户请求是通过 select 系统调用实现的。

C/S 模型非常适合资源相对集中的场合，并且它的实现简单。但缺点是服务器是通信中心，当访问量过大时，所有客户得到很慢的响应。

## 8.1.2 P2P 模型
![[Pasted image 20250214142550.png]]
云计算机群可以看作 P2P 模型，缺点是用户之间传输的请求过多时，网络的负载将加重。主机之间很难互相发现。实际的 P2P 模型通常带有一个专门的发现服务器，这个发现服务器通常还提供查找服务，使每个客户都能尽快地找到自己需要的资源。

# 8.2 服务器编程框架
![[Pasted image 20250214142846.png]]
![[Pasted image 20250214142926.png]]
![[Pasted image 20250214142933.png]]

I/O 处理单元是服务器管理客户连接的模块。它通常要完成以下工作：等待并接收新的客户连接，接收客户数据，将服务器响应数据返回给客户端。但是，数据的收发不一定在 I/O 处理单元中执行，也可能在逻辑单元中执行，具体在何处执行取决于事件处理模式。对于一个服务器机群来说，I/O 处理单元是一个专门的接入服务器。它实现负载均衡，从所有逻辑服务器中选取负荷最小的一台来为新客户服务。

一个逻辑单元通常是一个进程或线程。它分析并处理客户数据，然后将结果传递给 I/O 处理单元或者直接发送给客户端（取决于事件处理模式）。对服务器机群而言，一个逻辑单元本身就是一台逻辑服务器。服务器通常拥有多个逻辑单元，以实现对多个客户任务的并行处理。

网络存储单元可以是数据库、缓冲和文件，甚至是一台独立的服务器。但它不是必须的。比如 ssh、telnet。

请求队列是各单元之间的通信方式的抽象。I/O 处理单元接收到客户请求时，需要以某种方式通知一个逻辑单元来处理该请求。同样，多个逻辑单元同时访问一个存储单元时，也需要采用某种机制来协调处理竞态条件。请求队列通常被实现为池的一部分。对于服务器机群而言，请求队列是各台服务器之间预先建立的、静态的、永久的 TCP 连接。这种 TCP 连接能提高服务器之间交换数据的效率。

# 8.3 I/O 模型
socket 在创建的时候默认是阻塞的。socket 系统调用的第二个参数设置 SOCK_NONBLOCK 标志，或者通过 fcntl 系统调用的 F_SETFL 命令，将其设置为非阻塞的。阻塞的 fd 称为阻塞 I/O。

针对阻塞 I/O 执行的系统调用可能因为无法立即完成而被 OS 挂起，直到等待的事件发生为止。比如，客户端通过 connect 向服务器发起连接时，connect 将首先发送同步报文段给服务器，然后等待服务器返回确认报文段。如果服务器的确认报文段没有立即到达客户端，则 connect 调用将被挂起，直到客户端收到确认报文段并唤醒 connect 调用。socket 的基础 API 中，可能被阻塞的系统调用包括 accept、send、recv 和 connect。

针对非阻塞 I/O 执行的系统调用则总是立即返回，而不管事件是否已经发生。如果事件没有立即发生，这些系统调用就返回 -1，代表出错。此时根据 errno 来区分这两种情况。对 accept、send 和 recv 而言，事件未发生时 errno 通常被设置成 EAGAIN（再来一次）或者 EWOULDBLOCK（期望阻塞）；对 connect 而言，errno 则被设置成 EINPROGRESS（处理中）。

显然，只有在事件已经发生的情况下操作非阻塞 I/O（读写），才能提高程序效率。因此，非阻塞 I/O 通常要和其他 I/O 通知机制一起使用，比如 I/O 复用和 SIGIO 信号。

I/O 复用是最常用的 I/O 通知机制。它指的是，应用程序通过 I/O 复用函数向内核注册一组事件，内核通过 I/O 复用函数把其中就绪的事件通知给应用程序。Linux 上常用的 I/O 复用函数是 select、poll 和 epoll_wait。I/O 复用函数本身是阻塞的，它们能提高程序效率的原因在于它们具有同时监听多个 I/O 事件的能力。

SIGIO 信号也可以用来报告 I/O 事件。我们可以为一个目标 fd 指定宿主进程，那么被指定的宿主进程将捕获到 SIGIO 信号。这样，当目标 fd 上有事件发生时，SIGIO 信号的信号处理函数将被触发，我们也就可以在该信号处理函数中对目标文件描述符执行非阻塞 I/O 操作。

从理论上说，阻塞 I/O、I/O 复用和信号驱动 I/O 都是同步 I/O 模型。因为在这三种模型中，I/O 的读写操作，都是在 I/O 事件发生之后，由应用程序来完成的。而 POSIX 规范所定义的异步 I/O 模型则不同。对异步 I/O 而言，用户可以直接对 I/O 执行读写操作，这些操作告诉内核用户读写缓冲区的位置，以及 I/O 操作完成之后内核通知应用程序的方式。异步 I/O 的读写操作总是立即返回，而不论 I/O 是否是阻塞的，因为真正的读写操作已经由内核接管。同步 I/O 向应用程序通知的是 I/O 就绪事件，而异步 I/O 向应用程序通知的是 I/O 完成事件。aio.h 头文件中定义的函数提高了对异步 I/O 的支持。
![[Pasted image 20250214150307.png]]

# 8.4 两种高效的事件处理模式
服务器程序通常需要处理三类事件：I/O 事件、信号及定时事件。两种事件处理模式：Reactor 和 Proactor

同步 I/O 模型通常用于实现 Reactor 模式，异步 I/O 模型则用于实习 Proactor 模式。

## 8.4.1 Reactor 模式
它要求主线程（I/O 处理单元）只负载监听 fd 上是否有事件发生，有的话就立即将该事件通知工作线程（逻辑单元）。除此之外，主线程不做任何其他实质性的工作。读写数据，接收新的连接，以及处理客户端请求均在工作线程中完成。

使用同步 I/O 模型（以 epoll_wait 为例）实现的 Reactor 模式的工作流程是：
1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程则将 socket 可读事件放入请求队列。
4. 睡眠在请求队列上的某个工作线程被唤醒，它从 socket 读取数据，并处理客户请求，然后往 epoll 内核事件表中注册该 socket 上的写就绪事件。
5. 主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程将 socket 可写事件放入请求队列。
7. 睡眠在请求队列上的某个工作线程被唤醒，它往 socket 上写入服务器处理客户请求的结果。
![[Pasted image 20250214151601.png]]
图 8-5 中，工作线程从请求队列中取出事件后，将根据事件的类型来决定如何处理它：对于可读事件，执行读数据和处理请求的操作；对于可写操作，执行写数据的操作。

## 8.4.2 Proactor 模式
Proactor 模式将所有 I/O 操作都交给主线程和内核来处理，工作线程仅仅负载业务逻辑。

使用异步 I/O 模型（以 aio_read 和 aio_write 为例）实现的 Proactor 模式的工作流程是：
1. 主线程调用 aio_read 函数向内核注册 socket 上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序（以信号为例）。
2. 主线程继续处理其他逻辑
3. 当 socket 上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。
4. 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用 aio_write 函数向内核注册 socket 上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序。
5. 主线程继续处理其他逻辑。
6. 当用户缓冲区的数据被写入 socket 之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
7. 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭 socket。
![[Pasted image 20250214153832.png]]
连接 socket 上的读写事件是通过 aio_read/aio_write 向内核注册的，因此内核将通过信号来向应用程序报告连接 socket 上的读写事件。所以，主线程中的 epoll_wait 调用仅能用来检测监听 socket 上的连接请求事件。

## 8.4.3 模拟 Proactor 模式
使用同步 I/O 方式模拟出 Proactor 模式的一种方法。其原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”。从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

使用同步 I/O 模型（epoll_wait）模拟出的 Proactor 模式的工作流程如下：
1. 主线程往 epoll 内核事件表中注册 socket 上的读就绪事件。
2. 主线程调用 epoll_wait 等待 socket 上有数据可读。
3. 当 socket 上有数据可读时，epoll_wait 通知主线程。主线程从 socket 循环读取数据，直到没有更多数据可读，然后将读取的数据封装成一个请求对象并插入请求队列。
4. 睡眠在请求队列中的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往 epoll 内核事件表中注册 socket 上的写就绪事件。
5. 主线程调用 epoll_wait 等待 socket 可写。
6. 当 socket 可写时，epoll_wait 通知主线程。主线程往 socket 上写入服务器处理客户请求的结果。
![[Pasted image 20250214193355.png]]

# 8.5 两种高效的并发模式
如果程序是计算密集型的，并发编程并没有优势，反而由于任务的切换使效率降低。但如果程序是 I/O 密集型的，比如经常读写文件，访问数据库等，则情况就不同了。由于 I/O 操作的速度没有 CPU 计算快，所以让程序阻塞于 I/O 操作将浪费大量的 CPU 时间。

从实现上说，并发编程主要有多进程和多线程两种方式。并发模式是指 I/O 处理单元和多个逻辑单元之间协调完成任务的方法。服务器主要有两种并发编程模式：半同步/半异步模式和 Leader/Followers 模式。

## 8.5.1 半同步/半异步模式
在 I/O 模型中，“同步”和“异步”区分的是内核向应用程序通知的是何种 I/O 事件（就绪事件还是完成事件），以及该由谁来完成 I/O 读写（是应用程序还是内核）。在并发模式中，“同步”指的是程序完全按照代码序列的顺序执行；“异步”指的是程序的执行需要由系统事件来驱动。常见的系统事件包括中断、信号等。
![[Pasted image 20250214195124.png]]
同步线程和异步线程。异步线程不适合于大量的并发。对于服务器，应该同时使用同步线程和异步线程来实现，即采用半同步/半异步模式来实现。

半同步/半异步模式中，同步线程用于处理客户逻辑，相当于逻辑单元；异步线程用于处理 I/O 事件，相当于 I/O 处理单元。异步线程监听到客户请求后，就将其封装成请求对象并插入请求队列中。请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。
![[Pasted image 20250214195603.png]]
在服务器程序中，如果结合考虑两种事件处理模式和几种 I/O 模型，则半同步/半异步模式就存在多种变体。其中有一种变体称为半同步/半反应堆（half-sync/half-reactive）模式。
![[Pasted image 20250214195729.png]]
图中，异步线程只有一个，由主线程来充当。它负责监听所有 socket 上的事件。如果监听 socket 上有可读事件发生，即有新的连接请求到来，主线程就接受之以得到新的连接 socket，然后往 epoll 内核事件表中注册该 socket 上的读写事件。如果连接 socket 上有读写事件发生，即有新的客户请求到来或有数据要发送至客户端，主线程就将该连接 socket 插入请求队列中。所有工作线程都睡眠在请求队列中，当有任务到来时，它们将通过竞争获得任务的接管权。

主线程插入请求队列中的任务是就绪的连接 socket。这说明该图所示的半同步/半反应堆模式采用的事件处理模式是 Reactor 模式：它要求工作线程自己从 socket 上读取客户请求和往 socket 写入服务器应答。这就是该模式的名称中“half-reactive”的含义。

half-sync/half-reactive 模式存在如下缺点：
- 主线程和工作线程共享请求队列。主线程往请求队列中添加任务，或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，从而白白耗费 CPU 时间。
- 每个工作线程在同一时间只能处理一个客户请求。如果客户数量较多，而工作线程较少，则请求队列中将堆积很多任务对象，客户端的响应速度将越来越慢。如果通过增加工作线程来解决这一问题，则工作线程的切换也将耗费大量 CPU 时间。
![[Pasted image 20250214200838.png]]
图 8-11 中，主线程只管理监听 socket，连接 socket 由工作线程来管理。当有新的连接到来时，主线程就接受之并将新返回的连接 socket 派发给某个工作线程，此后该新 socket 上的任何 I/O 操作都由被选中的工作线程来处理，直到客户关闭连接。主线程向工作线程派发 socket 的最简单的方式，是往它和工作线程之间的管道里写数据。工作线程检测到管道上有数据可读时，就分析是否是一个新的客户连接请求到来。如果是，则把该新 socket 上的读写事件注册到自己的 epoll 内核事件表中。

图 8-11 中，每个线程（主线程和工作线程）都维持自己的事件循环，它们各自独立地监听不同的事件。因此，在这种高效的半同步/半异步模式中，每个线程都工作在异步模式，所以它并非严格意义上的半同步/半异步模式。

## 8.5.2 领导者/追随者模式
领导者/追随者模式是多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件的一种模式。在任意时间点，程序都仅有一个领导者线程，它负责监听 I/O 事件。而其他线程则都是追随者，它们休眠在线程池中等待称为新的领导者。当前的领导者如果检测到 I/O 事件，首先要从线程池中推选出新的领导者线程，然后处理 I/O 事件。此时，新的领导者等待新的 I/O 事件，而原来的领导者则处理 I/O 事件，二者实现了并发。

领导者/追随者包含了如下几个组件：句柄集（HandleSet）、线程集（ThreadSet）、事件处理器（EventHandler）和具体的事件处理器（ConcreteEventHandler）。
![[Pasted image 20250217104428.png]]
1. 句柄集
句柄（Handle）用于表示 I/O 资源，在 Linux 下通常就是一个文件描述符。句柄集管理众多句柄。

2. 线程集
它负责各线程之间的同步，以及新领导者线程的推选。线程集中的线程在任一时间必处于如下三种状体之一：
- Leader：线程当前处于领导者身份，负责等待句柄集上的 I/O 事件。
- Processing：线程正在处理事件。
- Follower：通过调用线程集的 join 方法等待称为新的领导者，
![[Pasted image 20250217105017.png]]
3. 事件处理器和具体的事件处理器
![[Pasted image 20250217105136.png]]

# 8.6 有限状态机
逻辑单元内部的一种高效编程方法：有限状态机（finite state machine）。

有的应用层协议头部包含数据包类型字段，每种类型可以映射为逻辑单元的一种执行状态，服务器可以根据它来编写相应的处理逻辑。
![[Pasted image 20250217111459.png]]
状态之间的转移是需要状态机内部驱动的。

下面考虑有限状态机应用的一个实例：HTTP 请求的读取和分析。根据 HTTP 协议，HTTP 头部结束的依据是遇到一个空行，该空行仅包含一对回车换行符。

两个有限状态机，主从状态机：主状态机在内部调用从状态机。从状态机 parse_line 函数，它从 buffer 中解析出一个行。
![[Pasted image 20250217112123.png]]

# 8.7 提高服务器性能的其他建议
分析高性能服务器需要注意的其他几个方面：池、数据复制、上下文切换和锁

## 8.7.1 池
空间换时间，即浪费服务器的硬件资源，以换取其运行效率。这就是池（pool）的概念。池是一组资源的集合，这组资源在服务器启动之初就被完全创建好并初始化，这称为静态资源分配。当服务器进入正式运行阶段，即开始处理客户请求的时候，如果它需要相关的资源，就可以直接从池中获取，无须动态分配。很显然，直接从池中取得所需资源比动态分配资源的速度要快得多。当服务器处理完一个客户连接后，可以把相关的资源放回池中，无须执行系统调用来释放资源。从最终的效果来看，池相当于服务器管理资源的应用层设施，它避免了服务器对内核的频繁访问。

池可分为多种，常见的有内存池、进程池、线程池和连接池。它们的含义都很明确。

内存池通常用于 socket 的接收缓存和发送缓存。连接池通常用于服务器或服务器机群的内部永久连接。连接池是服务器预先和数据库程序建立的一组连接的集合。当某个逻辑单元需要访问数据库时，它可以直接从连接池中取得一个连接的实体并使用之。

## 8.7.2 数据复制


## 8.7.3 上下文切换和锁
进程切换或线程切换导致的系统开销。