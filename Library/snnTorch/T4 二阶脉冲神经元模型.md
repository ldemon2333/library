学习跟先进的LIF神经元模型：Synaptic 和 Alpha

# 1.基于突触电导的LIF神经元模型
之前的神经元模型假设输入电压尖峰导致突触电流的瞬时突触电流的瞬时跳跃，然后有助于膜电位产生。实际上，脉冲会导致神经递质从突触前神经元逐渐释放到突触后神经元。基于突触电导的LIF模型考虑了输入电流的时序渐进动态特性。

## 1.1突触电流建模
如果突触前神经元放电，电压尖峰就会传递到神经元的轴突。它触发小泡释放神经递质到突触间隙。这会激活突触后受体，直接影响流入突触后神经元的有效电流。下面显示的是两种兴奋性受体，AMPA和NMDA。
![[Pasted image 20241011170421.png]]
最简单的突触电流模型假设电流在非常快的时间尺度上增加，然后是相对缓慢的指数衰减，如上面的AMPA受体反应所示。这与Lapicque模型的膜电位动力学非常相似。

突触模型有两个指数衰减项$I_{\rm syn}(t)$ 和 $U_{\rm mem}(t)$。将$I_{\rm syn}(t)$的后续项之间的比率(即衰减率)设置为$\alpha$，将$U(t)$的后续项之间的比率设置为$\beta$
$$ \alpha = e^{-\Delta t/\tau_{\rm syn}}$$
$$ \beta = e^{-\Delta t/\tau_{\rm mem}}$$
其中，单个时间步长的持续时间在未来被规范为$\Delta t = 1$。$\tau_{\rm syn}$模拟突触电流的时间常数，类似于$\tau_{\rm mem}$模拟膜电位的时间常数。$\beta$的推导方法与上一节完全相同，与$\alpha$的推导方法类似：
$$I_{\rm syn}[t+1]=\underbrace{\alpha I_{\rm syn}[t]}_\text{decay} + \underbrace{WX[t+1]}_\text{input}$$
$$U[t+1] = \underbrace{\beta U[t]}_\text{decay} + \underbrace{I_{\rm syn}[t+1]}_\text{input} - \underbrace{R[t]}_\text{reset}$$
与之前的LIF神经元相同的脉冲条件任然成立：
$$S_{\rm out}[t] = \begin{cases} 1, &\text{if}~U[t] > U_{\rm thr} \\

0, &\text{otherwise}\end{cases}$$

## 1.2 snntorch中的突触神经元模型
基于突触电导的神经元模型将突触电流动力学与被动式膜相结合。它必须用两个输入参数实例化：
* $\alpha$: 突触电流衰减率
* $\beta$: 膜电位衰减率(如Lapicque)
```python3
# Temporal dynamics
alpha = 0.9
beta = 0.8
num_steps = 200

# Initialize 2nd-order LIF neuron
lif1 = snn.Synaptic(alpha=alpha, beta=beta)
```
使用这个神经元与之前的LIF神经元完全相同，但现在添加了突触电流syn作为输入和输出：
**Inputs**

* `spk_in`: each weighted input voltage spike $WX[t]$ is sequentially passed in

* `syn`: synaptic current $I_{\rm syn}[t-1]$ at the previous time step

* `mem`: membrane potential $U[t-1]$ at the previous time step

**Outputs**

* `spk_out`: output spike $S[t]$ ('1' if there is a spike; '0' if there is no spike)

* `syn`: synaptic current $I_{\rm syn}[t]$ at the present time step

* `mem`: membrane potential $U[t]$ at the present time step

这些都是torch.Tensor类型。请注意，神经元模型在时间是后退了一步，但不失一般性。

应用周期性脉冲输入，观察电流和膜是如何随时间变化的：
```text
# Periodic spiking input, spk_in = 0.2 V
w = 0.2
spk_period = torch.cat((torch.ones(1)*w, torch.zeros(9)), 0)
spk_in = spk_period.repeat(20)

# Initialize hidden states and output
syn, mem = lif1.init_synaptic()
spk_out = torch.zeros(1) 
syn_rec = []
mem_rec = []
spk_rec = []

# Simulate neurons
for step in range(num_steps):
  spk_out, syn, mem = lif1(spk_in[step], syn, mem)
  spk_rec.append(spk_out)
  syn_rec.append(syn)
  mem_rec.append(mem)

# convert lists to tensors
spk_rec = torch.stack(spk_rec)
syn_rec = torch.stack(syn_rec)
mem_rec = torch.stack(mem_rec)

plot_spk_cur_mem_spk(spk_in, syn_rec, mem_rec, spk_rec, 
                     "Synaptic Conductance-based Neuron Model With Input Spikes")
```
![[Pasted image 20241011172654.png]]
这个模型还有可选的输入参数`reset_mechanism`和`threshold`，正如Lapicque的神经元模型所描述的那样。总之，每个脉冲都对突触电流$I_{\rm syn}$产生了移位的指数衰减，该电流然后被之前教程中导出的被动式膜方程积分，从而产生输出尖峰。
![[Pasted image 20241011173032.png]]

## 1.3 一阶神经元与二阶神经元的对比
一个很自然的问题是-**_何时使用一阶LIF神经元，何时使用二阶LIF神经元?_** 虽然这个问题还没有真正解决，但我自己的实验给了我一些可能有用的直觉。

**当二阶神经元更好的时候**
- 如果输入数据的时间关系发生在很长的时间尺度上，
- 或者输入脉冲模式是否稀疏

通过具有两个具有两个衰减项的递归方程，该神经元模型能够在较长时间内“维持”输入峰值。这对保存长期关系是有益的。

另一种用例可能是：

**当时序编码很重要时**

如果你关心脉冲的精确时间，对于二阶神经元来说，控制它似乎更容易。在`Leaky`模型中，脉冲将与输入直接同步触发。对于二阶模型，膜电位被“平滑”(即突触电流模型低通滤除膜电位)，这意味着$U[t]$经历有限的上升时间。这在之前的模拟中很明显，输出峰值相对于输入峰值有延迟。

**什么时候一阶神经元更好**

- 任何不属于上述情况的情况，有时是上述情况。

通过在一阶神经元模型(如Leaky)中减少一个方程，反向传播过程变得更简单。尽管如此，当$\alpha=0$，Synaptic模型在功能上等同于Leaky。在我自己对简单数据集的超参数扫描中，最佳结果似乎使$\alpha=0$尽可能接近0。随着数据复杂性的增加，$\alpha=0$可能会变大。

# 2.$\alpha$神经元模型（hacked spike response model）
还有一种脉冲响应模型（SRM）的递归版本，即“Alpha”神经元，称为“snn.Alpha"。迄今为止，神经元模型都是基于被动式膜模型，用常微分方程来描述它们的动力学。

另一方面，SRM模型家族使用滤波器来解释的。当输入脉冲到达时。该脉冲与滤波器卷积以产生膜电位响应。这个滤波器的形式可以是指数形式，就像Lapicque神经元的情况一样，也可以是更复杂的形式，比如指数的和。SRM模型很有吸引力，因为它们可以简单地将其嵌入滤波器中，从而任意添加耐火度、阈值自适应和任何数量的其他特征。


## 2.1 建立Alpha神经元模型
形式上，这个过程表示为：
$$U_{\rm mem}(t) = \sum_i W(\epsilon * S_{\rm in})(t)$$
其中传入的峰值$S_{\rm in}$与峰值响应内核$\epsilon( \cdot )$卷积。脉冲反应按突触权重$W$进行缩放。在上图中，左核是一个指数衰减函数，相当于Lapicque的一阶神经元模型。在右边，内核是一个alpha函数：
$$\epsilon(t) = \frac{t}{\tau}e^{1-t/\tau}\Theta(t)$$
其中$\tau$是alpha核的时间常数，$\Theta$是Heaviside阶跃函数。大多数基于核的方法采用alpha函数，因为它提供了一个时间延迟，对于指定神经元的确切脉冲时间的时间编码很有用。

在snnTorch中，脉冲响应模型不是直接作为滤波器实现的。相反，它被重新转换为递归形式，这样只需要前一个时间步值来计算下一组值。这大大减少了学习期间的内存开销。
![[Pasted image 20241011175023.png]]
因为膜电位现在是由两个指数之和决定的，每个指数都有自己独立的衰减率。 $α$ 定义了正指数的衰减率， $β$ 定义了负指数的衰减率。

```text
alpha = 0.8
beta = 0.7

# initialize neuron
lif2 = snn.Alpha(alpha=alpha, beta=beta, threshold=0.5)
```

使用这个神经元和之前的神经元一样，但是两个指数函数的和需要将突触电流`syn`分成`syn_exc`和`syn_inh`两个部分:

**Inputs**

* `spk_in`: each weighted input voltage spike $WX[t]$ is sequentially passed in

* `syn_exc`: excitatory post-synaptic current $I_{\rm syn-exc}[t-1]$ at the previous time step，上一个时间步的兴奋性突触后电流

* `syn_inh`: inhibitory post-synaptic current $I_{\rm syn-inh}[t-1]$ at the previous time step，上一个时间步的突触后抑制电流

* `mem`: membrane potential $U_{\rm mem}[t-1]$ at the present time $t$ at the previous time step

**Outputs**

* `spk_out`: output spike $S_{\rm out}[t]$ at the present time step ('1' if there is a spike; '0' if there is no spike)

* `syn_exc`: excitatory post-synaptic $I_{\rm syn-exc}[t]$ at the present time step $t$，兴奋性突触后电流

* `syn_inh`: inhibitory post-synaptic current $I_{\rm syn-inh}[t]$ at the present time step $t$

* `mem`: membrane potential $U_{\rm mem}[t]$ at the present time step

```text
# input spike: initial spike, and then period spiking 
w = 0.85
spk_in = (torch.cat((torch.zeros(10), torch.ones(1), torch.zeros(89), 
                     (torch.cat((torch.ones(1), torch.zeros(9)),0).repeat(10))), 0) * w).unsqueeze(1)

# initialize parameters
syn_exc, syn_inh, mem = lif2.init_alpha()
mem_rec = []
spk_rec = []

# run simulation
for step in range(num_steps):
  spk_out, syn_exc, syn_inh, mem = lif2(spk_in[step], syn_exc, syn_inh, mem)
  mem_rec.append(mem.squeeze(0))
  spk_rec.append(spk_out.squeeze(0))

# convert lists to tensors
mem_rec = torch.stack(mem_rec)
spk_rec = torch.stack(spk_rec)

plot_spk_mem_spk(spk_in, mem_rec, spk_rec, "Alpha Neuron Model With Input Spikes")
```
![[Pasted image 20241011175450.png]]

## 2.2 实际考虑
正如前面提到的突触神经元，模型越复杂，训练过程中的反向传播过程就越复杂。在我自己的实验中，我还没有找到Alpha神经元优于突触和泄漏神经元模型的案例。似乎通过正指数和负指数学习只会使梯度计算过程更加困难，并抵消了更复杂的神经元动力学中的任何潜在好处。

然而，当SRM模型表示为时变核(而不是这里所做的递归模型)时，它的性能似乎与更简单的神经元模型一样好。举个例子，请看下面的文章:

> [*Sumit Bam Shrestha and Garrick Orchard, "SLAYER: Spike layer error reassignment in time", Proceedings of the 32nd International Conference on Neural Information Processing Systems, pp. 1419-1328, 2018.*](https://arxiv.org/abs/1810.08646)

引入Alpha神经元的目的是为跨基于srm的模型移植到snnTorch提供一种选择，尽管在这里原生训练它们似乎不是太有效。

# 结论
我们已经介绍了snnTorch中可用的所有LIF神经元模型。快速总结一下:

- Lapicque:直接基于rc电路参数的物理精确模型
- Leaky:简化的一阶模型
- 突触:解释突触电流演化的二阶模型
- Alpha:膜电位跟踪Alpha函数的二阶模型

一般来说，“Leaky”和“Synaptic”似乎在训练网络时最有用。“Lapicque”有利于展示物理上精确的模型，而“Alpha”仅旨在捕捉SRM神经元的行为。


# 神经突触的动力学模型
突触的传递是神经科学领域重要的问题。神经元的突触用来传递上面一级神经元的激活或抑制信号，但是突触不是一个简单的传递路径，突触还有一些较为复杂的特性，突触还有一些较为复杂的特性，比如细胞都具有的电活动被动特性，突触的输入累积方式和其动态特性。

# 突触模型的两种基本思路
突触输入有两种基本的建模方法，分别是：
1）基于电流的建模（current-based）
2）基于导纳的建模（conductance-based）

首先来说比较基本的基于电流的建模，基于电流的突触建模忽略了突触后电压对突触的影响，只考虑外部输入的和，公式如下：
$$
I_{\rm syn} = \sum_{i=1}^MJ_is_i
$$
在这里总共有M个突触输入，$s_i$代表gating，作为这个突触接受外部的输入，在突触前膜发放spike的时候会被提高。$J_i$是这个突触输入的权重。这个公式给出了总的突触传入造成的输入电流。

如果更详细一点的考虑到突触后神经元的状态（电压）的话，那就是基于导纳的模型，每个突触输入的公式则是$I_{\rm syn} = g_{\rm syn}s(V-E_{\rm syn})$，在这里，$g_{\rm syn}$是这个突触最大的导纳，受到gating s的调控，也受到突触后膜电压波动$V-E_{\rm syn}$的影响。如果在考虑到有很多突触的输入，每个突触的权重为$W_i$，总的$I_{\rm syn}$则为：
$$
I_{\rm syn} = \sum_{i=1}^MW_ig_{\rm syn}s_i(V-E_{\rm syn})
$$


