GNN处理非结构化数据时的出色能力使其在网络数据分布、推荐系统、物理建模、自然语言处理和图上的组合优化问题。

# 1. 为什么需要图神经网络
处理非结构化事物，例如社交网络、知识图谱

相比于简单的文本和图像，这种网络类型的非结构化的数据非常复杂，处理它的难点包括：

1. 图的大小是任意的，图的拓扑结构复杂，没有像图像一样的空间局部性
2. 图没有固定的节点顺序，或者说没有一个参考节点
3. 图经常是动态图，而且包含多模态的特征，看上去不一样的图，可能有相同的邻接表
4. 图存在于非欧几里得空间，它不存在于2D或3D空间

那么对于这类数据我们该如何建模呢？能否将深度学习进行扩展使得能够建模该类数据呢？这些问题促使了图神经网络的出现与发展。

# 2.图神经网络是什么样子的

## 2.1 图神经网络的基本概念
每个节点都有一组定义它的特征。在社交网络图的案例中，这些特征可以是年龄、性别、居住国家、政治倾向等。每条边连接的节点都可能具有相似的特征。这体现了这些节点之间的某种相关性或关系。

假设我们有一个图 G，其具有以下顶点和边：

![[Pasted image 20240925185017.png]]
为了简单起见，假设图节点的特征向量是当前节点的索引的one-hot编码。类似地，其标签（或类别）可设为节点的颜色（绿、红、黄）。那么这个图看起来会是这样：

![[Pasted image 20240925185049.png]]



![[Pasted image 20240925184241.png]]
因此一个比较常见的图神经网络的应用模式如下图（图4），输入是一个图，经过多层图卷积等各种操作以及激活函数，最终得到各个节点的表示，以便于进行节点分类、链接预测、图与子图的生成等等任务。
![[Pasted image 20240925184410.png]]

# 3. 什么是GNN
受CNN和图嵌入影响，GNN用来预测点，边和基于图的任务。

- **CNN** 用于图像分类。同样，GNN 应用于图形结构（像素网格）以预测类别。
-  **RNN** 被用来文本分类，GNN也可以用来图结构的文本分类，把单词看作一个节点。
![[Pasted image 20240925190901.png]]
输入图通过一系列神经网络。输入图结构被转换为图嵌入，允许我们维护有关节点、边和全局上下文的信息。

然后，节点A和C的特征向量通过神经网络。它聚合了这些特征并将它们传递到下一层。

# 4. GNN类型
- **GCNs**，图卷积神经网络，类似于CNNs。它通过观察它邻居节点来学习特征。GNNs聚合节点向量，将结果传递给dense layer。它包括Graph convolution, linear layer and non-linear activation function。- There are two major types of GCNs: Spatial Convolutional Networks and Spectral Convolutional Networks.
- **Graph Auto-Encoder Networks** learn graph representation using an encoder and attempt to reconstruct input graphs using a decoder. The encoder and decoders are joined by a bottleneck layer. They are commonly used in link prediction as Auto-Encoders are good at dealing with class balance. 
- **Recurrent Graph Neural Networks(RGNNs)** learn the best diffusion pattern, and they can handle multi-relational graphs where a single node has multiple relations. This type of graph neural network uses regularizers to boost smoothness and eliminate over-parameterization. RGNNs use less computation power to produce better results. They are used in generating text, machine translation, speech recognition, generating image descriptions, video tagging, and text summarization.
- **Gated Graph Neural Networks (GGNNs)** are better than the RGNNs in performing tasks with long-term dependencies. Gated Graph Neural Networks improve Recurrent Graph Neural Networks by adding a node, edge, and time gates on long-term dependencies. Similar to Gated Recurrent Units (GRUs), the gates are used to remember and forget information in different states.


# 5. GNN任务
- 图分类
- 节点分类
- Link Prediction：预测邻接矩阵不完整的图中一对节点之间的联系
- 社区检测：根据边缘结构将节点划分为各种集群。它以类似的方式从 edge weights、distance 和 graph 对象中学习。
- Graph Embedding：将图像映射到向量中，保留有关节点、边和结构的相关信息
- Graph Generation：从示例图形分布中学习，以生成新的但相似的图形结构
![[Pasted image 20240925191826.png]]

# 6.GNN缺点
1. GNNs是浅层网络，通常只有3层，这限制了在大数据集上达到最优性能
2. 图结构不断在变，训练一个模型很难
3. 将模型部署到生产环境会面临**可扩展性问题**，因为这些网络的计算成本很高。如果您有一个大型且复杂的图形结构，则很难在生产中扩展 GNN。

# 7. 什么是GCN？
GCN和CNN之间的主要区别在于，它是为处理节点和边的顺序可以变化的非欧几里得数据结构开发的。

GCN有两种类型：
- 空间图卷积网络，使用空间特征，空间中的学习
- 谱图卷积网络，使用Laplacian矩阵的特征分解来沿节点传播信息


## Planetoid Cora Dataset
Planetoid 是一个引用网络数据集，节点是具有1433维bag-of-words特征向量的文献，边是研究论文的引用链接，有7个类，我们将训练模型来预测丢失的标签。
```py
from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures

dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())

print(f'Dataset: {dataset}:')
print('======================')
print(f'Number of graphs: {len(dataset)}')
print(f'Number of features: {dataset.num_features}')
print(f'Number of classes: {dataset.num_classes}')

data = dataset[0]  # Get the first graph object.
print(data)
```
Cora 数据集有2708个节点，10556条边，1433个features和7 classes。第一个图有2708个训练集，验证集和测试集masks
```
Dataset: Cora():
======================
Number of graphs: 1
Number of features: 1433
Number of classes: 7
Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])
```

1. **`x=[2708, 1433]`**:
   - 这是一个节点特征矩阵，其中 `2708` 表示节点的数量（Cora 数据集中的论文数量），`1433` 表示每个节点的特征维度（每篇论文的特征数）。所以，`x` 是一个形状为 `(2708, 1433)` 的张量，包含每篇论文的特征。

2. **`edge_index=[2, 10556]`**:
   - 这是一个边索引矩阵，描述了图中节点之间的连接关系。它的形状为 `(2, 10556)`，其中 `2` 表示每条边需要两个端点（源节点和目标节点），`10556` 表示边的数量。在这个矩阵中，第一行存储源节点的索引，第二行存储目标节点的索引。

3. **`y=[2708]`**:
   - 这是一个节点标签向量，包含每个节点（论文）的类别标签。形状为 `(2708,)`，每个元素表示对应节点的标签，例如，论文的领域类别。

4. **`train_mask=[2708]`**:
   - 这是一个布尔向量，用于指示哪些节点用于训练。它的形状为 `(2708,)`，其中 `True` 表示该节点将用于训练，`False` 表示不用于训练。

5. **`val_mask=[2708]`**:
   - 这是一个布尔向量，用于指示哪些节点用于验证。形状同样为 `(2708,)`，`True` 表示该节点将用于验证。

6. **`test_mask=[2708]`**:
   - 这是一个布尔向量，用于指示哪些节点用于测试。形状也是 `(2708,)`，`True` 表示该节点将用于测试。


## Cora 数据集编码
每篇论文的特征通常是通过 **词袋模型**（Bag of Words, BoW）或 **TF-IDF**（Term Frequency-Inverse Document Frequency）来编码的。具体编码方式如下：

### 1. 词袋模型（BoW）

- **定义**: 词袋模型将文本视为一个词的集合，而不考虑词的顺序。
- **过程**:
  - 首先，从所有论文中提取出所有唯一的单词，形成一个词汇表。
  - 对于每篇论文，创建一个特征向量，向量的每个维度对应于词汇表中的一个单词。
  - 如果某个单词在该论文中出现，则对应的特征值为 1；否则为 0。

### 2. TF-IDF

- **定义**: TF-IDF 是一种用于文本挖掘的加权方法，考虑了词在文档中的频率以及在整个语料库中的重要性。
- **过程**:
  - 计算每个单词在论文中的出现频率（Term Frequency, TF）。
  - 计算每个单词在整个文档集中的逆文档频率（Inverse Document Frequency, IDF）。
  - 对每篇论文的特征向量使用 TF-IDF 权重进行编码：每个特征的值为该单词在该论文中的 TF 与该单词的 IDF 的乘积。

### 特征矩阵示例

假设词汇表包含以下单词：`[“network”, “learning”, “graph”, “data”]`，则特征矩阵可能如下：

| 论文编号 | 网络 | 学习 | 图 | 数据 |
|----------|------|------|----|------|
| 0        | 1    | 0    | 1  | 0    |
| 1        | 0    | 1    | 0  | 1    |
| 2        | 1    | 1    | 1  | 1    |

在这个示例中，每个论文的特征向量长度为 4，表示词汇表的大小。

### 特征归一化

在加载数据集时，使用 `NormalizeFeatures()` 进行行归一化，可以使每行归一化。

## 节点分类
我们将会设计GCN模型包含两个GCN卷积层+relu函数，dropout=0.5，模型包含16个hidden channels.

GCN layer:
![[Pasted image 20240925195832.png]]
```
from torch_geometric.nn import GCNConv
import torch.nn.functional as F

class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

model = GCN(hidden_channels=16)
print(model)

```



## GCNConv 的实现

对于每个节点 $i$，GCN 的卷积操作可以表示为：

$$
H^{(l+1)} = \sigma\left(\tilde{A} H^{(l)} W^{(l)}\right)
$$

其中：
- $H^{(l)}$ 是第 $l$ 层的节点特征矩阵。
- $W^{(l)}$ 是第 $l$ 层的权重矩阵。
- $\tilde{A}$ 是邻接矩阵的归一化版本。
- $\sigma$ 是激活函数（如 ReLU）。

### forward方法解析
`forward` 方法负责接收输入特征和边索引，执行图卷积操作，并返回更新后的节点特征。主要步骤包括：

1. **添加自环**：确保每个节点能考虑自己的特征。
2. **计算归一化因子**：用于后续的消息传递。
3. **调用消息传递机制**：执行节点特征的聚合。

#### 示例实现

以下是 `GCNConv` 的 `forward` 方法的实现示例：

```python
def forward(self, x, edge_index):
    # 添加自环
    edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

    # 计算归一化邻接矩阵的权重
    row, col = edge_index
    deg = torch.bincount(row)  # 计算每个节点的度
    deg_inv_sqrt = deg.pow(-0.5)  # 计算度的平方根倒数
    norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]  # 归一化因子

    # 进行消息传递
    x = self.propagate(edge_index, x=x, norm=norm)

    # 返回更新后的节点特征
    return x
```

#### 关键步骤详解

1. **添加自环**:
   ```python
   edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))
   ```
   - 这一步确保每个节点可以接收自身的特征，有助于防止信息丢失。

2. **计算度**:
   ```python
   row, col = edge_index
   deg = torch.bincount(row)
   ```
   - 计算每个节点的度（即它连接的边的数量），用于后续的归一化。

3. **计算归一化因子**:
   ```python
   deg_inv_sqrt = deg.pow(-0.5)
   norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]
   ```
   - 通过度的平方根的倒数进行归一化，以确保信息传递时不受节点连接数的影响。

4. **消息传递**:
   ```python
   x = self.propagate(edge_index, x=x, norm=norm)
   ```
   - `propagate` 方法会处理消息的聚合，调用 `message` 方法进行特征的加权聚合。

#### 返回值

`forward` 方法返回的是更新后的节点特征矩阵 \(x\)，它包含了通过图卷积操作得到的新特征。

### `edge_index`要求
用于表示图结构的边索引矩阵。它的要求和格式如下：

1. **形状**: 
   - `edge_index` 应该是一个形状为 `[2, num_edges]` 的张量，其中 `num_edges` 是图中边的数量。
   - 第一行表示源节点的索引，第二行表示目标节点的索引。

   例如，对于边 \((0 \to 1)\) 和 \((1 \to 2)\)，`edge_index` 应该如下：

   ```
   edge_index = [[0, 1],
                 [1, 2]]
   ```

2. **数据类型**:
   - 通常为 `torch.long` 类型，以便可以表示大范围的节点索引。

3. **自环**:
   - 如果需要，`edge_index` 可以包含自环（即节点指向自身的边）。例如，节点 0 的自环可以表示为 \((0 \to 0)\)。

4. **无向边**:
   - 对于无向图，每条边 \((i \to j)\) 需要在 `edge_index` 中同时表示为 \((i \to j)\) 和 \((j \to i)\)。

#### 使用

在使用图卷积网络（如 `GCNConv`）时，`edge_index` 将与节点特征矩阵一起传入模型的 `forward` 方法，以便模型能够访问图的结构信息。

# 小结
图神经网络用作什么？
- 训练图神经网络去预测节点，边和图相关的任务。比如图分类，节点分类，链接预测，图聚类，图生成，图片和文本分类。



