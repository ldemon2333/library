Kubernetes项目的这个变革的效果立竿见影，很快在整个容器社区中催生出了大量的、基于Kubernetes API和扩展接口的二次创新工作，比如：

- 目前热度极高的微服务治理项目Istio；
- 被广泛采用的有状态应用部署框架Operator；
- 还有像Rook这样的开源创业项目，它通过Kubernetes的可扩展接口，把Ceph这样的重量级产品封装成了简单易用的容器存储插件。

# 从进程说起
- 容器技术的兴起源于PaaS技术的普及；
- Docker公司发布的Docker项目具有里程碑式的意义；
- Docker项目通过“容器镜像”，解决了应用打包这个根本性难题。

紧接着，我详细介绍了容器技术圈在过去五年里的“风云变幻”，而通过这部分内容，我希望你能理解这样一个道理：

> 容器本身没有价值，有价值的是“容器编排”。

也正因为如此，容器技术生态才爆发了一场关于“容器编排”的“战争”。而这次战争，最终以Kubernetes项目和CNCF社区的胜利而告终。所以，这个专栏后面的内容，我会以Docker和Kubernetes项目为核心，为你详细介绍容器技术的各项实践与其中的原理。

所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。

而**容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。**

对于Docker等大多数Linux容器来说，**Cgroups技术**是用来制造约束的主要手段，而**Namespace技术**则是用来修改进程视图的主要方法。

尽管你可以在容器里通过Mount Namespace单独挂载其他不同版本的操作系统文件，比如CentOS或者Ubuntu，但这并不能改变共享宿主机内核的事实。这意味着，如果你要在Windows宿主机上运行Linux容器，或者在低版本的Linux宿主机上运行高版本的Linux容器，都是行不通的。

其次，在Linux内核中，有很多资源和对象是不能被Namespace化的，最典型的例子就是：时间。

这就意味着，如果你的容器中的程序使用settimeofday(2)系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。

更为棘手的是，尽管在实践中我们确实可以使用Seccomp等技术，对容器内部发起的所有系统调用进行过滤和甄别来进行安全加固，但这种方法因为多了一层对系统调用的过滤，必然会拖累容器的性能。何况，默认情况下，谁也不知道到底该开启哪些系统调用，禁止哪些系统调用。

**Linux Cgroups的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合**。而对于Docker等Linux容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的PID填写到对应控制组的tasks文件中就可以了。

而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行docker run时的参数指定了，比如这样一条命令：

```
docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash
```

这也是容器技术中一个非常重要的概念，即：**容器是一个“单进程”模型。**

# 深入理解容器镜像
可能你立刻就能想到，这一定是一个关于Mount Namespace的问题：容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如/tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。

**Mount Namespace修改的，是容器进程对文件系统“挂载点”的认知**。但是，这也就意味着，只有在“挂载”这个操作发生之后，进程的视图才会被改变。而在此之前，新创建的容器会直接继承宿主机的各个挂载点。

**这就是Mount Namespace跟其他Namespace的使用略有不同的地方：它对容器进程视图的改变，一定是伴随着挂载操作（mount）才能生效。**

可是，作为一个普通用户，我们希望的是一个更友好的情况：每当创建一个新容器时，我希望容器进程看到的文件系统就是一个独立的隔离环境，而不是继承自宿主机的文件系统。怎么才能做到这一点呢？

不难想到，我们可以在容器进程启动之前重新挂载它的整个根目录“/”。而由于Mount Namespace的存在，这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。

在Linux操作系统里，有一个名为chroot的命令可以帮助你在shell中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。

**实际上，Mount Namespace正是基于对chroot的不断改良才被发明出来的，它也是Linux操作系统里的第一个Namespace。**

**而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。**

现在，你应该可以理解，对Docker项目来说，它最核心的原理实际上就是为待创建的用户进程：
1. 启用Linux Namespace配置；
    
2. 设置指定的Cgroups参数；
    
3. 切换进程的根目录（Change Root）。

这样，一个完整的容器就诞生了。不过，Docker项目在最后一步的切换上会优先使用pivot_root系统调用，如果系统不支持，才会使用chroot。这两个系统调用虽然功能类似，但是也有细微的区别，这一部分小知识就交给你课后去探索了。

`pivot_root` 和 `chroot` 都是 Linux 中用来改变进程视角下“根文件系统”的工具，但它们的用途、实现层次和能力存在本质区别。

---

### ✅ 简要区别对比

|特性|`chroot`|`pivot_root`|
|---|---|---|
|改变根目录|✅（仅改变当前进程及其子进程的视角）|✅（系统级更改，真正“挂载”新的根）|
|原根目录处理|❌（原来的根仍然挂着，无法访问需要技巧）|✅（可以挂载旧根到新根下指定位置）|
|作用范围|用户空间（用户态进程）|内核空间（必须是 root，影响整个挂载树）|
|常用场景|chroot jail、安全沙箱、临时隔离环境|容器技术（如 Docker）、initramfs 切换根|
|是否需要挂载支持|❌（直接修改目录引用）|✅（需要配合挂载新的文件系统）|
|是否彻底切换根文件系统|❌（只是“伪”切换）|✅（真正把根目录指向新的挂载点）|

---

### 🔍 `chroot`：简单的“视图”隔离

- `chroot /newroot` 是系统调用，通常用于把当前进程的“根目录”更改为某个子目录。
    
- 只改变**当前进程及子进程的文件路径解释**。
    
- 原根目录依然存在，可通过 open fd、`/proc/self/fd/` 等方法逃逸，**不安全**。
    
- 主要用于测试、构建、沙箱环境（如 `debootstrap` 创建 Debian 系统）。
    

```bash
chroot /my/newroot /bin/bash
```

---

### 🔍 `pivot_root`：真正的“系统根替换”

- `pivot_root(new_root, put_old)`：把当前挂载的根切换到 `new_root`，并把原根移动到 `put_old`。
    
- 是真正的挂载点切换（根文件系统级别切换），需要 `CAP_SYS_ADMIN` 权限。
    
- 常用于容器启动时替换 `initramfs` 为实际根文件系统。
    
- 比 `chroot` 更底层，也更安全、完整。
    

```c
int pivot_root(const char *new_root, const char *put_old);
```

条件限制：

- `new_root` 和 `put_old` 必须是挂载点。
    
- `put_old` 必须是 `new_root` 的子目录。
    

---

### 🧠 举例说明

#### 容器初始化：

1. 容器 init 进程挂载了 overlay 文件系统到 `/newroot`。
    
2. 执行：
    
    ```c
    mount --bind /newroot /newroot
    cd /newroot
    mkdir old_root
    pivot_root(".", "old_root");
    umount -l /old_root
    ```
    
3. 此时 `/` 是新的容器根，原系统根已经脱离，**无法轻易访问或逃逸**。
    

---

### 🔐 安全性比较

- `chroot`：容易逃逸，不应视为安全隔离手段。
    
- `pivot_root`：结合 mount namespace、cgroup、seccomp 等才是现代容器真正的“隔离墙”。
    

不过，**正是由于rootfs的存在，容器才有了一个被反复宣传至今的重要特性：一致性。**

**由于rootfs里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。**

事实上，对于大多数开发者而言，他们对应用依赖的理解，一直局限在编程语言层面。比如Golang的Godeps.json。但实际上，一个一直以来很容易被忽视的事实是，**对一个应用来说，操作系统本身才是它运行所需要的最完整的“依赖库”。**

那么，既然这些修改都基于一个旧的rootfs，我们能不能以增量的方式去做这些修改呢？这样做的好处是，所有人都只需要维护相对于base rootfs修改的增量内容，而不是每次修改都制造一个“fork”。

答案当然是肯定的。

这也正是为何，Docker公司在实现Docker镜像时并没有沿用以前制作rootfs的标准流程，而是做了一个小小的创新：

> Docker在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量rootfs。

当然，这个想法不是凭空臆造出来的，而是用到了一种叫作联合文件系统（Union File System）的能力。

