随着半导体产业的发展，芯片的工艺尺寸已经达到纳米级，冯·诺依曼架构固有的“存储墙”和“功耗墙”问题日益突出。人脑作为一个抽象的计算系统，具有非常高的并行计算能力（同时进行视觉识别、推理、肢体控制和运动），但能耗却很低（约20W）。人脑的计算原理与冯·诺依曼计算机有两点显著不同：首先，人脑拥有数十亿个神经元通过数万亿个突触相互连接的网络。神经元是大脑的计算原元素，通过离散的动作电位或脉冲进行信息交换或传递，突触是记忆和学习的存储元素。人脑通过神经元和突触将计算和存储统一起来，解决了记忆墙问题。其次，大脑中的神经元通过事件驱动或时间相关的脉冲传递信息。基于脉冲的时间处理允许大脑中进行稀疏且高效的信息传输，从而实现令人印象深刻的低功耗，
解决了功率墙问题。

脉冲神经网络（SNN）如图 1 所示，属于第三代神经网络，是脑启发计算领域最具代表性的概念。SNN 在神经元和突触连接模型方面模仿大脑，具有丰富的时空信息、事件驱动和高度的生物可信度。

由于脑启发式计算机硬件资源规模庞大、复杂度高，如何有效管理和利用这些资源一直是尚未解决的难题。海德堡大学开发的 BrainScaleS 操作系统 (OS)为 BrainScaleS 系统提供了软件开发和运行环境。英国曼彻斯特大学为 SpiNNaker 系统发起的软件系统包括在 SpiNNaker 系统上执行的软件程序和软件工具链 SpiNNTools。IBM 围绕其 TrueNorth 芯片建立了相对完整的软件生态系统，涵盖系统、软件、应用程序和其他方面。英特尔的 Loihi 开发工具链设计了基于 Python 的应用程序编程接口、编译器、运行时、软件模拟器和现场可编程门阵列 (FPGA) 仿真器。

各类类脑计算系统的软件相关工作主要集中在训练、模型转换、映射、模拟器等方面，而所有软件系统对运行环境的支持都只是从运行库或传统OS的角度考虑（如TrueNorth采用Linux系统，SpiNNaker采用实时OS），因此我们提出了一个更完整、更简洁的软件参考架构——Darwin-S，它涉及一个类脑OS和一个集成开发环境（IDE）

![[Pasted image 20241029103744.png]]

# 脑启发计算机的参考软件架构
Darwin-S旨在为类脑计算机提供应用开发和运行参考架构，使研究人员无需了解底层硬件的实现细节即可开发应用。类脑计算机的应用主要包括脉冲编解码过程和SNN。脉冲编解码过程将输入数据（如图像）编码为脉冲序列，并解码输出脉冲序列。SNN通过其内部的多层神经元处理脉冲，并通过输出层将结果脉冲发送出去。Darwin-S包含一个支持应用程序开发的IDE和一个为应用程序提供运行环境的OS。

层次化和模块化的思想可以很好地实现软件架构之间的解耦，右层抽象使得层次结构之间的实现细节相互透明，带来了良好的可扩展性和兼容性，如图2所示。
![[Pasted image 20241029104538.png]]

## A general-purpose architecture
Darwin-S 的设计目标是适用于不同的底层硬件架构，这种通用性从根本上基于我们对脑启发式计算机的抽象。不同的脑启发式硬件平台的架构和实现方法完全不同。然而，基本的设计原则是相同的：
- 使用大量专门设计的神经突触核心（例如，Loihi 和 TrueNorth 上的交叉开关，以及 SpiNNaker 上的 ARM 核心）
- simulating neurons dynamics in parallel
- storing synapses’ weight data within or near each neurosynaptic core
- neurosynaptic cores switch spiking messages through specially designed connection paths (for example, networks on chip or Ethernet).

基于这些受脑启发的计算机的共同特点，我们进行了两次关键尝试来实现硬件解耦，具体如下：

首先，我们在类脑操作系统中采用了硬件抽象层来屏蔽类脑计算机的硬件差异，并将硬件抽象为存储、通信和神经资源三个部分。其次，在类脑应用程序IDE中引入了描述上层SNN的中间模型定义语言，使下层实现对上层开发环境完全透明。

## Brain-inspired OS
与传统计算机系统软件中的任务和资源概念相比，我们将类脑计算机上运行的SNN定义为神经任务，相应地，神经元和突触被称为神经资源，因此类脑操作系统是一个为神经任务运行和神经资源管理而定制的软件系统。

从硬件角度看，OS实现了底层神经形态计算资源的封装和屏蔽，将其抽象为神经资源进行统一管理和调度，并支持上层神经任务的运行。从软件角度看，OS为神经任务动态分配神经资源，提供多个神经任务调度的运行环境，同时提供神经资源内部信息接口和控制脉冲释放流程，为用户开发神经任务提供调试手段。OS由以下四层组成：
- 硬件抽象层使标准化的硬件访问接口能够兼容不同的硬件。
- 资源管理层实现神经资源管理和调度。
- 类脑功能层通过提供脉冲编解码库、神经任务调度、SNN模型库等支持神经任务的运行。
- The external access layer provides three kinds of access interfaces for the state, data, and debugging of the brain-inspired computer.

## Brain-inspired application IDE
目前，SNN 应用程序的开发与脑启发计算机的硬件密切相关。因此，我们提出了一种应用程序开发和调试工具，使用户能够高效地构建和调试 SNN 应用程序，而无需关心底层硬件。

模型开发包支持使用直接训练的方式得到SNN，或者将训练好的人工神经网络（ANN）转化为SNN。我们定义一个模型描述语言来统一描述这两种方式得到的SNN。然后通过模拟器对SNN进行仿真，根据执行结果优化模型参数以获得更好的性能。编译器将SNN中的脉冲神经元和突触映射到神经突触核心。最后将SNN编译成可执行的模型代码，供类脑计算机运行。在应用程序部署运行后，用户可以通过调试工具提供的可视化和分析功能观察应用程序的执行情况。

# DARWIN-S: THE IMPLEMENTATION
Darwin-S的具体实现版本主要集中在Darwin应用程序集成开发环境（DarwinIDE）和Darwin类脑操作系统（DarwinOS）两个部分。DarwinIDE实现了应用程序调试和模型开发的功能，包括转换工具、模拟器、编译器、模型定义语言等。DarwinOS可以支持应用程序的运行和类脑计算机的管理。

## DarwinOS: Management and scheduling
DarwinOS 是达尔文类脑计算机的主要软件运行平台，充分利用了基于混合计算架构的计算机分布式架构，由 FPGA 实现的 ARM 芯片完成操作系统的逻辑部分，神经任务由神经形态芯片 Darwin 2 完成。DarwinOS 的关键功能是神经资源和任务的管理和调度，如图 3 所示。
![[Pasted image 20241029111146.png]]

### Darwin Mouse: A Darwin braininspired computer
类脑计算机达尔文鼠是在神经形态芯片达尔文2的基础上开发的，采用网状和树状混合架构，支持1.2亿个神经元和720亿个突触。如图3所示，第一层达尔文2芯片采用网状结构，通过高速芯片间接口连接，第二层芯片之间通过FPGA通信，第三层FPGA之间通过以太网通信，形成树状结构。最底层采用网状结构，更多使用神经形态芯片的本地通信，减少跨区域通信，在保证链路吞吐量的同时考虑跨区域通信的时延。但网状结构的缺点是无法连接大量的神经形态芯片，因此最高层采用树状结构来解决此问题。我们将第二层作为达尔文鼠的基本模块。 Darwin Mouse由66个这样的模块组成，每个基本模块包含12个互连的芯片和一个FPGA桥，后者负责底层芯片之间的脉冲传输以及与其他基本模块的交互，互连芯片通过片上网络在芯片内部或相邻芯片之间传输脉冲，如图4所示。
![[Pasted image 20241029111900.png]]

### Hardware abstract layer
该层屏蔽了类脑计算机硬件的差异，实现了存储、通信、神经资源等硬件相关的抽象，使得参考架构能够支持不同的类脑硬件。

借鉴Darwin Mouse的三层混合架构，实现实时通信中间件和分布式文件系统，方便FPGA之间的实时通信和大规模SNN模型文件的存储。以数据为特征的实时通信中间件通过发布/订阅模式，保证服务质量策略，实现FPGA之间同步、高效、灵活的脉冲传输。分布式文件系统统一管理和抽象Darwin Mouse的所有存储资源，为上层软件创建统一的文件操作接口，同时支持冗余备份，提高文件存储的可靠性。神经资源抽象将神经形态芯片中神经元、突触等神经资源的操作统一为标准操作接口，主要包括神经元行为配置、突触权重参数读写、神经元连接路由配置等。这种设计使得支持多种类型的神经形态芯片成为可能。

### Resource management layer
DarwinOS通过资源管理层实现神经资源的状态管理和调度，其资源管理能力和分配效率直接决定了Darwin Mouse的整体性能。

资源状态管理主要包括神经元资源和突触资源的占用情况、神经元膜电位、故障状态等。资源状态管理一方面可以向外部用户提供整体的资源占用情况和系统故障状态，另一方面可以为神经资源调度设置资源约束。神经资源调度根据不同神经任务的资源需求和当前资源的空闲状态进行动态的神经任务迁移，通过资源调度，将缺乏长时间输入尖峰的神经任务优先导出到外部文件系统，随后将神经资源分配给需要紧急运行的神经任务，最大程度地满足用户神经任务的计算需求。通过负载平衡合理分配神经资源，可以充分实现系统的最佳功耗和性能。

### Brain-inspired functional layer
类脑功能层提供脉冲编码解码、神经任务调度、SNN模型库等神经任务的运行环境，使类脑计算机能够支持脑模拟等大规模神经任务以及边缘计算等场景的小规模神经任务的应用。

信息在SNN内部通过离散脉冲进行传输和处理，因此气味、图像、语音等输入数据必须编码成脉冲序列。类脑OS提供脉冲编解码库供应用使用。类脑计算机通过神经任务调度来运行神经任务，神经任务调度包括神经任务分解、神经资源分配、动态网络映射和神经网络加载等。根据神经资源的占用情况，将神经任务分解成多个执行子任务，动态映射并加载到类脑计算机的神经形态芯片中进行运行。

SNN模型库包含已训练好的语音、图像识别等标准模型，并有相应的脉冲编解码库，OS可以根据用户需求动态加载不同的SNN和编解码库，实现不同的类脑应用。

### External access layer
针对类脑计算机的外部交互问题，OS主要提供神经资源状态访问接口，通过数据交互接口完成SNN及其脉冲编码解码文件的输入输出操作，用户可以调用调试接口获取应用程序的运行状态，特别是膜电压等神经突触核心信息。

### DarwinIDE: Development, language, and compiler
神经科学家或SNN算法研究者在基于达尔文类脑计算机开发类脑模型时，由于对硬件约束的了解不足，面临着巨大的挑战。因此，为了让用户能够在资源受限的情况下高效地构建神经网络，并观察神经网络的运行，我们基于Darwin-S软件参考架构实现了DarwinIDE。如图5所示，DarwinIDE由两部分组成：达尔文模型开发工具包（DarwinMDTK）和调试工具。DarwinMDTK实现模型的训练、转换、仿真和编译。调试工具具有可视化、分析和执行跟踪功能。由于神经网络中的神经元数量庞大（多达数十亿个神经元），无法手动完成神经元的连接和权重参数的配置。而是需要通过DarwinMDTK自动完成SNN的构建。首先通过训练工具直接训练SNN，或者使用转换工具将ANN转换为用Darwin模型定义语言（DarwinMDL）描述的SNN，再通过模拟器对模型进行仿真，仿真运行通过后，编译器对模型进行解析，完成模型映射，并转换成硬件可执行的模型代码。调试工具面向可执行模型的执行过程，通过调用OS提供的调试接口获取神经元脉冲释放、膜电压等信息，并以图形方式显示，进行分析或跟踪。
![[Pasted image 20241029112958.png]]

### Model definition language
DarwinMDL指定了标准化的描述语法规则和神经相关性高的关键字，从而更加准确、规范地描述SNN。DarwinMDL作为一种独立于硬件平台的语言，通过训练、转换、仿真和编译工具为SNN模型提供了中间描述语言。DarwinMDL描述的SNN还可以通过图形同步显示，以直观地检查SNN内部结构的正确性，并最大限度地减少编辑和语法错误。

### Model conversion
目前，实现SNN主要有两种方式。一种是通过神经网络层调整和转换训练好的ANN，并微调连接的权重参数，从而获得可用的SNN。另一种方法是通过直接训练算法获得SNN。这些产生最先进性能的大规模SNN很可能是通过基于转换的方法获得的。考虑到这一点，我们在DarwinMDTK中包含了一个模型转换工具，以帮助开发人员将使用PyTorch或TensorFlow训练的ANN转换为DarwinMDL描述的SNN。此外，“案例研究”部分将提供一个详细的实例来阐明此工作流程。

该工具的工作流程可分为四个主要步骤。第一步是模型解析。使用深度学习库构建ANN并完成训练后，模型解析器对ANN进行解析，生成模型的中间表示。根据需要删除或替换ANN中的某些神经网络层，得到中间ANN。接下来，针对ANN中神经元之间的连接关系构建等效的SNN模型结构。之后，进一步调整SNN中的权重参数，并将其赋值给SNN相应的突触。最后，配置SNN中神经元和突触的参数，完成SNN的构建。

### Model training
除了转换之外，直接训练是获得SNN的另一种方法。为了让开发人员能够尽可能高效地从头开始培养SNN，我们在DarwinMDTK中集成了一个名为Spikebased Artificial Intelligence Computing (SPAIC) (glabNCRC/SPAIC)的SNN训练框架。开发人员只需要定义SNN网络结构、训练算法和相关训练参数，训练过程就会自动进行。这个过程的输出就是DarwinMDL定义的SNN，可以在下一步的模拟中使用。

SPAIC中集成了几种训练算法，如时空信用分配算法。SNN的训练过程与深度神经网络类似，只是SNN需要用脉冲编码信息。一个典型的训练过程如下。首先，根据网络结构的设计，初始化网络连接(突触)和参数。然后，对学习算法进行多次迭代。每次迭代通常由一次前向传递和一次后向传递组成，前向传递中，SNN 使用输入（输出）和脉冲编码（解码）进行特定时间步长的模拟，后向传递中，误差通过脉冲反向传播到网络参数，然后优化器根据梯度更新参数。最后，训练好的 SNN 将被打包成 DarwinMDL 标准格式。

### Model simulator
在编译应用程序之前，需要先使用模拟器对转换后的SNN进行仿真，以评估模型性能，并决定是否调整转换参数进行优化。模拟器从上到下分为三个部分：输入过程、SNN的运行监控和模型输出过程。输入过程提供输入数据的预处理和编码。编码数据被输入到模拟器上执行的SNN中。SNN的运行状态，包括神经元、突触连接和放电脉冲，在运行过程中会被持续监控。最终需要处理模型的输出。如果采用频率编码方法，则需要统计SNN最终输出层中每个神经元的脉冲激励，以得到最终结果。

在模拟器上执行SNN并处理数据时，通过定义神经元状态监视器来监视各层神经元的状态，通过定义脉冲激励监视器来获取各层神经元的脉冲激励。两个监视器一方面可以监测神经元的状态变化，用于模型的性能分析，对放电过快或者长时间不放电的神经元进行分析处理；另一方面可以在仿真应用过程中及时分析模型计算过程中的性能瓶颈，通过软件层面的仿真及时迭代优化模型，使其在硬件上部署时获得更好的性能。


### Model compiler
编译器由语言解析器和映射器组成。语言解析器将模型转换为中间代码、语法树以供映射。然后映射器将其绑定到特定的神经资源。

- 模型语言解析器：语言解析过程与传统编译器类似，经过词法分析、语法分析、语义分析三个阶段。词法分析扫描识别单词，比较关键词，建立对应的符号列表；语法分析根据DarwinMDL的语法规则，确定对应的语法类别；语义分析检查网络整体的模型结构，并在每个阶段进行错误检查和处理。在语义分析阶段，我们针对神经网络的特点对编译进行优化。在SNN的构建过程中，层的定义顺序和单层神经元属性的顺序是截然不同的。另外，一些参数可以省略，使用默认值。语言分析需要优化语义解析，根据上下文获取正确的层级顺序，并将值放入对应的属性键中，完成语义匹配。
- 模型映射：SNN的映射分为粗粒度分配和细粒度分配两个阶段。粗粒度分配阶段用于判断类脑计算机是否能满足网络映射的需求，如果类脑计算机的资源能够满足网络需求，则进入下一个细粒度分配阶段。输入需要映射的SNN后，进行资源评估，计算网络所需的资源总量，如果结果不超过硬件的可用资源，则进行下一步计算，否则网络无法映射到硬件上。根据不同的SNN结构，细粒度分配阶段可以采用两种方式完成。如果SNN具有良好的拓扑结构，如全连接层、卷积结构，则可以计算分配给每个节点的神经元数量。另一种方法是针对不规则的连接。同一层神经元的连接数可能相差很大，采用第一种自适应算法计算所需节点数，以尽可能少的节点数完成网络拓扑结构优化。该问题可以转化为装箱问题，每个节点看作一个箱子，里面放着神经元和相应的连接，当神经元数量达到阈值，或者另一个神经元的连接无法放入时，箱子就会装满。根据数据流向，反向分配资源，得到一个网络与硬件神经元一一对应的平等网络。在映射过程中，可以采用贪婪算法来优化功耗。

# CASE STUDY
基于 Darwin Mouse，我们以改进的国家标准与技术研究所的手写数字识别模型为例，说明 SNN 模型在类脑计算机上的开发、编译和执行的整个过程，如图 6 所示。
![[Pasted image 20241029114644.png]]

在本例中，SNN 模型是通过转换开发的。首先，使用传统的 ANN 框架 TensorFlow 构建和训练分类 ANN。然后通过基于数据的权重归一化的参数调整来优化 ANN 中的权重参数。最后，使用模型转换工具将 ANN 转换为 SNN。它使用的算法可以根据用户需求进行定制。

我们使用 Diehl 等人提出的方法将简单的卷积 ANN 转换为 SNN。输出的SNN包含四层，784个虚拟输入节点，650个计算神经元和41,600个突触，如图7所示。模拟时间步长设置为1毫秒，识别时间窗口为100毫秒。最后，使用我们的模型转换工具将ANN转换为SNN总共需要19.123秒。

在将模型部署到实际的脑启发计算机之前，先通过模拟器进行模拟，以验证模型的正确性和性能。首先，从DarwinMDL描述的模型文件中解析出每层神经元的数量和类型以及层间连接权重，并创建和初始化SNN。然后，将其放在模拟器上运行。经过几次模拟运行后，根据结果优化网络参数，以提高模型的性能。在模拟器上验证完SNN后，编译器编译DarwinMDL文件，生成可执行模型文件，提交给DarwinOS部署在Darwin Mouse上运行。然后在DarwinOS的控制下，将待识别图像编码成脉冲输入计算机，解码相应的输出，得到最终结果。使用DarwinIDE提供的调试工具显示神经资源状态和神经任务执行结果，如图8所示。经过前面描述的工作流程，我们的最终结果如下：平均处理一张图像需要56.063毫秒。SNN在模拟器和类脑计算机上的准确率分别为92.8%和83%。与输入模型转换工具的训练好的 ANN 获得的 93.27% 准确率相比，准确率损失分别为 0.47% 和 10.27%。结果比最先进的方法稍差。然而，考虑到我们没有专门优化训练和转换过程，而且大多数参数只是设置默认值，我们认为这个结果是可以接受的。

![[Pasted image 20241029114758.png]]

![[Pasted image 20241029114938.png]]


对于类脑计算机软件架构，尽管学术界和工业界尚未达成统一的标准，但纵观现有的类脑计算系统，努力的方向始终如一，期望抽象的硬件细节构建出软件运行的初级环境，并进一步建立编程开发环境和操作系统，简化编程方式。未来类脑计算机软件系统将从操作系统、编程语言、编程范式等方面逐步实现标准化，推动类脑计算生态的快速良性发展。
