## 5.1 Available Software
有许多不同的 SNN 模拟器 - 例如，BindsNET、Nengo、NeMo、Brian2GeNN、Nest 和 CARLsim。现有的模拟器具有不同级别的生物模型、计算速度和对硬件平台的支持。根据神经模型动态评估的计算方式，它们分为三类：
- 事件驱动（异步），其中膜电位仅在尖峰到达时被修改；
- 时钟驱动（同步），其中神经状态在每个时钟滴答声时更新；
- 混合策略（异步和同步）（Rudolph-Lilith、Dubois 和 Destexhe，2012 年）。

由于实现复杂性，事件驱动模拟器不像时钟驱动模拟器那样被广泛使用。此外，由于它们的顺序性，它们很难并行化。它们的主要优势是更高的运行速度，因为它们不计算神经元的小更新步骤。事件驱动模拟器的另一个好处是可以高精度地表示脉冲的时间。这些模拟器更适合活动较少且稀疏的神经网络层（Naveros、Garrido、Carrillo、Ros 和 Luque，2017 年）。

大多数 SNN 模拟器都是时钟驱动的。由于具有高并行性，时钟驱动模拟器充分利用了 CPU 和 GPU 平台中的并行计算资源。它们的平台对于具有低到中等数学复杂度的小型和中型神经元组表现更好，而 GPU 时钟驱动平台对于具有高数学复杂度的大型神经元组表现更好。时钟驱动模拟器的主要优点是它们适合在触发大量事件时模拟大型网络。许多这些模拟器都是建立在现有的深度学习框架之上的，因为它们在结构上类似于模拟 ANN。它们的主要缺点是脉冲时间与时钟的滴答声对齐，并且仅在时钟的滴答声处检查阈值条件（Brette 等人，2007 年）。选择最合适的技术需要在三个要素之间进行权衡：（1）神经网络架构（例如，神经元数量、神经模型复杂度、输入和输出突触数量、平均发放率）、（2）硬件资源（CPU 和 GPU 核心数量、RAM 大小）以及（3）模拟要求和目标。

文献中报道的 SNN 模拟器有
BindsNET（Hazan 等人，2018）、Nengo（Bekolay 等人，2014）、NeMo（Fid-
jeland、Roesch、Shanahan 和 Luk，2009）、GeNN（Yavuz 等人，2016）、Brain
2（Stimberg、Brette 和 Goodman，2019），Brian2GeNN（Stimberg、Good-
man 和 Nowotny，2020）、NEST（Gewaltig 和 Diesmann，2007）、CARLsim
（Beyeler、Carlson、Chou、Dutt 和 Krichmar，2015 年；Chou 等人，2018 年），Neu-
Cube（卡萨博夫，2014）、PyNN（戴维森，2009）、ANNarchy （Vitay、Dinkelbach 和 Hamker，2015）和 NEURON（Hines 和 Carnevale 1997）。选择 SNN 模拟器有一些主要标准。它应该是开放访问的；易于调试和运行；并支持各种ASIC 和 FPGA 等硬件来执行模拟并支持生物复杂度级别。我们在表 3 中描述了现有突出的 SNN 模拟器的主要特征。
![[Pasted image 20241216131856.png]]

BindsNET 是一个用于快速构建和模拟 SNN 的开源 Python 包，它基于 PyTorch 深度学习库进行矩阵计算。BindsNET 允许研究人员在 CPU 或 GPU 上测试软件原型，然后将模型部署到专用硬件上（Hazan 等人，2018 年）。

Nengo 是一个基于神经工程框架的神经模拟器，用于模拟大规模脉冲和非脉冲神经模型。它用 Python 编写，支持 TensorFlow 后端。这个 Python 库允许用户定义神经元类型、学习规则和优化方法（Bekolay 等人，2014 年）。

NeMo 是一个用于模拟 SNN 的 C++ 类库，可以在单个工作站上模拟数万个神经元。它具有 Matlab 和 Python 的绑定，并且是 PyNN 模拟器接口支持的后端之一（Fidjeland 等人，2009 年）。

GeNN 是一个开源库，用于通过代码生成技术加速 CPU 或 GPU 上的 SNN 模拟（Yavuz、Turner 和 Nowotny，2016 年）。

Brain 是一个用 Python 编写的流行的 SNN 开源模拟器。它非常灵活、易于扩展，并且常用于计算神经科学。Brain 的第 2 版允许科学家有效地模拟 SNN 模型（Stimberg 等人，2019 年）。在新开发的软件包 Brian2GeNN 中，GPU 增强型神经网络模拟器 (GeNN) 可用于加速 Brain 模拟器中的模拟 (Stimberg 等人，
2020)。

另一个流行的开源 SNN 模拟器是 NEST，它专注于神经网络的动态、大小和结构。它适用于大型脉冲神经元网络（Gewaltig 等人，2007 年）。CARLsim 是一个用户友好且 GPU 加速的 SNN 库，用 C++ 编写，支持 CPU-GPU 共同执行（Beyeler 等人，2015 年）。CARLsim 的第 4 版已得到改进，可在实时约束下模拟大规模 SNN 模型（Chou 等人，2018 年）。表 4 显示了大多数 SNN 模拟软件的功能。

## 5.2 Available Hardware
脉冲神经形态硬件可细分为模拟和数字或混合模式（模拟/数字）设计。
模拟硬件使用物理过程来模拟人工神经元的某些计算功能。这种方法的优点是，通过系统的自然动力学可以非常有效地实现可能作为显式数学运算而成本高昂的操作（Neil & Liu，2016）。此外，实值物理变量可以具有几乎无限的精度。模拟硬件实现因模拟元素的使用程度而异。许多实现仅在具有模拟元素的神经元中执行计算，保持脉冲信号的通信数字化（Camuñas，Linares-Barranco 和 Serrano-Gotarredona，2019）。

数字硬件用位来表示神经元的所有变量，就像传统计算机一样。这意味着变量的精度取决于用于表示变量的位数。这种精度还强烈影响基本操作的能耗和变量存储的内存要求。与模拟硬件相比，数字设计的一大优势是变量的精度是可控和保证的。此外，数字硬件可以使用成熟的芯片设计和制造技术来设计。数字解决方案可以在 FPGA 或专用集成电路 (ASIC) 上实现 (Schuman 等，2017)。或者，由于 ASIC 的生产成本高，其他研究小组专注于在 FPGA 上实现 SNN。

### 5.2.1 Learning with Neuromorphic Hardware
学习机制对于神经形态系统适应特定应用的能力至关重要。根据学习中包含的超参数数量，可以执行各种类型的学习，并且学习时间可能会有很大差异。当在神经形态芯片中进行此类学习时，该学习称为片上训练（Lee, Lee, Kim, Lee, & Seo,2020）。为了进行片上训练，神经形态芯片应该具有学习所需的几乎所有功能（Walter, Röhrbein,& Knoll, 2015）。片外训练是一种使用软件等在神经形态芯片外部实现学习的方法。外部学习完成后，根据神经形态系统对权重进行后处理，或者使用后处理的权重制造神经形态系统。

是否实施片上或片外训练取决于所考虑的应用。如果目标是设计一个用于机器学习的通用加速器，那么显然芯片应该允许片上训练（Burr 等人，2015 年）。如果目的是在嵌入式低功耗硬件上执行独特的机器学习任务，则可能耗电的片外学习只能实现一次，之后对生成的网络进行片上编程。此时，有人可能会争辩说，在某些情况下，系统应该需要在运行时适应其传感环境，这被称为在线学习。一种解决方案是在操作时间之间启用片外训练，并在非活动或加载时间内更新或微调 SNN。但是，这种方法仍然带来一些缺点；例如，它需要添加一个内存来存储在操作期间获取的输入数据。此外，在线学习仍在研究中，因为机器学习目前存在遗忘的主要缺点，这意味着训练有素的网络无法在不失去先前学习任务的准确性的情况下学习新任务（Zheng & Mazumder，2018b）。

多年来，STDP 一直是脉冲神经形态系统中实现机器学习任务的首选算法（Diehl & Cook，2014）。它在神经形态社区中很受欢迎，原因有几个。首先，神经形态计算领域传统上受到生物学的启发。这就是神经形态硬件中早期学习方法受到大脑中观察到的机制启发的原因。此外，STDP 在模拟神经形态硬件中很容易实现。它的时间依赖性通常由指数衰减建模，可以通过模拟电子元件简单地计算出来。最后，如果我们想要应用监督学习，这些算法需要复杂的神经元和突触模型，或者层之间以及神经核心之间的梯度浮点值通信，这使得它们的硬件实现不切实际。此外，如果在线执行权重更新（即在推理期间），则必须暂停前馈操作进行学习，这会增加系统的操作延迟。

### 5.2.2 Large-Scale Neuromorphic Hardware
评估大规模神经网络需要高度可配置的专用硬件。众所周知的神经形态架构 TrueNorth (Merolla 等人，2014 年)、Neurogrid (Benjamin 等人，2014 年)、BrainScaleS (Schemmel 等人，2010 年)、Loihi (Davies 等人，2018 年) 和 SpiNNaker (Furber、Galluppi、Temple 和 Plana，2014 年) 追求各种特性来模拟脉冲神经元网络。（请注意，本评论涉及众所周知的全数字和混合数模神经形态硬件。）

IBM TrueNorth 芯片是一个在数字电子中实现的神经形态平台。该芯片专为大规模网络评估而设计，更接近人脑结构，而不是传统计算机中使用的冯·诺依曼架构。单个 TrueNorth 芯片包含 54 亿个晶体管和 4096 个神经突触核心。每个核心包括 12.75 KB 的本地静态随机存取存储器 (SRAM)、256 个神经元、265 个轴突和 265 × 265 突触交叉开关。该芯片最多可模拟 100 万个神经元和 2.65 亿个突触。TrueNorth 芯片可通过 Corelet 编程语言进行编程（Merolla 等人，2014 年）。

Neurogrid 是一种混合数字模拟神经形态设备，旨在实时模拟生物大脑。 Neurogrid 板由 16 个互补金属氧化物半导体 (CMOS) NeuroCore 芯片组成，每个芯片都有 256 × 256 个模拟神经元，采用 180 nm CMOS 技术制造。 该板能够对具有数十亿个突触连接和 100 万个神经元的大脑进行实时生物模拟 (Benjamin 等人，2014)。

BrainScaleS 是一种混合模式模拟/数字神经形态硬件系统，基于神经元、突触和可塑性模型的物理仿真，旨在模拟大脑大小的神经网络。该系统由 8 英寸硅片组成，能够模拟多达 50 × 106 个塑性突触和 200,000 个神经元。BrainScaleS 系统中实现了自适应指数 IF 神经元模型和模拟网络核心结构中的突触。系统中的通信单元是数字的，而处理单元是模拟电路（Schemmel 等人，2010 年）。

英特尔实验室设计了一种名为 Loihi 的全数字神经形态研究芯片，用于实现 SNN。该芯片采用英特尔的 14 nm 工艺技术制造，包含 128 个内核和三个管理 Lakemont 内核。Loihi 芯片可以实现多达 130,000 个神经元和 1.3 亿个突触。此外，每个内核中嵌入的学习引擎支持片上学习，具有各种学习规则，这使得 Loihi 对于主管/非主管和强化模型更加灵活。它可以比传统处理器更快、更高效地处理信息，分别高达 1000 和 10,000，这使其成为解决特定类型优化问题的理想选择（Davies 等人，2018 年）。

SpiNNaker 是一个大型数字神经形态系统，旨在实时模拟大规模神经计算模型。SpiNNaker 板由 48 个芯片组成，每个芯片包含 18 个 ARM 微处理器和一个片上网络 (NoC)。每个核心包含一个 ARM968 和一个直接内存访问 (DMA) 控制器，可实时实现近 1000 个脉冲神经元。SpiNNaker 的优势之一是使用异步通信方案。PyNN 接口使 SpiNNaker 板可编程。PyNN 是一个 Python 库，提供各种脉冲神经元模型和突触可塑性规则。这种神经形态平台已用于神经科学应用，例如视觉皮层或小脑的模拟 (Furber，2016)。

这些神经形态系统的主要特征如表 5 所示。请注意，对于网络的执行，本表仅回顾了在片上实现以在线运行的学习方法。

### 5.2.3 FPGA-Based Implementation of SNN
SNN 算法具有并行和分布式特性。当今的计算机架构和软件不适合 SNN 执行。另一种方法是通过专用硬件加速 SNN 应用程序。神经形态硬件旨在最大限度地降低能耗和成本，同时保持最高的准确性。与在 CPU 上运行的软件程序相比，它具有令人鼓舞的加速效果，并且功耗低于 GPU。

已经使用了几种神经形态加速器来实现 SNN。然而，它们遇到了一些限制，例如神经元的最大扇入/扇出和突触精度，并且由于成本高而不适合嵌入式系统（Ji et al., 2016）。FPGA 作为一种可编程且低成本的设备可以解决这个问题：它们表现出高性能和重新配置能力，并且比当前的 CPU 和 GPU 更节能。此外，它们支持并行处理并包含足够的本地内存来恢复权重，这使它们成为实现 SNN 的合适候选者（Guo, Yantir, Fouda, Eltawil, & Salama, 2021）。Rahman (2017) 证明，使用单个 CPU，处理时间很慢（每张图像大约 1 分钟）。然而，随着 FPGA 硬件加速的成功以及使用具有更多滤波器和卷积层的更复杂网络，在实时场景中使用 SNN 将成为可能（每幅图像 1 秒）。与专用集成电路 (ASIC) 相比，FPGA 是实现数字神经形态平台的合适候选者。它们提供快速的设计和制造时间、低成本、高灵活性、更直接的计算机接口和出色的稳定性。虽然使用 FPGA 的改进潜力很大，但仍有许多未解决的研究问题限制了 FPGA 目前主流的吸引力。

与 CPU 和 GPU 相比，在 FPGA 上实现神经网络非常耗时。FPGA 在神经网络计算中仍未像 CPU 和 GPU 等通用硬件平台那样得到广泛应用的一个重要原因是其可编程性相对较低 (Hofmann, 2019)。Caffe 和 TensorFlow 等软件框架仅支持 CPU 和 GPU 等硬件单元，并且可以在这些操作系统上执行。尽管高级综合 (HLS) 缩短了 FPGA 上的开发周期，但高效的 HLS 系统设计仍然需要深入了解硬件细节，这对一般神经网络开发人员来说可能是一个问题 (Zhang & Kouzani, 2020)。仍然需要基于 FPGA 的框架来支持主流软件神经网络库，如 TensorFlow 和 Caffe。

多项研究报告了在 FPGA 上针对各种应用实现 SNN 的不同方法。基于 FPGA 的 SNN 实现已被提出用于对音符进行分类 (Cerezuela-Escudero 等，2015)、心电图 (ECG)、边缘检测 (Qi 等，2014)、实时图像去扭曲 (Molin 等，2015)、运动系统 (Guerra-Hernandez 等，2017)、仿生图案生成 (Ambroise、Levi、Joucla、Yvert 和 Saïghi，2013) 和事件驱动的视觉处理 (Youse-fzadeh、Serrano-Gotarredona 和 Linares-Barranco，2015)。

请注意，我们在此重点介绍最近基于 FPGA 的图像分类领域 SNN 实现，这是目前机器学习的一个重要领域。许多研究小组现在正集中精力开发用于解决各种分类和识别问题的储存库计算。Tanaka 等人 (2019) 总结了物理储存库计算的最新进展，例如模拟电路和 FPGA。Yi 等人 (2016) 开发了一种实时的、基于硬件的 FPGA 架构，用于循环神经网络 (RNN) 训练的储存库计算方法。许多研究一直致力于在 FPGA 上为液态机 (LSM) 设计合适的神经形态架构 (Liu, Jin, & Li, 2018; Wang, Jin, & Li, 2015; Jin, Liu, & Li, 2016)。

已经多次尝试在 FPGA 上实现 SNN 以进行模式识别。Ju 等人 (2020) 提出了一种基于 FPGA 的深度 SNN 实现。他们应用了硬件友好的脉冲最大池化操作和两种并行方法（移位寄存器和粗粒度并行）来提高数据重用率。FPGA 实现的功耗比 GPU 实现低 22 倍，速度比 CPU 实现高 41 倍。Abderrahmane 和 Miramond (2019) 探索了一种用于嵌入式人工智能应用的基于脉冲的神经网络。他们在 FPGA 平台上实现了两种架构，即时分复用和完全并行。然而，对于具有这两种架构的更深层网络来说，FPGA 片上内存是不够的。高效的内存访问对于存储 SNN 的参数和评估至关重要。片上内存有限制，而片外内存比片上内存消耗更多的能量。因此，设计合适的架构可以减少内存访问。Nallathambi 和 Chandrachoodan (2020) 提出了一种新颖的概率脉冲传播方法，减少了评估 SNN 所需的片外内存访问次数，从而节省了时间和能源。

为了充分利用基于事件和基于帧的处理，Yousefzadeh、Orchard、Stromatias、Serrano-Gotarredona 和 Linares-Barranco (2018) 提出了一种结合 SNN 和 ANN 特征的混合神经网络。它们在 FPGA 上的实现每帧消耗 7 uJ，并在 MNIST 数据库上获得 97% 的准确率。在类似的工作中，Losh 和 Llamocca (2019) 设计了脉冲混合网络 (SHiNe)，基于 FPGA 的硬件在 MNIST 数据集上实现了合理的准确率 (90%)。由于两个因素，SHiNe 设计的 FPGA 资源利用率明显较低 (约低 35%)：神经网络 (SHiNe 网络比标准神经网络简单得多，每个信号只需要 1 位) 和神经元实现 (每个 SHiNe 神经元仅包括一个计数器和一组比较器)。他们还实施了一种名为节俭的方法，该方法限制了一层神经元与下一层神经元之间允许的连接数量。他们在 Zynq XC7Z010 PSoC 板上的 FPGA 设计比 GPU 或 CPU 实现的功耗要低得多。Zhang 等人 (2020) 开发了一种基于 FPGA 的 SNN 实现，与软件实现相比，其速度提高了 908,578 倍。他们通过使用算术移位而不是乘法运算来减少硬件资源的消耗，从而可以提高训练效率。

Han, Li, Zheng, and Zhang (2020) 提出了一种基于 FPGA 的 SNN 硬件实现，该实现支持多达 16.384 个神经元和 1680 万个突触，功耗为 0.477 W。他们使用了一种混合更新算法，其中包括时间步进和事件驱动算法。除了片上块随机存取存储器 (RAM) 外，他们还使用外部 DDR 存储器来优化存储器访问的延迟。

Kuang 等人 (2019) 介绍了一种基于 FPGA 的实时 SNN 实现，通过无乘法器近似显著降低了硬件资源成本。他们提出的系统适用于生物启发式神经形态平台和在线应用。Wang、Li、Shao、Dey 和 Li (2017) 提出的基于 FPGA 的 SNN 并行神经形态处理器成功解决了与内存组织和并行处理相关的几个关键问题。通过 32 路并行设计实现了 59.4 倍的训练速度提升，并通过在其处理器设计中使用近似乘法器将能耗降低了 20%。Fang、Shrestha、Zhao、Li 和 Qiu (2019) 提出的一种基于 FPGA 的 SNN 硬件实现，具有生物现实的神经元和突触，应用了一种群体编码方案将连续值转换为脉冲事件。与 GPU 实现相比，FPGA 实现的功耗降低了 196 倍，速度提高了 10.1 倍。他们的实验表明，与 FPGA 平台上的速率 SNN 相比，时间 SNN 的速度提高了 8.43 倍。

表 6 展示了最近基于 FPGA 的 SNN 实现在网络配置、系统性能和目标设备方面的性能。