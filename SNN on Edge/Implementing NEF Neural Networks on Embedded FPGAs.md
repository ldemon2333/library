# Abstract
低功耗、高速神经网络对于在边缘提供可部署的嵌入式 AI 应用至关重要。==我们描述了一种具有在线学习功能的神经工程框架 (NEF) 网络的 FPGA 实现，其性能比移动 GPU 实现高出一个数量级或更多。具体来说，我们提供了一种支持 Python 的嵌入式 PYNQ FPGA 实现，该实现支持高级综合 (HLS) 工作流程，允许在亚毫秒内实现自适应神经网络，具有低延迟、直接 I/O 访问物理世界的功能。==我们调整代码中不同中间变量的精度，以实现与速度较慢、较大的浮点参考设计相比具有竞争力的绝对精度。神经网络的在线学习组件利用即时反馈来调整网络权重，以最好地支持给定的算术精度。由于此类网络的可能设计配置空间巨大，且受目标精度约束，我们使用 Hyperopt 超参数调整工具而不是手动搜索来找到帕累托最优设计。具体而言，我们能够在 Vivado HLS 的 500 次迭代中生成优化设计，然后在该子集上运行完整的 Vivado 布局布线阶段。对于 64-4096 个神经元和 1-8 个表示维度的神经网络群体，我们由 Hyperopt 生成的优化 FPGA 实现比 Jetson TX1 GPU 上的竞争 cuBLAS 实现速度提高了 10-484 倍，同时功耗降低了 2.4-9.5 倍。我们的加速是 HLS 特定的重新制定（15 倍改进）、精度适应（4 倍改进）和低延迟直接 I/O 访问（1000 倍改进）的结果。

# 1. 介绍
随着摩尔定律的终结不可避免地临近，半导体行业在制造和生产可行芯片方面面临着越来越多的技术和物理挑战。同时，机器学习革命正在创造对更强大的处理硬件的需求，这些硬件可以训练和评估复杂的神经网络。FPGA 提供了一个可配置的计算基础，使我们能够根据需要专门为我们的计算任务配置硬件资源，从而优雅地适应摩尔定律的终结。特别是，它们非常适合机器学习任务，因为它们提供对数千个 DSP 和 RAM 块的并行访问。

机器学习 (ML) 开发人员通常使用 Python 作为其开发环境。许多流行的软件包（例如 Tensorflow、Keras、Nengo 等）都是围绕 Python 构建的，并在社区中广泛使用。在硬件方面，ML 开发人员已经采用 GPU 进行训练和推理。这是通过优化的 GPU 库、高级 CUDA 编程环境以及与 Python 的轻松集成实现的。FPGA 被视为具有陡峭的编程学习曲线的奇特设备，因为它们使用 VHDL 或 Verilog 等低级语言。为了帮助解决生产力差距，FPGA 现在允许使用带有高级综合 (HLS) 编译器的 C/C++ 进行编程。此外，Xilinx 还推出了 PYNQ，这是一个用于访问 Zynq 板上的 FPGA 硬件的 Python 环境。 PYNQ环境具有干净的 API，可用于配置 FPGA、使用 DMA 进行数据移动、访问 GPIO 块等。HLS 和 PYNQ 的组合对于 ML 开发人员来说是一个更具吸引力的起点。

FPGA 在延迟、功耗和可配置性方面比 GPU 具有显著优势。这些功能在功耗受限的网络边缘部署中尤其重要，例如在物联网、移动或实时应用中。因此，过去曾多次尝试将 ML 与嵌入式 FPGA 结合起来 [7]、[11]、[13]、[14]，但大多数主要集中在卷积网络上。==本文的目标是提出一个优化的 FPGA 后端，将包装在 PYNQ API 中的 HLS 生成的硬件与 Nengo [1] 神经网络开发框架集成在一起。==
Nengo 是一个 Python 包，用于模拟脉冲和非脉冲大规模神经网络，并对神经工程框架 (NEF) [5] 提供独特的支持。Nengo 包含一个图形界面，可帮助可视化网络拓扑并检查模型中的实时表示值。它非常灵活，可以实现传统的深度学习、视觉和电机控制应用，但除此之外，它还包括工作记忆、分层强化学习、归纳推理和规划。事实上，世界上最大的功能性大脑模型 Spaun [6] 就是使用 Nengo 构建的，展示了该框架的丰富功能。Nengo 目前支持 CPU、GPU、SpiNNaker [10] 和其他后端，现在还可以针对 PYNQ FPGA 板。

总之，==我们为 Nengo 开发了一个 FPGA 后端，以实现使用具有在线学习功能的神经网络结构的低功耗、低延迟嵌入式系统==。我们使用 HLS 描述神经网络，该描述具有足够的参数和灵活性，可以涵盖一系列实现可能性。此外，我们重新制定了描述中的并行性，以克服 Vivado HLS 的局限性并公开数据流和管道并行性。此外，我们使用 Hyperopt [3] 降低算术运算的精度，以找到设计的最佳参数。值得注意的是，所包含的在线学习允许网络不断调整网络权重以在所选位精度的约束内执行所需的功能。最后，为了展示完全嵌入式的性能，我们绕过 ARM 主机 CPU，并通过 GPIO 将传感器和执行器与自适应神经网络架构直接集成在一起。

# 6. 结论
使用支持 Python 的嵌入式 PYNQ FPGA 板为机器学习革命所需的繁重工作量计算提供了一个有希望的解决方案。将高级综合与 PYNQ Python API 结合使用
有助于使 FPGA 编程更易于访问。我们已经展示了如何使用针对硬件量身定制的结构化 HLS 方法来利用问题的并行性，从而将评估神经网络所需的周期减少 15 倍。此外，我们展示了定点超参数可以使用 Hyperopt 自动优化成本函数，包括资源使用、准确性和周期数以进一步将周期减少 4 倍——整体改进超过 65 倍。此外，定点表示的精度降低允许将更大的模型（最多 32k 个神经元）存储在芯片上，同时仍然优于只能支持 16k 个神经元的浮点对应模型。与受 ARM DMA 限制的设计相比，使用直接 I/O 访问可将性能提高 1000 倍，从 715μs 的步进时间降低到 0.678μs。我们还证明了我们的 FPGA 实现比 Jetson TX1 GPU 的性能高出 10-484 倍，适用于 64-4096 个神经元和 1-8 个表示维度的神经网络群体，同时功耗降低 2.4-9.5 倍。

==该项目是为 Nengo 神经网络开发环境创建功能齐全的 FPGA 后端的第一步。除了低功耗、低成本的嵌入式场景之外，我们还计划将这项工作扩展到更大的 FPGA，以解决更大的云和边缘计算工作负载。==