
https://ieeexplore.ieee.org/document/8528875
# Abstract
将计算架构从冯·诺依曼架构转变为基于事件的脉冲神经网络 (SNN)，为视觉或感觉运动控制等应用中低功耗处理传感数据提供了新的机会。探索认知 SNN 之路需要设计紧凑、低功耗和多功能的实验平台，其关键要求是==在线学习==，以便在不受控制的环境中适应和学习新功能。然而，目前在 SNN 中嵌入在线学习受到高复杂性和面积开销的阻碍。在本文中，我们介绍了 ==ODIN，这是一款 0.086 平方毫米 64k 突触 256 神经元在线学习数字脉冲神经形态处理器==，采用 28 纳米 FDSOI CMOS 工艺，每个突触操作 (SOP) 的最小能量为 12.7 pJ。它利用脉冲驱动突触可塑性 (SDSP) 学习规则的有效实现，实现高密度嵌入式在线学习，每个 4 位突触仅 0.68 µm2。神经元可以独立配置为标准泄漏积分和激发模型，也可以配置为自定义现象学模型，以模拟生物脉冲神经元中发现的 20 种 Izhikevich 行为。使用 6k 16 × 16 MNIST 训练图像的单一呈现到单层全连接 10 神经元网络，并采用基于片上 SDSP 的学习，ODIN 实现了 84.5% 的分类准确率，同时使用等级顺序编码在 0.55 V 下仅消耗 15 nJ/推理。因此，==ODIN 可以进一步发展低功耗、自适应和低成本处理的认知神经形态设备。==

# 1. 介绍
虽然未来几年物联网 (IoT) 范式的大规模部署对自主智能传感器设计提出了严格的要求 [1]，但摩尔定律 [2] 的终结要求新的计算架构能够适应严格的成本和功耗降低限制。与当前的冯·诺依曼处理架构形成鲜明对比的是，生物大脑似乎具有无与伦比的性能-资源权衡 [3]：例如，蜜蜂大脑有近 100 万个神经元，功耗约为 10 μW，但它能够执行复杂的行为，如序列和模式学习、导航、规划和预测，同时表现出超越人类婴儿的学习速度 [4]，[5]。因此，为了使硅信息处理设备更接近生物大脑的效率，神经形态工程领域沿着两个轴的范式转变解决了生物启发系统的研究和设计。==第一个轴与计算组织相关：生物神经网络具有共置处理（即神经元）和记忆（即突触）的特点，具有大规模并行数据处理 [6]。第二个轴与信息表示相关：生物神经网络在时间域中处理信息，使用尖峰来编码数据。信息处理完全由事件驱动，从而实现稀疏低功耗计算 [5]。

这种双重范式转变可能导致新的生物启发和节能的神经形态计算设备，其稀疏事件驱动的数据采集和处理似乎特别适合依赖于能量收集的物联网分布式自主智能传感器[1]，[3]，用于自主嵌入式系统的封闭式传感器运动回路和具有严格电池要求的机器人[7]，[8]，脑机接口[9]，[10]和神经科学实验或生物混合平台[11]，[12]。然而，尽管神经科学最近取得了进展，但对大脑的计算和操作原理的详细了解仍然遥不可及[13]。这凸显了对具有高度多功能性的高效实验平台的需求，这些平台在神经元行为[14]和具有突触可塑性的在线学习[15]方面具有很高的通用性，以探索类似大脑的计算，实现高效的基于事件的 SNN 处理器。 [16] 提出了一种使用 SpiNNaker 进行大规模神经网络模拟的软件方法，但高灵活性是以有限的功率和面积效率为代价的。基于 FPGA 的方法也有类似的结论（例如 [17]–[20]）。因此，需要克服低功耗、低面积、大规模集成生物物理精确的神经形态 SNN 设备的挑战 [21]。

神经形态设备的第一个设计方法出现在 20 世纪 80 年代末，利用在亚阈值状态下工作的 MOS 晶体管直接模拟大脑离子通道动力学 [22]，这种方法至今仍是 SNN（例如 ROLLS [23] 和 DYNAP [24]）的流行方法。亚阈值模拟方法使用生物时间常数模拟大脑动力学以实现实时感觉运动控制，而超阈值模拟方法允许模拟加速度因子高达 100,000 的神经元以实现快速处理（例如 BrainScaleS [25]）。还提出了一种开关电容模拟实现方法，以简化深亚微米技术中的稳健模拟设计 [26]、[27]。然而，为了充分利用技术扩展，几个研究小组最近开始设计数字 SNN（例如，Seo 等人在 [28] 中，Kim 等人在 [29] 中，IBM 的 TrueNorth [30] 和英特尔的 Loihi [31]）。数字设计具有更短的设计周期、对噪声、工艺电压温度 (PVT) 变化和不匹配的低敏感性，并且抑制了产生偏置电流和电压的需要。根据其实现方式，数字 SNN 可以跨越生物到加速时间常数，并表现出制造的硬件和软件模型之间的一一对应关系。


模拟SNN：
- 超阈值模拟方法（BrainScalesS）
数字SNN：
- IBM 的 TrueNorth
- Intel 的 Loihi

由于模拟大脑动力学需要实施高复杂度的神经元和突触模型，因此实施资源高效的生物物理精确且用途广泛的数字 SNN 仍然是一个悬而未决的挑战。实际上，需要两个关键要素。==首先，事件驱动的嵌入式在线学习允许低功耗自主代理实时适应不受控制环境中的新功能，在这种环境中，有限的训练数据会即时呈现给网络。这些要求无法通过基于反向传播的人工神经网络 (ANN) 中的传统离线学习技术来满足，因为它们依赖于大量训练数据的重复呈现。由于生物扇入量级为每神经元 100 到 10,000 个突触，因此在每个单个突触中本地嵌入在线学习规则（例如脉冲时间依赖性可塑性 (STDP) [32] 或脉冲驱动的突触可塑性 (SDSP) [33]）具有挑战性 [34]。忆阻器有望创下新纪录，但与 CMOS 的高收益协同集成仍有待证明 [35],==
[36]。==其次，广泛使用的漏积分和激发 (LIF) 神经元模型已被证明缺乏探索大型神经网络计算特性所必需的基本行为库 [37]。相比之下，实现生物物理精确模型（例如 Hodgkin-Huxley [38]、Izhikevich [39] 或自适应指数 [40]）需要数字 SNN 来求解耦合非线性微分方程并在每个积分时间步更新所有神经元状态。==因此，在这项工作中，我们提出了 ==ODIN，一种采用 28 纳米 FDSOI CMOS 的在线学习数字脉冲神经形态处理器。它包含 256 个神经元和 64k 个突触，并以高密度嵌入 SDSP 在线学习，每个突触仅占 0.68 μm2。可以使用完全由事件驱动且不需要在每个时间步更新神经元的自定义现象学模型对神经元进行编程，以模拟生物脉冲神经元 [14] 中发现的所有 20 种 Izhikevich 行为。 ODIN 仅占用 0.086 mm2 的面积，在 0.55 V 电压下每次突触操作 (SOP) 的最小能量为 12.7 pJ。使用来自 MNIST 手写数字数据集 [41] 的 6k 16 × 16 像素训练图像的单次呈现，基于片上 SDSP 学习的单层全连接 10 神经元网络实现了 84.5% 的分类准确率，使用排序编码每次推理仅消耗 15 nJ。==

本文的其余部分结构如下。首先，第二部分描述了 ODIN 的设计，并详细介绍了基于事件的寻址方案、在线学习突触、现象学神经元模型和内部事件调度程序的架构和实现细节。其次，第三部分介绍了规格和测量结果，并在 MNIST 上比较了两种学习策略：片上和在线使用 SDSP 或片外和离线使用随机梯度下降。最后，在第四部分讨论这些结果并将其与最新技术进行比较，然后在第五部分总结结论。

# 2. ARCHITECTURE AND IMPLEMENTATION
ODIN SNN 中实现的交叉开关架构如图 1 所示。为了利用数字逻辑的高速操作来最小化硅片面积，采用了时间复用方法，其中神经元和突触以顺序方式更新，而不是并行更新。N 个神经元和 NxN 个突触的各个状态存储在片上 SRAM 中，控制器处理神经元和突触更新以模拟 N × N 交叉开关，其中每个 N 个神经元都有 N 个在线学习突触的扇入。
![[Pasted image 20241208132713.png]]


芯片级的输入和输出事件通过==地址事件表示 (AER) 总线处理，这是一种流行的四阶段握手通信方案，是 SNN 的事实标准 [42]、[43]。==由于 ODIN 是使用同步数字实现流程 (第 III 节) 实现的，为了以异步方式使用 AER，分别在输入和输出 AER 接口的 REQ 和 ACK 线上放置了双锁存同步屏障，以限制亚稳态问题。为了提高 ODIN SNN 实验和测试的多功能性，输入 AER 总线进行了扩展，以表示各种事件类型。

# 4. Discussion
表 I 提供了最先进的神经形态芯片的性能和规格摘要。具有核心模拟神经元和突触计算以及高速数字外围设备的混合信号设计分组在左侧 [23]–[25]、[27]、[63]、[64]，数字设计与 ODIN 一起分组在右侧 [16]、[28]–[31]。对于高效的脉冲神经形态实验平台，关键的优缺点是神经元的多功能性（即 Izhikevich 行为库）、突触可塑性、密度和每 SOP 的能量。

![[Pasted image 20241208135946.png]]


表 I 中的几种芯片嵌入了特定的路由方案，以实现互连芯片的大规模集成，例如 HICANN、NeuroGrid、DYNAPs、SpiNNaker、TrueNorth 和 Loihi，而最近在 [68] 中为 IFAT 提出了分层路由 AER 拓扑。为了进行公平的比较，当这些芯片由多个神经突触核心组成时，我们在表 I 中报告了与单个神经突触核心相关的密度数据。表 I 中比较的其他芯片（包括 ODIN）由单个神经突触核心组成。可以使用标准输入和输出 AER 接口实现大规模互连，但这种连接方案需要外部路由表来定义芯片间连接。 ODIN 的范围在于设计一个功率和面积高效的神经突触核心，我们期望在未来的工作中探索分层事件路由基础设施，以便将 ODIN 神经突触核心转移到高效的大规模集成中。

在所有 SNN 中，28 纳米 IBM TrueNorth 芯片 [30] 之前具有最佳的神经元和突触密度，远远超过迄今为止提出的所有混合信号方法。与 ODIN 相比，其神经突触核心具有相同数量的神经元和突触，并且两种芯片均采用 28 纳米 CMOS 技术，因此可以直接进行比较。虽然 TrueNorth 没有嵌入突触可塑性，但我们通过 ODIN 展示了可以将每个突触的位数增加四倍并添加在线学习，同时略微减少整体面积，从而提高整体神经元和突触密度。

14 纳米英特尔 Loihi 芯片最近被提出 [31]，并嵌入了可配置的基于脉冲时间的学习规则。Loihi 也是一个实验平台，具有特定的功能。虽然 ODIN 中的神经元钙变量对应于通过钙泄漏具有可配置时间常数的 SDSP 资格轨迹，但 Loihi 在其可编程学习规则的背景下提供了几种类型的资格轨迹（例如，多个脉冲轨迹和奖励轨迹），具有扩展的可配置性。其轴突和不应期延迟、随机性和稳态阈值适应性可以通过 SDSP 的随机转换（图 11）以及现象学 Izhikevich 神经元的不应期、脉冲延迟和阈值变异性行为在 ODIN 中捕获。 Loihi 还允许使用多区室神经元进行树突树计算，而 ODIN 则进一步扩展了行为库。Loihi 具有可配置的突触扇入/分辨率权衡，但尽管 Loihi 是在更先进的 14 纳米 FinFET 技术节点中实现的，表 I 显示 ODIN 在神经元核心密度（即 ODIN 为 3k 神经元/mm2，Loihi 最高为 2.6k）和突触核心密度（即 ODIN 为 741k 突触/mm2，Loihi 为 625k，具有 4 位突触）方面与 Loihi 相比更具优势。

关于功耗，如表 I 所示，现有技术中报告的 SOP 能量仅供参考，由于不同芯片之间的测量过程不标准化，因此不应直接进行比较。但是，它允许提取数量级。SpiNNaker 软件方法的灵活性-功率权衡显而易见：神经元和突触模型的高可编程性导致每 SOP 的全局能量为 26.6 nJ。下一代 SpiNNaker 可能会通过先进的功耗降低技术和专用的硬件加速器（例如 [69]、[70]）来改善这种权衡。对于 ODIN，在 28 nm FDSOI CMOS 中，电源电压降至 0.55 V 会导致最大 SOP 速率下的每 SOP 最小全局能量为 12.7 pJ。表 I 还显示，亚阈值模拟设计的百 fJ 增量能量使其看起来特别节能，因为它们排除了泄漏、空闲功率和网络操作的影响。然而，当考虑到这些因素时，DYNAP 的每 SOP 全局能量和增量能量之间的高比率表明这些设计不能有效地扩展。

# 5. 结论
在这项工作中，我们展示了 ODIN，这是一种采用 28 纳米 FDSOI CMOS 技术实现的数字脉冲神经形态处理器。它在仅 0.086 平方毫米的面积内嵌入了 256 个神经元和 64k 个突触，并模拟了 20 种 Izhikevich 行为中的每一种。具有过拟合预防机制的 SDSP 学习规则以高密度嵌入到所有突触中，每个 4 位突触 0.68 微米 2，并嵌入在线学习。在迄今为止提出的所有混合信号和数字 SNN 中，ODIN 具有最高的神经元和突触密度，同时表现出每 SOP 的全局能量低至 12.7 pJ。使用 ODIN 上的单层脉冲神经网络，我们表明基于 SDSP 的片上在线学习允许在 MNIST 分类任务上训练近似分类器，该任务针对在训练阶段功率和资源受限的应用程序量身定制。如果目标应用程序在学习阶段没有严格的功率或资源限制，则离线学习可以达到更高的准确率。在线和离线训练方法都利用了 ODIN 的能源效率，在推理阶段每个分类仅消耗 15 nJ，准确率分别为 84.5% 和 91.4%



