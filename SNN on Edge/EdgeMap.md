摘要：脉冲神经网络 (SNN) 作为第三代人工神经网络，以其强大的智能特性和节能优势而备受关注。这些特性使它们非常适合边缘计算场景。然而，当前将 SNN 部署到神经形态硬件上的映射方案面临着执行时间延长、吞吐量低以及对能耗和连接性考虑不足等限制，这些限制削弱了它们对边缘计算应用的适用性。为了应对这些挑战，==我们引入了 EdgeMap，这是一种优化的映射工具链，专门设计用于在不影响性能的情况下将 SNN 部署到边缘设备上。EdgeMap 包含两个主要阶段。第一阶段涉及基于流图分区算法将 SNN 图划分为小的神经元簇，神经元簇的大小受物理神经元核心的限制。在随后的映射阶段，我们采用了一种多目标优化算法，专门用于降低能源成本和通信成本，以实现高效部署。== EdgeMap 在四种典型的 SNN 应用程序中进行了评估，其性能大大优于其他最先进的映射方案。性能改进包括平均延迟减少高达 19.8%，能耗减少 57%，通信成本减少 58%。此外，EdgeMap 的执行时间显著提高了 1225.44 倍，吞吐量也增加了 4.02 倍。这些结果突出了 EdgeMap 的效率和有效性，强调了它在边缘计算场景中部署 SNN 应用程序的实用性。

# 1. 介绍
可穿戴电子设备、物联网设备、工业机械和连接到互联网的智能手机等边缘设备的日益普及，推动了智能应用的发展 [1]。边缘计算已成为一种有前途的方法，它通过更靠近源头处理数据（而不是依赖集中式节点）来减少延迟和节省带宽，从而优化整体系统性能。因此，人们对赋予边缘计算更高的智能性越来越感兴趣 [2]。

脉冲神经网络 (SNN) 凭借其低能耗和强大的仿生智能特性，在为边缘设备提供智能功能方面展现出巨大潜力 [3]。越来越多的 SNN 在各种边缘计算应用中表现出卓越的计算性能，包括对象识别 [4]、语音识别 [5] 和机器人控制 [6]。通过利用 SNN，边缘设备可以转变为更智能的节点，能够以更高的准确性和效率执行复杂的智能应用程序。

最近，出现了 TrueNorth [7]、Loihi [8] 和 SpiNNaker [9] 等神经形态硬件设计。这些设计通过片上网络 (NoC) 具有多个互连的神经形态核心 (NC)，从而实现了 SNN 的节能和高性能执行 [10]。为了弥合 SNN 和硬件实现之间的差距，已经提出了各种映射方案 [11–13]。这些方案通常涉及两个阶段：分区和映射。在分区阶段，SNN 神经元的计算图在神经形态硬件的约束下被划分为簇。然后，映射阶段将这些簇放置到物理神经元核心上以实现不同的优化目标。

然而，虽然这些映射方案增强了神经形态硬件上 SNN 的性能、可扩展性和准确性，但它们目前主要关注部署在服务器端的神经形态硬件。这种方法假设环境稳定且计算资源无限，这不能反映边缘计算场景。因此，在紧凑型边缘设备上实现 SNN 面临着独特的挑战，这使得它比服务器端部署更复杂、更严格。这些挑战可能包括：

能源限制：边缘计算设备通常是独立单元，在严格的能源限制下运行，因此电源效率是其运行的关键因素。不同的映射方案可能导致能耗的巨大差异，从而严重影响这些设备的性能和可行性。这些现实凸显了对全面考虑能源效率的映射方案的迫切需求。
•实时处理：许多边缘计算应用程序需要实时或近实时处理，需要低延迟和高效的网络通信。然而，在不损害其他基本属性（如能源效率）的情况下实现这些性能特征是一个具有挑战性的平衡问题。
•复杂环境：边缘计算场景本质上是复杂多样的，通常具有不同的约束和要求。与服务器端环境不同，边缘环境可以具有更加多样化和苛刻的约束和要求。

基于上述挑战，本文旨在探索多种边缘计算环境下 SNN 应用的最佳映射工具链。
我们为各种 SNN 开发了一种分区算法，以实现边缘设备上快速且资源高效的分区。然后应用映射优化策略来满足边缘计算要求。本文的主要贡献是提供更高效、更灵活的神经形态计算在边缘计算应用中的部署，同时提高整体系统性能。我们提出了一种受基于流的方法 [14] 启发的新型分区方法。

该方法有效地将 SNN 划分为多个神经元簇，显著减少了分区时间，同时最小化了簇之间的尖峰数量。

重要的是，我们的方法考虑了神经形态硬件的扇入和扇出限制，确保与边缘设备约束兼容。

我们提出了一种多目标优化方法，将神经元簇放置到神经形态设备上。该方法解决了边缘计算中的各种挑战，包括带宽限制、通信成本和能耗。我们的方法在成功降低能耗和延迟的同时，还极大地提高了边缘环境中神经形态计算的整体性能。

我们提出了一种适用于各种神经形态边缘设备的多功能映射工具链。通过在基于 NoC 的硬件上对各种 SNN 和规模进行广泛的评估，我们展示了边缘计算性能的显着增强。此外，我们的工具链可以适应不同边缘计算场景的不同约束和要求。

本文的结构如下：第 2 节回顾了相关工作。第 3 节讨论了理解后续章节所需的背景知识。第 4 节深入探讨了 EdgeMap 的设计方法。第 5 节概述了用于评估的设置。第 6 节详细介绍了我们的实验结果。最后，在第 7 节中，我们总结了本文。

# 2. 相关工作
最近，SNN 因其能源效率和计算能力而引起了人们的兴趣 [3]。然而，由于其复杂的连接和硬件限制，在神经形态硬件上执行 SNN 具有挑战性。人们为弥补这一差距做出了许多努力，目前的 SNN 映射方案通常分为三类：专用硬件映射、基于交叉开关的硬件的通用映射和其他灵活的映射方案。

第一类涉及专门为专门的 SNN 解决方案量身定制的专用硬件设计方案。此类映射方案的示例包括用于 µBrain [16] 的 SentryOS [15]、用于 TrueNorth [7] 的 Corelet 工具链 [17] 和用于 Loihi [8] 的 LCompiler [18]。这些完整的工具链旨在最大限度地优化核心利用率。SentryOS 工具链包含一个 SentryC 编译器，它将 SNN 网络结构划分为多个子网络，以及一个 SentryRT 实时管理器，负责实时对不同的子网络进行排序和计算。Corelet 是 TrueNorth 的专用可编程工具链，它封装了生物细节和神经元复杂性，然后提出了一种面向对象的 Corelet 语言来编写和执行 SNN。 LCompiler 框架通过呈现一个数据流图将 SNN 映射到 Loihi 神经形态硬件上，该数据流图具有描述 SNN 实例的逻辑实体，例如隔间、突触、输入映射、输出轴突和突触轨迹。该框架首先将 SNN 转换为微代码，并将 SNN 拓扑转换为连接矩阵。接下来，它采用贪婪算法将逻辑实体映射到硬件，然后再生成 Loihi 核心的比特流。在 Wang 等人的研究中。[19]，他们提出了一种针对 Tianjic 神经形态芯片 [20] 的创新映射方法。该方法包括两个阶段：逻辑映射和物理映射。在逻辑映射阶段，作者引入了一种采用异步 4D 模型分区的闭环映射策略。对于物理映射阶段，应用了汉密尔顿循环算法。该方法的优点是能够实现较高的资源利用率和处理效率，为在神经形态硬件上高效部署神经网络提供了一个有趣的视角。所有这些映射工具链都是针对特定目标而设计的，限制了它们的通用应用。这限制了它们在更通用用途上的适应性。

第二类侧重于基于交叉开关的 SNN 拓扑方案，这是更通用的映射技术。这些方案包括最先进的映射技术，例如 NEUTRAMS [21]、SpiNeMap [13]、SNEAP [22] 和 DFSynthesizer [23]。
NEUTRAMS 是一个协同设计工具链，它可以对 SNN 进行分区以满足硬件约束，并优化它们在神经形态硬件上的映射。SpiNeMap 采用贪婪方法，大致基于 Kernighan-Lin 图分区算法 [24]，以最小化集群间尖峰通信，并利用 PSO 算法 [25] 将每个集群放置在物理核心上。SNEAP [22] 使用 METIS 图分区算法对 SNN 计算图进行分区，目标是通信成本，然后使用贪婪算法得到最终的映射结果。 DFSynthesizer [21] 是一个用于映射机器学习算法的端到端框架。它将 SNN 分解并划分为集群，然后利用同步数据流图的丰富语义来探索影响映射性能的不同硬件约束。这些现有的工具链主要针对云服务器设计，没有考虑边缘计算等复杂计算环境的限制。这可能会限制它们在资源受限的边缘场景中的适用性，因为环境因素会发挥作用。

已经提出了各种工作来解决映射方案中的特定挑战。例如，Jin 等人 [26] 旨在解决将大规模 SNN 映射到神经形态硬件上的挑战。他们的方法采用希尔伯特曲线和力导向算法来优化映射阶段，在部署大规模 SNN 时实现了显着的时间退化。同样，Nair [27] 建议通过将 ANN 修改为具有自适应脉冲神经元模型的 RNN 单元并将其缩放以适合芯片，将循环神经网络映射到内存计算神经形态芯片。此外，Migspike [28] 被引入来解决由累积故障概率引起的可靠性问题，它使用节点级恢复机制来处理神经元故障，方法是将备用神经元放入每个神经元核心，通过有缺陷神经元的映射方法实现。

综上所述，已经提出了各种方案来优化神经形态硬件的映射，以实现不同的优化目标。为了在这些当前映射方案的基础上，本文的目标是介绍一种新颖的映射工具链，该工具链针对能源和计算资源有限且需要低延迟的复杂边缘计算场景进行了定制。

# 3. Background and Motivation
本节首先简要概述 SNN，强调其独特属性，这些属性有助于实现高效的计算模式和功能。随后，我们介绍边缘计算，深入探讨其固有环境的复杂性及其附带的必要条件。

## 3.1 A Brief Introduction to SNN
受哺乳动物大脑的启发，SNN 因其能够以比传统神经网络更高效的方式处理数据而越来越受人工智能应用的欢迎。此外，SNN 不易过度拟合，并且更善于捕捉非线性模式，因此非常适合广泛的人工智能应用 [6,29​​,30]。

如图 1 所示，典型且基本的 SNN 模型可以表示为由一系列连接层组成的有向图。该模型还可能包含层间连接，从而增强网络的连接性和学习能力。SNN 中的每个神经元都连接到特定数量的神经元，并具有可调整的连接权重，从而使网络能够从数据中学习。在计算过程中，SNN 中的每个神经元都会处理来自邻居的加权刺激尖峰，从而生成尖峰输出并将其传输到输出神经元。这个迭代过程持续进行，直到输出层产生最终结果。


## 3.2 Edge Computing
如图 2 所示，edge-fog-cloud 架构已成为分布式计算的流行范例，它在管理计算资源和减少通信延迟方面具有显著优势，已证明其适用于各个领域 [32]。该结构包含三层：边缘层、雾层和云层，雾层是边缘计算和云计算之间的桥梁。与主要依赖于边缘设备输入数据（如图像 [33]、语音 [34] 和视频 [35]）的传统云计算不同，边缘计算通过提供更接近最终用户的处理和存储服务来减轻云计算中心的负担。然而，从边缘向云端发展通常会产生更复杂的机器学习和数据处理能力，但会带来更高的延迟和通信开销。雾层是当代架构设计中的特色，它充当边缘和云之间的网格，帮助平衡其他两层的优点和缺点。该层解决了与可靠性、负载平衡、通信开销和数据共享相关的问题。具体而言，雾层充当靠近边缘层的数据收集器和靠近云层的数据过滤器，近乎实时地简化数据流，以实现高效的处理、压缩和转换。
![[Pasted image 20241224232350.png]]

尽管边缘-雾-云架构具有潜力，但边缘设备日益增长的需求对云层和雾层施加了巨大压力。这种情况强调了增强边缘智能的必要性。朝着这一目标迈出的重要一步是探索和实施边缘计算中的 SNN。然而，这种整合带来了独特的挑战。虽然 SNN 提供了高计算效率和生物真实感，但它们的固有特性（例如时间动态和基于尖峰的通信）使其部署变得复杂。有限的硬件资源和神经元连接的复杂性给将 SNN 映射到神经形态硬件上带来了额外的困难。增强边缘计算应用的智能与克服边缘设备约束之间的平衡是我们在本文中讨论的重点。

此外，边缘计算本身的采用也带来了一系列独特的挑战，这主要是由于资源受限以及需要实时数据分析和决策。这种困难在物联网设备 [36]、自动驾驶汽车 [37] 和智能城市基础设施 [38] 等应用中尤为明显。在多样化设备和复杂场景中平衡算法准确性、能耗和通信效率是一项重大困难。计算能力有限的单个边缘计算场景通常无法应对大规模数据处理。相反，协作边缘计算场景需要有效的协调方案来管理计算能力和设备数量的变化。因此，部署人工智能模型或将数据传输到云端进行处理等传统做法对于要求实时、高智能性能的应用程序而言已显得不足。

这些约束和当前解决方案的局限性凸显了新方法的必要性。正是在这种背景下，这项工作引入了专门为在边缘计算设备上部署 SNN 而设计的映射工具链。这项创新旨在弥合 SNN 和边缘计算之间的差距，重点是低延迟和高智能性能。

# 4. Framework and Design Method
## 4.1 Framework Overview
EdgeMap 框架旨在增强边缘计算场景中神经形态硬件上 SNN 的性能。当前的映射方法主要关注神经网络推理的前向方向，因为学习阶段可能对延迟不敏感并通过云端进行。如图 3 所示，EdgeMap 工具链通过以下阶段部署特定的神经网络：
![[Pasted image 20241224232816.png]]
离线训练阶段：考虑到边缘计算中的各种应用场景，具有不同网络结构的模型的设计和训练至关重要。这些结构必须满足不同的准确性和规模要求。训练过程可以使用 Nengo [39]、CARLsim [40] 和 Brain2 [41] 等框架来实现。为清楚起见，我们在图 3 中使用了常用的卷积 SNN 进行识别应用，主要用于分类任务 [42]。

处理阶段：如图 4 所示，此阶段是整个过程的关键。我们首先从训练过的 SNN 中提取信息，例如神经元连接结构、权重信息和脉冲通信细节。SNN 拓扑表示为计算图，如图 4a 所示。随后，我们将 SNN 划分为更小的神经元簇，以便于处理，如图 4b 所示。最后，我们将这些分区后的神经元簇映射到神经形态核心上，如图 4c 所示。这个过程构成了我们的 EdgeMap 工具链的核心功能。它优化了硬件资源利用率并确保了计算效率。

![[Pasted image 20241224232932.png]]

边缘计算阶段：在这一部分，我们简要介绍了两种边缘计算模式：个体边缘计算场景和协作边缘计算场景。个体边缘计算场景涉及多种计算模式和不同类型的设备。对于协作边缘计算场景，多个边缘设备通过网络连接协作以完成更多计算需要的任务。

## 4.2 Neuromorphic Edge Computing Hardware Model
本文主要讨论SNN在边缘设备上的部署，分为两种场景：个体边缘计算和协同边缘计算。个体边缘计算适用于SNN规模较小，或者单个边缘设备计算资源充足的情况。相反，当单个边缘设备的计算资源不足时，就需要协同边缘计算，需要多个设备进行计算。

为了更清楚地理解边缘计算模式，我们设计了一个简化的硬件模型，如图 5 所示。为了清楚起见，我们假设每个边缘设备由四个通过 2D 网格互连的神经形态核心组成。虽然实际设备可能拥有更多核心，但我们的模型旨在有效地阐明系统的基本架构。此外，为了模拟协作边缘计算，我们将四个边缘设备建模为通过网格拓扑互连。图中的虚线表示协作边缘计算环境中设备之间的通信路径，雾层是此类交互的主要促进者。为了研究的目的，我们做出以下假设：

![[Pasted image 20241224233203.png]]
设备之间的脉冲通信延迟和能耗与设备神经形态核心内的脉冲通信延迟和能耗相同。

脉冲处理所需的能量均匀分布在所有边缘设备上。

不同设备之间的 NC 具有相同的计算能力，包括相同数量的神经元和突触。

通过设定这些假设，我们建立了一个通用框架来研究 SNN 在各种设备和应用场景下的部署。这使我们能够更好地理解协作边缘计算的关键方面，并对边缘计算环境中不同映射算法的性能进行更全面的评估。

## 4.3 Streaming-Based SNN Partition

## 4.4 Multi-Objective Optimization Mapping
在本文中，我们假设边缘设备上有足够数量的物理核心可用于并行处理 SNN 中的所有神经元。
映射阶段对于多核协作计算至关重要，尤其是在边缘场景中，它将分区的神经元簇分配给相应的 NC，如图 4c 所示。如图 7 所示，映射方案的选择会显著影响能耗、平均延迟和跳数。在图 7a 中，我们显示了分区后的神经元簇。子图 (b) 和 (c) 展示了两种不同的映射方案。在方案 (b) 中，最大通信吞吐量为 75（峰值）。另一方面，方案 (c) 将最大通信吞吐量增加到 115（总峰值从 2 到 3 和从 1 到 3）。然而，它也导致集群 2 节点的拥塞加剧，从而导致延迟增加。因此，映射方案的选择应在各种因素之间取得平衡，以实现最有效的结果。

为了有效模拟基于NoC的多核或多设备神经形态计算之间的通信，我们开发了一个基于Noxim的模拟器[43]。该工具不仅为基于NoC的多核神经形态硬件内的通信提供了精确的模型，而且还支持各种边缘计算场景，促进了多设备之间的协作。